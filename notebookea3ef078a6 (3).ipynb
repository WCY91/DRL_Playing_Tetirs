{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T14:11:21.839803Z",
     "iopub.status.busy": "2025-04-16T14:11:21.839521Z",
     "iopub.status.idle": "2025-04-16T14:13:42.815519Z",
     "shell.execute_reply": "2025-04-16T14:13:42.814614Z",
     "shell.execute_reply.started": "2025-04-16T14:11:21.839777Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3[extra] in /usr/local/lib/python3.11/dist-packages (2.1.0)\n",
      "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (0.29.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.5.1+cu124)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.1.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.2.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.7.5)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.11.0.86)\n",
      "Requirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.6.1)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.18.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (7.0.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.67.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (14.0.0)\n",
      "Collecting shimmy~=1.1.0 (from shimmy[atari]~=1.1.0; extra == \"extra\"->stable-baselines3[extra])\n",
      "  Downloading Shimmy-1.1.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (11.1.0)\n",
      "Collecting autorom~=0.6.1 (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra])\n",
      "  Downloading AutoROM-0.6.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (8.1.8)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (2.32.3)\n",
      "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra])\n",
      "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (4.13.1)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (0.0.4)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->stable-baselines3[extra]) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->stable-baselines3[extra]) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->stable-baselines3[extra]) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->stable-baselines3[extra]) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->stable-baselines3[extra]) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->stable-baselines3[extra]) (2.4.1)\n",
      "Collecting ale-py~=0.8.1 (from shimmy[atari]~=1.1.0; extra == \"extra\"->stable-baselines3[extra])\n",
      "  Downloading ale_py-0.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.70.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.7)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (75.1.0)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.17.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.18.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3[extra]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3[extra]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3[extra]) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13->stable-baselines3[extra])\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13->stable-baselines3[extra])\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13->stable-baselines3[extra])\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13->stable-baselines3[extra])\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13->stable-baselines3[extra])\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13->stable-baselines3[extra])\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3[extra]) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13->stable-baselines3[extra])\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3[extra]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13->stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (2.19.1)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from ale-py~=0.8.1->shimmy[atari]~=1.1.0; extra == \"extra\"->stable-baselines3[extra]) (6.5.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->stable-baselines3[extra]) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->stable-baselines3[extra]) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.20->stable-baselines3[extra]) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.20->stable-baselines3[extra]) (2024.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (2025.1.31)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.20->stable-baselines3[extra]) (2024.2.0)\n",
      "Downloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
      "Downloading Shimmy-1.1.0-py3-none-any.whl (37 kB)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ale_py-0.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: AutoROM.accept-rom-license\n",
      "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for AutoROM.accept-rom-license: filename=autorom_accept_rom_license-0.6.1-py3-none-any.whl size=446711 sha256=7e8674bb3652723d968220c220e31bb74ebed5d3f8dda55abe3cec83bee78a76\n",
      "  Stored in directory: /root/.cache/pip/wheels/bc/fc/c6/8aa657c0d2089982f2dabd110efc68c61eb49831fdb7397351\n",
      "Successfully built AutoROM.accept-rom-license\n",
      "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, AutoROM.accept-rom-license, autorom, nvidia-cusolver-cu12, shimmy, ale-py\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
      "  Attempting uninstall: shimmy\n",
      "    Found existing installation: Shimmy 1.3.0\n",
      "    Uninstalling Shimmy-1.3.0:\n",
      "      Successfully uninstalled Shimmy-1.3.0\n",
      "  Attempting uninstall: ale-py\n",
      "    Found existing installation: ale-py 0.10.1\n",
      "    Uninstalling ale-py-0.10.1:\n",
      "      Successfully uninstalled ale-py-0.10.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "kaggle-environments 1.16.11 requires shimmy>=1.2.1, but you have shimmy 1.1.0 which is incompatible.\n",
      "dopamine-rl 4.1.2 requires ale-py>=0.10.1, but you have ale-py 0.8.1 which is incompatible.\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed AutoROM.accept-rom-license-0.6.1 ale-py-0.8.1 autorom-0.6.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 shimmy-1.1.0\n",
      "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.6)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (7.0.0)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.3)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.21.0)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.1)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "--2025-04-16 14:13:42--  http://www.aiotlab.org/teaching/oop/tetris/TetrisTCPserver_v0.6.jar\n",
      "Resolving www.aiotlab.org (www.aiotlab.org)... 18.238.176.108, 18.238.176.59, 18.238.176.89, ...\n",
      "Connecting to www.aiotlab.org (www.aiotlab.org)|18.238.176.108|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://www.aiotlab.org/teaching/oop/tetris/TetrisTCPserver_v0.6.jar [following]\n",
      "--2025-04-16 14:13:42--  https://www.aiotlab.org/teaching/oop/tetris/TetrisTCPserver_v0.6.jar\n",
      "Connecting to www.aiotlab.org (www.aiotlab.org)|18.238.176.108|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3879189 (3.7M) [binary/octet-stream]\n",
      "Saving to: ‘TetrisTCPserver_v0.6.jar’\n",
      "\n",
      "TetrisTCPserver_v0. 100%[===================>]   3.70M  --.-KB/s    in 0.08s   \n",
      "\n",
      "2025-04-16 14:13:42 (49.2 MB/s) - ‘TetrisTCPserver_v0.6.jar’ saved [3879189/3879189]\n",
      "\n",
      "✅ 檔案複製成功\n"
     ]
    }
   ],
   "source": [
    "!pip install \"stable-baselines3[extra]\"\n",
    "!pip install wandb\n",
    "!wget http://www.aiotlab.org/teaching/oop/tetris/TetrisTCPserver_v0.6.jar\n",
    "import os\n",
    "\n",
    "if os.path.exists(\"TetrisTCPserver_v0.6.jar\"):\n",
    "    print(\"✅ 檔案複製成功\")\n",
    "else:\n",
    "    print(\"❌ 檔案複製失敗\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T14:49:45.456095Z",
     "iopub.status.busy": "2025-04-16T14:49:45.455422Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Java started\n",
      "✅ Java server started\n",
      "⏳ 等待 Tetris TCP server 啟動中...\n",
      "✅ Java TCP server 準備完成，連線成功\n",
      "✅ PyTorch is using GPU:Client has joined the game Tesla T4\n",
      "Client has exited the game\n",
      "\n",
      "✅ 建立環境開始\n",
      "Client has exited the game\n",
      "Client has joined the game\n",
      "Address already in use (Bind failed)\n",
      "Tetris TCP server is listening at 10612\n",
      "Client has joined the game\n",
      "Using cuda device\n",
      "Model device: cuda\n",
      "Logging to ./sb3_log/DQN_11\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.856    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 23       |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 152      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.683    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 23       |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 334      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.528    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 23       |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 497      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.256    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 23       |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 783      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0937   |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 23       |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 954      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 23       |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 1646     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.383    |\n",
      "|    n_updates        | 161      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 23       |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 2102     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.457    |\n",
      "|    n_updates        | 275      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total_timesteps  | 2529     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.605    |\n",
      "|    n_updates        | 382      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 124      |\n",
      "|    total_timesteps  | 2863     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.284    |\n",
      "|    n_updates        | 465      |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import socket\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import imageio\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import VecNormalize, VecFrameStack\n",
    "from IPython.display import FileLink, display, Image\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import torch\n",
    "# 使用 wandb 記錄訓練日誌\n",
    "import os\n",
    "import wandb\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "# 從 Kaggle Secrets 讀取 API Token\n",
    "user_secrets = UserSecretsClient()\n",
    "WANDB_API_KEY = user_secrets.get_secret(\"WANDB_API_KEY\")\n",
    "\n",
    "# 設定環境變數，模擬 login\n",
    "os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY\n",
    "\n",
    "# login & init\n",
    "wandb.login()\n",
    "wandb.init(project=\"tetris-training\", entity=\"t113598065-ntut-edu-tw\")\n",
    "\n",
    "log_path = \"/kaggle/working/tetris_train_log.txt\"\n",
    "\n",
    "def write_log(message):\n",
    "    with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(message + \"\\n\")\n",
    "    print(message)\n",
    "\n",
    "import time\n",
    "\n",
    "def wait_for_tetris_server(ip=\"127.0.0.1\", port=10612, timeout=30):\n",
    "    write_log(\"⏳ 等待 Tetris TCP server 啟動中...\")\n",
    "    start_time = time.time()\n",
    "    while True:\n",
    "        try:\n",
    "            test_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "            test_sock.settimeout(1.0)\n",
    "            test_sock.connect((ip, port))\n",
    "            test_sock.close()\n",
    "            write_log(\"✅ Java TCP server 準備完成，連線成功\")\n",
    "            break\n",
    "        except socket.error:\n",
    "            if time.time() - start_time > timeout:\n",
    "                raise TimeoutError(\"❌ 等待 Java TCP server 超時\")\n",
    "            time.sleep(0.5)\n",
    "\n",
    "# 啟動 Java Tetris server\n",
    "print(\"Java started\")\n",
    "subprocess.Popen([\"java\", \"-jar\", \"TetrisTCPserver_v0.6.jar\"])\n",
    "write_log(\"✅ Java server started\")\n",
    "wait_for_tetris_server()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"✅ PyTorch is using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"❌ PyTorch is using CPU\")\n",
    "# ----------------------------\n",
    "# 定義 Tetris 環境 (採用老師的格式)\n",
    "class RewardLoggerCallback(BaseCallback):\n",
    "    def __init__(self, log_path=\"./reward_log.txt\", verbose=0):\n",
    "        super().__init__(verbose)\n",
    "        self.log_path = log_path\n",
    "        self.episode_rewards = []\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # 每次 env step 呼叫一次，但只有在 episode 結束時才記錄\n",
    "        infos = self.locals.get(\"infos\", [])\n",
    "        for info in infos:\n",
    "            if \"episode\" in info:  # VecEnv 會回傳 episode reward\n",
    "                ep_reward = info[\"episode\"][\"r\"]\n",
    "                self.episode_rewards.append(ep_reward)\n",
    "                with open(self.log_path, \"a\") as f:\n",
    "                    f.write(f\"{len(self.episode_rewards)},{ep_reward}\\n\")\n",
    "                print(f\"📈 Episode {len(self.episode_rewards)} Reward: {ep_reward}\")\n",
    "        return True\n",
    "\n",
    "class TetrisEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\"], \"render_fps\": 20}\n",
    "    N_DISCRETE_ACTIONS = 5\n",
    "    IMG_HEIGHT = 200\n",
    "    IMG_WIDTH = 100\n",
    "    IMG_CHANNELS = 3\n",
    "\n",
    "    def __init__(self, host_ip=\"127.0.0.1\", host_port=10612):\n",
    "        super().__init__()\n",
    "        self.action_space = spaces.Discrete(self.N_DISCRETE_ACTIONS)\n",
    "        # self.observation_space = spaces.Box(low=0, high=255, shape=(84, 84), dtype=np.uint8)\n",
    "        self.observation_space = spaces.Box(low=0, high=255, shape=(1, 84, 84), dtype=np.uint8)\n",
    "        self.server_ip = host_ip\n",
    "        self.server_port = host_port\n",
    "\n",
    "        self.client_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "        self.client_sock.connect((self.server_ip, self.server_port))\n",
    "\n",
    "        # 初始化 reward shaping 與統計用變數\n",
    "        self.lines_removed = 0\n",
    "        self.height = 0\n",
    "        self.holes = 0\n",
    "        self.lifetime = 0\n",
    "\n",
    "    def step(self, action):\n",
    "        if action == 0:\n",
    "            self.client_sock.sendall(b\"move -1\\n\")\n",
    "        elif action == 1:\n",
    "            self.client_sock.sendall(b\"move 1\\n\")\n",
    "        elif action == 2:\n",
    "            self.client_sock.sendall(b\"rotate 0\\n\")\n",
    "        elif action == 3:\n",
    "            self.client_sock.sendall(b\"rotate 1\\n\")\n",
    "        elif action == 4:\n",
    "            self.client_sock.sendall(b\"drop\\n\")\n",
    "    \n",
    "        terminated, lines, height, holes, observation = self.get_tetris_server_response(self.client_sock)\n",
    "    \n",
    "        reward = 0\n",
    "        if action == 4:\n",
    "            reward += 5\n",
    "    \n",
    "        if height > self.height:\n",
    "            reward -= (height - self.height) * 5\n",
    "    \n",
    "        if holes < self.holes:\n",
    "            reward += (self.holes - holes) * 10\n",
    "    \n",
    "        if lines > self.lines_removed:\n",
    "            reward += (lines - self.lines_removed) * 1000\n",
    "            self.lines_removed = lines\n",
    "    \n",
    "        self.height = height\n",
    "        self.holes = holes\n",
    "        self.lifetime += 1\n",
    "    \n",
    "        info = {'removed_lines': self.lines_removed, 'lifetime': self.lifetime}\n",
    "    \n",
    "        truncated = False\n",
    "    \n",
    "        # 關鍵！處理終止觀察值\n",
    "        if terminated:\n",
    "            info['terminal_observation']  = observation.copy()  \n",
    "    \n",
    "        return observation, reward, terminated, truncated, info\n",
    "\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        self.client_sock.sendall(b\"start\\n\")\n",
    "        terminated, lines, height, holes, observation = self.get_tetris_server_response(self.client_sock)\n",
    "        # 重置統計變數\n",
    "        self.lines_removed = 0\n",
    "        self.height = 0\n",
    "        self.holes = 0\n",
    "        self.lifetime = 0\n",
    "        return observation, {}\n",
    "\n",
    "    def render(self):\n",
    "        cv2.imshow(\"Tetris\", self.last_observation)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "    def close(self):\n",
    "        self.client_sock.close()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def get_tetris_server_response(self, sock):\n",
    "        is_game_over = (sock.recv(1) == b'\\x01')\n",
    "        removed_lines = int.from_bytes(sock.recv(4), 'big')\n",
    "        height = int.from_bytes(sock.recv(4), 'big')\n",
    "        holes = int.from_bytes(sock.recv(4), 'big')\n",
    "        img_size = int.from_bytes(sock.recv(4), 'big')\n",
    "        img_png = sock.recv(img_size)\n",
    "        nparr = np.frombuffer(img_png, np.uint8)\n",
    "        np_image = cv2.imdecode(nparr, -1)\n",
    "        resized = cv2.resize(np_image, (84, 84))\n",
    "        gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
    "        gray = np.expand_dims(gray, axis=0)  # <- 關鍵！channel-first\n",
    "        self.last_observation = gray.copy()\n",
    "        return is_game_over, removed_lines, height, holes, gray\n",
    "    \n",
    "\n",
    "        \n",
    "# 檢查環境\n",
    "print(\"✅ 建立環境開始\")\n",
    "env = TetrisEnv()\n",
    "check_env(env)\n",
    "\n",
    "# ----------------------------\n",
    "# 建立訓練環境（使用向量化、多個 env）並加入正規化與 frame stacking\n",
    "# 這部分主要用於加速並穩定訓練\n",
    "# train_env = make_vec_env(TetrisEnv, n_envs=3)\n",
    "# train_env = VecNormalize(train_env, norm_obs=False, norm_reward=True)\n",
    "# train_env = VecFrameStack(train_env, n_stack=4, channels_order='first')\n",
    "train_env = DummyVecEnv([lambda: TetrisEnv()])\n",
    "train_env = VecFrameStack(train_env, n_stack=4, channels_order=\"first\")\n",
    "\n",
    "# ----------------------------\n",
    "# 使用 DQN 進行訓練，調整超參數以提升效能：\n",
    "# 這裡設定 buffer_size、learning_starts、target_update_interval 等參數\n",
    "model = DQN(\"CnnPolicy\", train_env, verbose=1, tensorboard_log=\"./sb3_log/\",\n",
    "            gamma=0.95,\n",
    "            learning_rate=1e-4,         # 較低的學習率有助於穩定收斂\n",
    "            buffer_size=20000,         # 經驗回放緩衝區大小\n",
    "            learning_starts=1000,       # 多少步後開始學習\n",
    "            policy_kwargs=dict(normalize_images=False),\n",
    "            target_update_interval=1000 # 目標網路更新頻率\n",
    "           )\n",
    "write_log(\"Model device: \" + str(model.device))\n",
    "# model.learn(total_timesteps=100000)  # 可根據需要延長 timesteps1000000\n",
    "reward_logger = RewardLoggerCallback(log_path=\"./reward_log.txt\")\n",
    "model.learn(total_timesteps=5000000, callback=reward_logger)\n",
    "\n",
    "# 儲存訓練後的模型（訓練完畢後可先暫停 train_env 的歸一化更新）\n",
    "train_env.training = False\n",
    "\n",
    "# ----------------------------\n",
    "# 包裝測試環境，但僅用來符合 predict 格式，取影像還是從原生環境拿\n",
    "# wrapped_test_env = make_vec_env(TetrisEnv, n_envs=1)\n",
    "# wrapped_test_env = VecNormalize(wrapped_test_env, norm_obs=False, norm_reward=False, training=False)\n",
    "# wrapped_test_env = VecFrameStack(wrapped_test_env, n_stack=4, channels_order='first')\n",
    "wrapped_test_env = DummyVecEnv([lambda: TetrisEnv()])\n",
    "wrapped_test_env = VecFrameStack(wrapped_test_env, n_stack=4, channels_order=\"first\")\n",
    "\n",
    "# 原始環境保留用來取影像\n",
    "raw_test_env = TetrisEnv()\n",
    "\n",
    "# 初始化狀態\n",
    "wrapped_obs = wrapped_test_env.reset()\n",
    "raw_obs, _ = raw_test_env.reset()\n",
    "\n",
    "frames = []\n",
    "total_test_reward = 0\n",
    "test_steps = 1000\n",
    "\n",
    "for step in range(test_steps):\n",
    "    action, _ = model.predict(wrapped_obs, deterministic=True)\n",
    "\n",
    "    # 執行動作\n",
    "    next_raw_obs, reward, done, truncated, info = raw_test_env.step(action)\n",
    "    wrapped_obs, _, _, _ = wrapped_test_env.step(action)\n",
    "\n",
    "    total_test_reward += reward\n",
    "    frames.append(np.expand_dims(raw_obs.copy(), axis=0))\n",
    "    # frames.append(raw_obs.copy())  # 儲存原始影像\n",
    "    raw_obs = next_raw_obs\n",
    "\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "write_log(\"Test completed: Total reward = \" + str(total_test_reward))\n",
    "\n",
    "# 將回放影像存入資料夾（依老師格式）\n",
    "replay_folder = './replay'\n",
    "if os.path.exists(replay_folder):\n",
    "    shutil.rmtree(replay_folder)\n",
    "os.makedirs(replay_folder, exist_ok=True)\n",
    "episode_folder = os.path.join(replay_folder, \"0\", \"0\")\n",
    "os.makedirs(episode_folder, exist_ok=True)\n",
    "for i, frame in enumerate(frames):\n",
    "    fname = os.path.join(episode_folder, '{:06d}.png'.format(i))\n",
    "    cv2.imwrite(fname,frame[0].squeeze())\n",
    "\n",
    "# 產生 replay GIF（最佳回放）\n",
    "filenames = sorted(glob.glob(episode_folder + '/*.png'))\n",
    "gif_images = []\n",
    "for filename in filenames:\n",
    "    gif_images.append(imageio.imread(filename))\n",
    "imageio.mimsave('replay.gif', gif_images, loop=0)\n",
    "print(\"Replay GIF saved: replay.gif\")\n",
    "display(FileLink('replay.gif'))\n",
    "\n",
    "# 將測試結果寫入 CSV（格式與老師版本一致）\n",
    "with open('tetris_best_score_test2.csv', 'w') as fs:\n",
    "    fs.write('id,removed_lines,played_steps\\n')\n",
    "    fs.write(f'0,{info[\"removed_lines\"]},{info[\"lifetime\"]}\\n')\n",
    "    fs.write(f'1,{info[\"removed_lines\"]},{info[\"lifetime\"]}\\n')\n",
    "print(\"CSV file saved: tetris_best_score_test2.csv\")\n",
    "display(FileLink('tetris_best_score_test2.csv'))\n",
    "wandb.save('tetris_best_score_test2.csv')\n",
    "\n",
    "# ----------------------------\n",
    "# 儲存最終模型（請確認將 '113598065' 替換成你的學號）\n",
    "model.save('113598065_dqn_30env_1M.zip')\n",
    "print(\"Model saved: 113598065_dqn_30env_1M.zip\")\n",
    "display(FileLink('113598065_dqn_30env_1M.zip'))\n",
    "wandb.save('113598065_dqn_30env_1M.zip')\n",
    "\n",
    "# 關閉環境\n",
    "wrapped_test_env.close()\n",
    "raw_test_env.close()\n",
    "train_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import socket\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import imageio\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import VecNormalize, VecFrameStack, DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import torch\n",
    "import time\n",
    "import wandb\n",
    "import io\n",
    "import struct # For unpacking bytes\n",
    "from PIL import Image # For image processing\n",
    "\n",
    "# --- Kaggle/Jupyter 特有導入 ---\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    # 如果在 Kaggle 環境，嘗試讀取 WandB API Key\n",
    "    try:\n",
    "        user_secrets = UserSecretsClient()\n",
    "        WANDB_API_KEY = user_secrets.get_secret(\"WANDB_API_KEY\")\n",
    "        os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY\n",
    "        print(\"Trying to login WandB using Kaggle secrets...\")\n",
    "        wandb.login()\n",
    "        wandb.init(project=\"tetris-training\", entity=\"t113598065-ntut-edu-tw\", sync_tensorboard=True)\n",
    "        print(\"✅ WandB login successful via Kaggle secrets.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ WandB setup via Kaggle secrets failed: {e}. Trying anonymous login.\")\n",
    "        wandb.login(anonymous=\"allow\")\n",
    "        wandb.init(project=\"tetris-training\", anonymous=\"allow\", sync_tensorboard=True)\n",
    "        print(\"✅ WandB login successful anonymously.\")\n",
    "except ImportError:\n",
    "    # 如果不在 Kaggle，嘗試直接登入\n",
    "    print(\"Kaggle secrets not found. Trying standard WandB login...\")\n",
    "    try:\n",
    "        if \"WANDB_API_KEY\" in os.environ:\n",
    "             wandb.login()\n",
    "             wandb.init(project=\"tetris-training\", entity=\"t113598065-ntut-edu-tw\", sync_tensorboard=True)\n",
    "             print(\"✅ WandB login successful via environment variable.\")\n",
    "        else:\n",
    "             wandb.login(anonymous=\"allow\")\n",
    "             wandb.init(project=\"tetris-training\", anonymous=\"allow\", sync_tensorboard=True)\n",
    "             print(\"✅ WandB login successful anonymously (no API key found).\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Standard WandB login failed: {e}. WandB logging disabled.\")\n",
    "        wandb.init(mode=\"disabled\") # Disable WandB if login fails\n",
    "\n",
    "# --- IPython Display Fallback ---\n",
    "try:\n",
    "    from IPython.display import display, FileLink\n",
    "except ImportError:\n",
    "    def display(dummy): pass\n",
    "    def FileLink(path): return f\"File available at: {path}\"\n",
    "    print(\"⚠️ IPython.display not found. Download links may not work as expected.\")\n",
    "\n",
    "# --- Logging Setup ---\n",
    "log_path = \"/kaggle/working/tetris_train_log.txt\" # Kaggle 路徑\n",
    "if not os.path.exists(\"/kaggle/working/\"):\n",
    "    log_path = \"./tetris_train_log.txt\" # 本地路徑\n",
    "\n",
    "def write_log(message):\n",
    "    with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] {message}\\n\")\n",
    "    print(message)\n",
    "\n",
    "# --- Wait for Server ---\n",
    "def wait_for_tetris_server(ip=\"127.0.0.1\", port=10612, timeout=30):\n",
    "    write_log(\"⏳ 等待 Tetris TCP server 啟動中...\")\n",
    "    start_time = time.time()\n",
    "    while True:\n",
    "        try:\n",
    "            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as test_sock:\n",
    "                test_sock.settimeout(1.0)\n",
    "                test_sock.connect((ip, port))\n",
    "            write_log(f\"✅ Java TCP server ({ip}:{port}) 準備完成，連線成功\")\n",
    "            break\n",
    "        except socket.error as e:\n",
    "            if time.time() - start_time > timeout:\n",
    "                write_log(f\"❌ 等待 Java TCP server 超時 ({timeout}s)\")\n",
    "                raise TimeoutError(\"❌ 等待 Java TCP server 超時\")\n",
    "            time.sleep(0.5)\n",
    "\n",
    "# --- Reward Logger Callback (TXT format) ---\n",
    "class RewardLoggerCallback(BaseCallback):\n",
    "    def __init__(self, log_path: str, verbose: int = 0):\n",
    "        super().__init__(verbose)\n",
    "        self.log_path = log_path\n",
    "        self.episode_rewards = []\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Check if the environment is vectorized\n",
    "        is_vec_env = isinstance(self.training_env, (DummyVecEnv, VecFrameStack, VecNormalize))\n",
    "\n",
    "        if is_vec_env:\n",
    "            for i, done in enumerate(self.locals[\"dones\"]):\n",
    "                if done:\n",
    "                    info = self.locals[\"infos\"][i]\n",
    "                    if \"episode\" in info:\n",
    "                        ep_reward = info[\"episode\"][\"r\"]\n",
    "                        ep_len = info[\"episode\"][\"l\"]\n",
    "                        ep_num = len(self.episode_rewards) + 1\n",
    "                        self.episode_rewards.append(ep_reward)\n",
    "                        with open(self.log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "                            f.write(f\"{ep_num},{ep_reward}\\n\")\n",
    "                        if wandb.run and wandb.run.mode != \"disabled\":\n",
    "                             wandb.log({\"train/episode_reward\": ep_reward, \"train/episode_length\": ep_len}, step=self.num_timesteps)\n",
    "        # Handling for non-vectorized envs (less common with SB3 but good practice)\n",
    "        elif self.locals[\"dones\"]:\n",
    "             info = self.locals[\"infos\"] # Should be a single dict\n",
    "             if \"episode\" in info:\n",
    "                  ep_reward = info[\"episode\"][\"r\"]\n",
    "                  ep_len = info[\"episode\"][\"l\"]\n",
    "                  ep_num = len(self.episode_rewards) + 1\n",
    "                  self.episode_rewards.append(ep_reward)\n",
    "                  with open(self.log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "                       f.write(f\"{ep_num},{ep_reward}\\n\")\n",
    "                  if wandb.run and wandb.run.mode != \"disabled\":\n",
    "                       wandb.log({\"train/episode_reward\": ep_reward, \"train/episode_length\": ep_len}, step=self.num_timesteps)\n",
    "        return True\n",
    "\n",
    "\n",
    "# --- Tetris 環境 (修改為接收圖像) ---\n",
    "class TetrisEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Tetris 環境，通過 TCP 與外部 Java 伺服器通信。\n",
    "    **警告:** 內部實現基於對伺服器協議的假設 (發送圖像 + 文本狀態)。\n",
    "    \"\"\"\n",
    "    metadata = {'render_modes': ['human', 'ansi'], 'render_fps': 4}\n",
    "\n",
    "    def __init__(self, ip=\"127.0.0.1\", port=10612, render_mode=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.server_ip = ip\n",
    "        self.server_port = port\n",
    "        self.sock = None\n",
    "        self.text_buffer = \"\" # Buffer for text messages\n",
    "        self.render_mode = render_mode\n",
    "        self.current_observation_image = None\n",
    "\n",
    "        # **假設:** 狀態是 200x100 RGB 圖像\n",
    "        self.image_height = 200\n",
    "        self.image_width = 100\n",
    "        self.image_channels = 3\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0, high=255,\n",
    "            shape=(self.image_height, self.image_width, self.image_channels),\n",
    "            dtype=np.uint8\n",
    "        )\n",
    "\n",
    "        # **假設:** 動作是 40 種 (4 旋轉 * 10 X座標)\n",
    "        self.num_actions = 40\n",
    "        self.action_space = spaces.Discrete(self.num_actions)\n",
    "\n",
    "        assert render_mode is None or render_mode in self.metadata[\"render_modes\"]\n",
    "        write_log(f\"TetrisEnv (Image Mode) initialized. Observation space: {self.observation_space}, Action space: {self.action_space}\")\n",
    "\n",
    "    def _connect_to_server(self):\n",
    "        if self.sock:\n",
    "            self.close()\n",
    "        try:\n",
    "            self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "            self.sock.settimeout(20.0) # Increased timeout for potentially larger data\n",
    "            self.sock.connect((self.server_ip, self.server_port))\n",
    "        except socket.error as e:\n",
    "            write_log(f\"❌ Failed to connect to Tetris server: {e}\")\n",
    "            self.sock = None\n",
    "            raise ConnectionError(f\"Failed to connect to Tetris server: {e}\")\n",
    "\n",
    "    def _send_command(self, command):\n",
    "        if not self.sock:\n",
    "            raise ConnectionError(\"Not connected to server.\")\n",
    "        try:\n",
    "            full_command = command + \"\\n\"\n",
    "            self.sock.sendall(full_command.encode('utf-8'))\n",
    "        except socket.error as e:\n",
    "            write_log(f\"❌ Error sending command '{command}': {e}\")\n",
    "            self.close()\n",
    "            raise ConnectionError(f\"Error sending command: {e}\")\n",
    "\n",
    "    def _receive_exact_bytes(self, n_bytes):\n",
    "        \"\"\"Receives exactly n_bytes from the socket.\"\"\"\n",
    "        if not self.sock:\n",
    "            raise ConnectionError(\"Not connected to server.\")\n",
    "        chunks = []\n",
    "        bytes_recd = 0\n",
    "        while bytes_recd < n_bytes:\n",
    "            try:\n",
    "                chunk = self.sock.recv(min(n_bytes - bytes_recd, 4096))\n",
    "                if not chunk:\n",
    "                    self.close()\n",
    "                    raise ConnectionAbortedError(f\"Connection closed by server while waiting for {n_bytes} bytes.\")\n",
    "                chunks.append(chunk)\n",
    "                bytes_recd += len(chunk)\n",
    "            except socket.timeout:\n",
    "                self.close()\n",
    "                raise TimeoutError(f\"Socket timeout while waiting for {n_bytes} bytes.\")\n",
    "            except socket.error as e:\n",
    "                self.close()\n",
    "                raise ConnectionError(f\"Socket error while receiving data: {e}\")\n",
    "        return b''.join(chunks)\n",
    "\n",
    "    def _receive_text_line(self):\n",
    "        \"\"\"Receives a newline-terminated text message.\"\"\"\n",
    "        if not self.sock:\n",
    "             raise ConnectionError(\"Not connected to server.\")\n",
    "        while \"\\n\" not in self.text_buffer:\n",
    "            try:\n",
    "                # Use recv with a smaller size for text likely after image\n",
    "                chunk = self.sock.recv(1024)\n",
    "                if not chunk:\n",
    "                    self.close()\n",
    "                    raise ConnectionAbortedError(\"Connection closed by server while waiting for text line.\")\n",
    "                # Attempt to decode immediately to catch errors early, but buffer original bytes if needed\n",
    "                try:\n",
    "                    self.text_buffer += chunk.decode('utf-8')\n",
    "                except UnicodeDecodeError as e:\n",
    "                     # Handle case where text might be mixed with unexpected binary data\n",
    "                     write_log(f\"❌ Error decoding text chunk: {e}. Received bytes: {chunk}\")\n",
    "                     # Decide recovery strategy: skip chunk, raise error, etc.\n",
    "                     # For now, we'll raise, assuming text should be clean UTF-8\n",
    "                     raise ValueError(f\"Invalid UTF-8 received in text message: {e}\")\n",
    "\n",
    "            except socket.timeout:\n",
    "                self.close()\n",
    "                raise TimeoutError(\"Socket timeout while waiting for text line.\")\n",
    "            except socket.error as e:\n",
    "                self.close()\n",
    "                raise ConnectionError(f\"Socket error while receiving text line: {e}\")\n",
    "\n",
    "        line_end = self.text_buffer.find(\"\\n\")\n",
    "        data_line = self.text_buffer[:line_end]\n",
    "        self.text_buffer = self.text_buffer[line_end + 1:]\n",
    "        return data_line\n",
    "\n",
    "    def _receive_message(self):\n",
    "        \"\"\"\n",
    "        Receives a message based on the **assumed** protocol:\n",
    "        1. 4-byte integer (big-endian) for image size.\n",
    "        2. image_size bytes of PNG data.\n",
    "        3. Newline-terminated text line for status (reward, terminated, info).\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # 1. Receive image size header (4 bytes, big-endian)\n",
    "            header_bytes = self._receive_exact_bytes(4)\n",
    "            image_size = struct.unpack('>I', header_bytes)[0] # '>I' for big-endian unsigned int\n",
    "\n",
    "            # 2. Receive image data\n",
    "            if image_size == 0:\n",
    "                 # Handle case where server might send 0 size for error or empty image\n",
    "                 image_bytes = b''\n",
    "                 write_log(\"⚠️ Received image size 0 from server.\")\n",
    "            elif image_size > 5_000_000: # Sanity check for abnormally large size\n",
    "                 raise ValueError(f\"Received excessively large image size: {image_size} bytes.\")\n",
    "            else:\n",
    "                 image_bytes = self._receive_exact_bytes(image_size)\n",
    "\n",
    "            # 3. Receive status text line\n",
    "            status_line = self._receive_text_line()\n",
    "\n",
    "            return image_bytes, status_line\n",
    "\n",
    "        except (struct.error, ValueError) as e:\n",
    "             write_log(f\"❌ Error processing message header or size: {e}\")\n",
    "             raise ValueError(f\"Invalid message structure received: {e}\")\n",
    "\n",
    "\n",
    "    def _parse_image_and_status(self, image_bytes, status_line):\n",
    "        \"\"\"\n",
    "        Parses the received image bytes and status line.\n",
    "        **Assumes** status_line format: \"reward,term_flag[,lines_step][,final_lines][,final_lifetime]\"\n",
    "        \"\"\"\n",
    "        # Parse Image\n",
    "        observation_image = None\n",
    "        try:\n",
    "            if image_bytes:\n",
    "                 img = Image.open(io.BytesIO(image_bytes))\n",
    "                 # Convert to RGB if it's not already (handles RGBA, Grayscale etc.)\n",
    "                 img = img.convert(\"RGB\")\n",
    "                 observation_image = np.array(img, dtype=np.uint8)\n",
    "\n",
    "                 # Verify shape (optional but recommended)\n",
    "                 expected_shape = (self.image_height, self.image_width, self.image_channels)\n",
    "                 if observation_image.shape != expected_shape:\n",
    "                      write_log(f\"⚠️ Warning: Received image shape {observation_image.shape} differs from expected {expected_shape}. Resizing or check Env definition.\")\n",
    "                      # Example: Resize (might distort aspect ratio)\n",
    "                      # from skimage.transform import resize\n",
    "                      # observation_image = (resize(observation_image, expected_shape, anti_aliasing=True) * 255).astype(np.uint8)\n",
    "                      # Fallback: Return error state if resize is not desired\n",
    "                      raise ValueError(\"Incorrect image dimensions received.\")\n",
    "\n",
    "            else: # Handle empty image bytes case\n",
    "                 observation_image = np.zeros(self.observation_space.shape, dtype=self.observation_space.dtype)\n",
    "\n",
    "        except Exception as e:\n",
    "            write_log(f\"❌ Error processing received image data: {e}\")\n",
    "            observation_image = np.zeros(self.observation_space.shape, dtype=self.observation_space.dtype)\n",
    "            # We still need to parse the status line if possible\n",
    "            # return observation_image, 0.0, True, False, {\"error\": f\"Image processing error: {e}\"}\n",
    "\n",
    "        # Parse Status Line\n",
    "        try:\n",
    "            parts = status_line.strip().split(',')\n",
    "            if len(parts) < 2:\n",
    "                raise ValueError(\"Status line has too few parts.\")\n",
    "\n",
    "            reward = float(parts[0])\n",
    "            terminated_flag = int(parts[1])\n",
    "            terminated = (terminated_flag == 1)\n",
    "            truncated = False # Assume no truncation via time limit\n",
    "\n",
    "            # Attempt to parse optional info fields\n",
    "            info = {}\n",
    "            if len(parts) > 2: info['lines_cleared_this_step'] = int(parts[2])\n",
    "            if terminated and len(parts) > 3: info['removed_lines'] = int(parts[3]) # Only relevant if terminated\n",
    "            if terminated and len(parts) > 4: info['lifetime'] = int(parts[4])      # Only relevant if terminated\n",
    "\n",
    "            # Fill defaults if keys are missing after termination (needed for evaluation)\n",
    "            if terminated:\n",
    "                 info.setdefault('removed_lines', 0)\n",
    "                 info.setdefault('lifetime', 0)\n",
    "\n",
    "\n",
    "            return observation_image, reward, terminated, truncated, info\n",
    "\n",
    "        except Exception as e:\n",
    "            write_log(f\"❌ Error parsing status line '{status_line}': {e}\")\n",
    "            # Return observation image if valid, but signal error/termination\n",
    "            if observation_image is None: # If image parsing also failed\n",
    "                 observation_image = np.zeros(self.observation_space.shape, dtype=self.observation_space.dtype)\n",
    "            # Terminate the episode on parsing error\n",
    "            return observation_image, 0.0, True, False, {\"error\": f\"Status parsing error: {e}\"}\n",
    "\n",
    "\n",
    "    def _map_action_to_command(self, action):\n",
    "        \"\"\"\n",
    "        Maps action index (0-39) to \"PLACE <rot> <x>\" command (Assumption).\n",
    "        \"\"\"\n",
    "        if not 0 <= action < self.num_actions:\n",
    "            write_log(f\"❌ Invalid action: {action}. Using action 0.\")\n",
    "            action = 0\n",
    "        num_x_positions = 10\n",
    "        rotation_index = action // num_x_positions\n",
    "        x_position = action % num_x_positions\n",
    "        command = f\"PLACE {rotation_index} {x_position}\"\n",
    "        return command\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        try:\n",
    "            self._connect_to_server()\n",
    "            self._send_command(\"RESET\")\n",
    "            image_bytes, status_line = self._receive_message()\n",
    "            observation, _, _, _, info = self._parse_image_and_status(image_bytes, status_line)\n",
    "            self.current_observation_image = observation\n",
    "            if self.render_mode == \"human\": self.render()\n",
    "            if info is None: info = {} # Ensure info is always a dict\n",
    "            return observation, info\n",
    "        except (ConnectionError, TimeoutError, ValueError, ConnectionAbortedError, struct.error) as e:\n",
    "             write_log(f\"❌ Error during reset: {e}. Returning zero observation.\")\n",
    "             obs = np.zeros(self.observation_space.shape, dtype=self.observation_space.dtype)\n",
    "             info = {\"error\": f\"Reset error: {e}\"}\n",
    "             self.current_observation_image = obs\n",
    "             return obs, info\n",
    "\n",
    "    def step(self, action):\n",
    "        if self.sock is None:\n",
    "            write_log(\"❌ Attempting to step with no connection.\")\n",
    "            obs = np.zeros(self.observation_space.shape, dtype=self.observation_space.dtype)\n",
    "            return obs, 0.0, True, False, {\"error\": \"Connection lost\"}\n",
    "        try:\n",
    "            command = self._map_action_to_command(action)\n",
    "            self._send_command(command)\n",
    "            image_bytes, status_line = self._receive_message()\n",
    "            observation, reward, terminated, truncated, info = self._parse_image_and_status(image_bytes, status_line)\n",
    "            self.current_observation_image = observation\n",
    "\n",
    "            if self.render_mode == \"human\": self.render()\n",
    "            if info is None: info = {} # Ensure info is always a dict\n",
    "\n",
    "            # Add final evaluation keys if terminated (based on parsing assumption)\n",
    "            if terminated:\n",
    "                info.setdefault('removed_lines', 0)\n",
    "                info.setdefault('lifetime', 0)\n",
    "\n",
    "            return observation, float(reward), bool(terminated), bool(truncated), info\n",
    "\n",
    "        except (ConnectionError, TimeoutError, ValueError, ConnectionAbortedError, struct.error) as e:\n",
    "             write_log(f\"❌ Error during step: {e}. Terminating episode.\")\n",
    "             obs = self.current_observation_image if self.current_observation_image is not None else np.zeros(self.observation_space.shape, dtype=self.observation_space.dtype)\n",
    "             return obs, 0.0, True, False, {\"error\": f\"Step error: {e}\"}\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode == \"ansi\":\n",
    "            # Cannot render image as text easily\n",
    "            print(\"State: (Image observation, use 'human' mode or check saved images)\")\n",
    "        elif self.render_mode == \"human\":\n",
    "             if self.current_observation_image is not None:\n",
    "                 try:\n",
    "                     # Convert RGB (PIL/numpy) to BGR (OpenCV)\n",
    "                     img_bgr = cv2.cvtColor(self.current_observation_image, cv2.COLOR_RGB2BGR)\n",
    "                     cv2.imshow(\"Tetris (Python Render)\", img_bgr)\n",
    "                     cv2.waitKey(1) # Needed for imshow to refresh\n",
    "                 except Exception as e:\n",
    "                     print(f\"Human rendering failed: {e}\")\n",
    "             else:\n",
    "                 print(\"State: (No observation image available)\")\n",
    "\n",
    "    def close(self):\n",
    "        if self.sock:\n",
    "            try:\n",
    "                self.sock.shutdown(socket.SHUT_RDWR)\n",
    "                self.sock.close()\n",
    "            except socket.error: pass\n",
    "            finally: self.sock = None\n",
    "        if self.render_mode == \"human\":\n",
    "             try: cv2.destroyAllWindows()\n",
    "             except: pass\n",
    "\n",
    "\n",
    "# --- 主程式 ---\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Constants ---\n",
    "    SERVER_IP = \"127.0.0.1\"\n",
    "    SERVER_PORT = 10612\n",
    "    STUDENT_ID = \"113598065\"\n",
    "    # Using EXACT filenames as requested\n",
    "    MODEL_SAVE_PATH_ZIP = \"/kaggle/working/113598065_dqn_30env_1M.zip\"\n",
    "    CSV_SAVE_PATH = \"/kaggle/working/tetris_best_score_test2.csv\"\n",
    "    # Other paths derived from WORK_DIR\n",
    "    WORK_DIR = \"/kaggle/working/\"\n",
    "    if not os.path.exists(WORK_DIR): WORK_DIR = \"./\"\n",
    "    REWARD_LOG_FILE_PATH = os.path.join(WORK_DIR, \"reward_log.txt\")\n",
    "    TENSORBOARD_LOG_PATH = os.path.join(WORK_DIR, \"tensorboard_logs/\")\n",
    "    JAVA_SERVER_JAR = \"TetrisTCPserver_v0.6.jar\"\n",
    "    TOTAL_TRAIN_TIMESTEPS = 1_000_000 # Adjust training steps if needed (doesn't affect filename now)\n",
    "    N_STACK_FRAMES = 4 # Number of frames to stack for CNN\n",
    "\n",
    "    # --- 1. 啟動 Java Server ---\n",
    "    write_log(\"--- Starting Java Server ---\")\n",
    "    java_process = None\n",
    "    # ...(Same Java startup code as before)...\n",
    "    try:\n",
    "        java_process = subprocess.Popen([\"java\", \"-jar\", JAVA_SERVER_JAR], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        write_log(f\"✅ Java server process started (PID: {java_process.pid}). Waiting for connection...\")\n",
    "        # Add brief pause and check for immediate errors\n",
    "        time.sleep(2)\n",
    "        stderr_check = \"\"\n",
    "        try: stderr_check = java_process.stderr.read()\n",
    "        except: pass # Ignore read errors if process running\n",
    "        if stderr_check:\n",
    "             write_log(\"--- Java Server STDERR on Startup ---\"); write_log(stderr_check); write_log(\"---------------------------------\")\n",
    "        wait_for_tetris_server(SERVER_IP, SERVER_PORT)\n",
    "    except FileNotFoundError:\n",
    "        write_log(f\"❌ Error: {JAVA_SERVER_JAR} not found.\"); exit()\n",
    "    except Exception as e:\n",
    "        write_log(f\"❌ Error starting/waiting for Java server: {e}\")\n",
    "        if java_process: java_process.terminate()\n",
    "        exit()\n",
    "\n",
    "    # --- 2. 環境檢查與創建 ---\n",
    "    write_log(\"--- Setting up Environment ---\")\n",
    "    env_instance_for_check = None\n",
    "    train_env_vec = None\n",
    "    try:\n",
    "        # Check the base environment first\n",
    "        env_instance_for_check = TetrisEnv(ip=SERVER_IP, port=SERVER_PORT)\n",
    "        check_env(env_instance_for_check, warn=True)\n",
    "        write_log(\"✅ Base environment check passed.\")\n",
    "    except Exception as e:\n",
    "        write_log(f\"❌ Environment check failed: {e}\")\n",
    "        if env_instance_for_check: env_instance_for_check.close()\n",
    "        if java_process: java_process.terminate()\n",
    "        exit()\n",
    "    finally:\n",
    "         if env_instance_for_check: env_instance_for_check.close()\n",
    "\n",
    "    # Create vectorized and stacked environment for training\n",
    "    train_env = DummyVecEnv([lambda: TetrisEnv(ip=SERVER_IP, port=SERVER_PORT)])\n",
    "    train_env_vec = VecFrameStack(train_env, n_stack=N_STACK_FRAMES)\n",
    "    write_log(f\"✅ Training environment created and wrapped with VecFrameStack (n_stack={N_STACK_FRAMES}).\")\n",
    "    write_log(f\"   Observation space (stacked): {train_env_vec.observation_space}\")\n",
    "\n",
    "\n",
    "    # --- 3. 定義模型 ---\n",
    "    write_log(\"--- Defining DQN Model (CNN Policy) ---\")\n",
    "    policy_type = \"CnnPolicy\" # Use CNN for image input\n",
    "    os.makedirs(TENSORBOARD_LOG_PATH, exist_ok=True)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    write_log(f\"Using device: {device}\")\n",
    "\n",
    "    model = DQN(\n",
    "        policy_type,\n",
    "        train_env_vec, # Train on the stacked environment\n",
    "        verbose=1,\n",
    "        tensorboard_log=TENSORBOARD_LOG_PATH,\n",
    "        learning_rate=1e-4, # May need tuning for CNN\n",
    "        buffer_size=50000,  # May need larger buffer for images\n",
    "        learning_starts=10000,# Let buffer fill more before learning\n",
    "        batch_size=32,      # Often smaller batch size for CNNs due to memory\n",
    "        tau=1.0,\n",
    "        gamma=0.99,\n",
    "        train_freq=4,\n",
    "        gradient_steps=1,\n",
    "        target_update_interval=1000, # May need longer interval\n",
    "        exploration_fraction=0.1,\n",
    "        exploration_final_eps=0.05,\n",
    "        # SB3's DQN with CnnPolicy expects images in channel-first format (C, H, W)\n",
    "        # VecFrameStack usually handles the dimension permutation if the env returns H, W, C\n",
    "        policy_kwargs=dict(features_extractor_kwargs=dict(features_dim=512)), # Example CNN feature dim\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # --- 4. 定義回調函數 ---\n",
    "    reward_logger = RewardLoggerCallback(log_path=REWARD_LOG_FILE_PATH)\n",
    "    callbacks = [reward_logger]\n",
    "    if wandb.run and wandb.run.mode != \"disabled\":\n",
    "        from wandb.integration.sb3 import WandbCallback\n",
    "        wandb_callback = WandbCallback(log=\"all\", verbose=2)\n",
    "        callbacks.append(wandb_callback)\n",
    "\n",
    "    # --- 5. 訓練模型 ---\n",
    "    write_log(f\"--- Starting Training for {TOTAL_TRAIN_TIMESTEPS} timesteps ---\")\n",
    "    training_successful = False\n",
    "    try:\n",
    "        model.learn(\n",
    "            total_timesteps=TOTAL_TRAIN_TIMESTEPS,\n",
    "            log_interval=10,\n",
    "            callback=callbacks\n",
    "        )\n",
    "        training_successful = True\n",
    "        write_log(\"✅ Training completed successfully.\")\n",
    "    except KeyboardInterrupt:\n",
    "        write_log(\"🛑 Training interrupted by user.\")\n",
    "    except Exception as train_e:\n",
    "        write_log(f\"❌ Training failed: {train_e}\")\n",
    "        # ...(Error saving logic remains the same)...\n",
    "        error_save_path = os.path.join(WORK_DIR, f\"{STUDENT_ID}_dqn_error.zip\") # Generic error name\n",
    "        try: model.save(error_save_path); write_log(f\"💾 Intermediate model saved to {error_save_path}\")\n",
    "        except: write_log(\"❌ Failed to save intermediate model after error.\")\n",
    "    finally:\n",
    "        # --- 保存最終模型 (Using exact requested filename) ---\n",
    "        if training_successful:\n",
    "            try:\n",
    "                model.save(MODEL_SAVE_PATH_ZIP) # Use the exact path defined earlier\n",
    "                write_log(f\"💾 Final model saved: {MODEL_SAVE_PATH_ZIP}\")\n",
    "                display(FileLink(MODEL_SAVE_PATH_ZIP))\n",
    "                if wandb.run and wandb.run.mode != \"disabled\":\n",
    "                    wandb.save(MODEL_SAVE_PATH_ZIP, base_path=WORK_DIR)\n",
    "                    write_log(\"⬆️ Final model uploaded to WandB.\")\n",
    "            except Exception as final_save_e:\n",
    "                write_log(f\"❌ Failed to save final model: {final_save_e}\")\n",
    "        # 關閉訓練環境\n",
    "        if train_env_vec: train_env_vec.close() # Close the VecFrameStack wrapper\n",
    "        write_log(\"✅ Training environment closed.\")\n",
    "\n",
    "    # --- 6. 評估模型並保存 CSV ---\n",
    "    if training_successful:\n",
    "        write_log(\"\\n--- Starting Model Evaluation ---\")\n",
    "        # Use a non-vectorized, non-stacked env for simplicity in eval loop control\n",
    "        eval_env = None\n",
    "        try:\n",
    "            write_log(f\"🔄 Loading model from: {MODEL_SAVE_PATH_ZIP}\")\n",
    "            # Load model, no env needed if saved correctly\n",
    "            eval_model = DQN.load(MODEL_SAVE_PATH_ZIP, device=device)\n",
    "\n",
    "            # Create a fresh evaluation environment (not stacked)\n",
    "            eval_env = TetrisEnv(ip=SERVER_IP, port=SERVER_PORT)\n",
    "            obs, info = eval_env.reset() # obs is single image (H, W, C)\n",
    "\n",
    "            # For CNN policy, prediction needs channel-first and batch dim (N, C, H, W)\n",
    "            # And needs stacking if trained with stacking. Manual stacking for eval:\n",
    "            stacked_obs_deque = io.deque([np.zeros_like(obs)] * N_STACK_FRAMES, maxlen=N_STACK_FRAMES)\n",
    "            stacked_obs_deque.append(obs)\n",
    "\n",
    "            def get_stacked_observation(deque):\n",
    "                # Stack along the channel dimension (axis=2 for HWC -> HWSC, then transpose) or a new axis\n",
    "                stacked_frames = np.array(list(deque)) # Shape (N_STACK, H, W, C)\n",
    "                # SB3 CnnPolicy usually expects (Batch, C*N_STACK, H, W) or similar based on extractor\n",
    "                # Or VecFrameStack gives (Batch, H, W, C*N_STACK) -> let's assume this\n",
    "                # This part is tricky and depends on how VecFrameStack observation space is structured.\n",
    "                # Let's assume VecFrameStack concatenates channels: (H, W, C * N_STACK)\n",
    "                # We need to replicate this manually.\n",
    "                processed_obs = np.concatenate(list(deque), axis=-1) # Concatenate along channel axis -> (H, W, C*N_STACK)\n",
    "                # Add batch dimension\n",
    "                return np.expand_dims(processed_obs, axis=0)\n",
    "\n",
    "\n",
    "            terminated = False\n",
    "            truncated = False\n",
    "            played_steps = 0\n",
    "            removed_lines_total = 0\n",
    "            final_removed_lines = 0\n",
    "            final_lifetime = 0\n",
    "\n",
    "            while not terminated and not truncated:\n",
    "                current_stacked_obs_for_policy = get_stacked_observation(stacked_obs_deque)\n",
    "                action, _ = eval_model.predict(current_stacked_obs_for_policy, deterministic=True)\n",
    "                obs, reward, terminated, truncated, info = eval_env.step(action[0]) # action is usually wrapped in a list/array\n",
    "                stacked_obs_deque.append(obs) # Add new observation\n",
    "                played_steps += 1\n",
    "                # Accumulate lines based on info from step (ASSUMPTION)\n",
    "                removed_lines_total += info.get('lines_cleared_this_step', 0)\n",
    "                # If terminated, try to get final stats from info (ASSUMPTION)\n",
    "                if terminated:\n",
    "                    final_removed_lines = info.get('removed_lines', removed_lines_total)\n",
    "                    final_lifetime = info.get('lifetime', played_steps)\n",
    "\n",
    "            write_log(f\"🏁 Evaluation Episode finished. Steps: {final_lifetime}, Removed Lines: {final_removed_lines}\")\n",
    "\n",
    "            # --- 寫入 CSV 文件 (Using exact requested filename and format) ---\n",
    "            write_log(f\"💾 Writing evaluation results to: {CSV_SAVE_PATH}\")\n",
    "            with open(CSV_SAVE_PATH, 'w') as fs:\n",
    "                fs.write('id,removed_lines,played_steps\\n')\n",
    "                fs.write(f'0,{final_removed_lines},{final_lifetime}\\n')\n",
    "                fs.write(f'1,{final_removed_lines},{final_lifetime}\\n')\n",
    "            write_log(\"✅ CSV file saved.\")\n",
    "            display(FileLink(CSV_SAVE_PATH))\n",
    "            if wandb.run and wandb.run.mode != \"disabled\":\n",
    "                wandb.save(CSV_SAVE_PATH, base_path=WORK_DIR)\n",
    "                write_log(\"⬆️ CSV results uploaded to WandB.\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "             write_log(f\"❌ Evaluation failed: Model file not found at {MODEL_SAVE_PATH_ZIP}\")\n",
    "        except KeyError as e:\n",
    "             write_log(f\"❌ Evaluation failed: Missing key {e} in environment's info dictionary.\")\n",
    "             write_log(\"   Ensure TetrisEnv step() returns info with required keys on termination.\")\n",
    "        except Exception as eval_e:\n",
    "             write_log(f\"❌ An error occurred during evaluation or CSV saving: {eval_e}\")\n",
    "        finally:\n",
    "            if eval_env: eval_env.close()\n",
    "            write_log(\"✅ Evaluation environment closed.\")\n",
    "\n",
    "\n",
    "    # --- 7. 清理工作 ---\n",
    "    # ...(Same cleanup code as before)...\n",
    "    write_log(\"--- Cleaning up ---\")\n",
    "    if java_process:\n",
    "        try:\n",
    "            java_process.terminate()\n",
    "            java_process.wait(timeout=5)\n",
    "            write_log(\"☕ Java server process terminated.\")\n",
    "        except subprocess.TimeoutExpired:\n",
    "            java_process.kill()\n",
    "            write_log(\"🔪 Java server process killed.\")\n",
    "        except Exception as e:\n",
    "            write_log(f\"⚠️ Error terminating Java process: {e}\")\n",
    "\n",
    "    if wandb.run and wandb.run.mode != \"disabled\":\n",
    "         wandb.finish()\n",
    "         write_log(\"📊 WandB run finished.\")\n",
    "\n",
    "    write_log(\"🏁 Full script finished.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11461423,
     "sourceId": 96443,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
