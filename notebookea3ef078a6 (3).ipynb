{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T14:11:21.839803Z",
     "iopub.status.busy": "2025-04-16T14:11:21.839521Z",
     "iopub.status.idle": "2025-04-16T14:13:42.815519Z",
     "shell.execute_reply": "2025-04-16T14:13:42.814614Z",
     "shell.execute_reply.started": "2025-04-16T14:11:21.839777Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3[extra] in /usr/local/lib/python3.11/dist-packages (2.1.0)\n",
      "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (0.29.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.5.1+cu124)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.1.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.2.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.7.5)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.11.0.86)\n",
      "Requirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.6.1)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.18.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (7.0.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.67.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (14.0.0)\n",
      "Collecting shimmy~=1.1.0 (from shimmy[atari]~=1.1.0; extra == \"extra\"->stable-baselines3[extra])\n",
      "  Downloading Shimmy-1.1.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (11.1.0)\n",
      "Collecting autorom~=0.6.1 (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra])\n",
      "  Downloading AutoROM-0.6.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (8.1.8)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (2.32.3)\n",
      "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra])\n",
      "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (4.13.1)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (0.0.4)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->stable-baselines3[extra]) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->stable-baselines3[extra]) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->stable-baselines3[extra]) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->stable-baselines3[extra]) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->stable-baselines3[extra]) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->stable-baselines3[extra]) (2.4.1)\n",
      "Collecting ale-py~=0.8.1 (from shimmy[atari]~=1.1.0; extra == \"extra\"->stable-baselines3[extra])\n",
      "  Downloading ale_py-0.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.70.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.7)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (75.1.0)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.17.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.18.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3[extra]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3[extra]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3[extra]) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13->stable-baselines3[extra])\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13->stable-baselines3[extra])\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13->stable-baselines3[extra])\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13->stable-baselines3[extra])\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13->stable-baselines3[extra])\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13->stable-baselines3[extra])\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3[extra]) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13->stable-baselines3[extra])\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3[extra]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13->stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (2.19.1)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from ale-py~=0.8.1->shimmy[atari]~=1.1.0; extra == \"extra\"->stable-baselines3[extra]) (6.5.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->stable-baselines3[extra]) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->stable-baselines3[extra]) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.20->stable-baselines3[extra]) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.20->stable-baselines3[extra]) (2024.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (2025.1.31)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.20->stable-baselines3[extra]) (2024.2.0)\n",
      "Downloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
      "Downloading Shimmy-1.1.0-py3-none-any.whl (37 kB)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ale_py-0.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: AutoROM.accept-rom-license\n",
      "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for AutoROM.accept-rom-license: filename=autorom_accept_rom_license-0.6.1-py3-none-any.whl size=446711 sha256=7e8674bb3652723d968220c220e31bb74ebed5d3f8dda55abe3cec83bee78a76\n",
      "  Stored in directory: /root/.cache/pip/wheels/bc/fc/c6/8aa657c0d2089982f2dabd110efc68c61eb49831fdb7397351\n",
      "Successfully built AutoROM.accept-rom-license\n",
      "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, AutoROM.accept-rom-license, autorom, nvidia-cusolver-cu12, shimmy, ale-py\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
      "  Attempting uninstall: shimmy\n",
      "    Found existing installation: Shimmy 1.3.0\n",
      "    Uninstalling Shimmy-1.3.0:\n",
      "      Successfully uninstalled Shimmy-1.3.0\n",
      "  Attempting uninstall: ale-py\n",
      "    Found existing installation: ale-py 0.10.1\n",
      "    Uninstalling ale-py-0.10.1:\n",
      "      Successfully uninstalled ale-py-0.10.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "kaggle-environments 1.16.11 requires shimmy>=1.2.1, but you have shimmy 1.1.0 which is incompatible.\n",
      "dopamine-rl 4.1.2 requires ale-py>=0.10.1, but you have ale-py 0.8.1 which is incompatible.\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed AutoROM.accept-rom-license-0.6.1 ale-py-0.8.1 autorom-0.6.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 shimmy-1.1.0\n",
      "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.6)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (7.0.0)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.3)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.21.0)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.1)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "--2025-04-16 14:13:42--  http://www.aiotlab.org/teaching/oop/tetris/TetrisTCPserver_v0.6.jar\n",
      "Resolving www.aiotlab.org (www.aiotlab.org)... 18.238.176.108, 18.238.176.59, 18.238.176.89, ...\n",
      "Connecting to www.aiotlab.org (www.aiotlab.org)|18.238.176.108|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://www.aiotlab.org/teaching/oop/tetris/TetrisTCPserver_v0.6.jar [following]\n",
      "--2025-04-16 14:13:42--  https://www.aiotlab.org/teaching/oop/tetris/TetrisTCPserver_v0.6.jar\n",
      "Connecting to www.aiotlab.org (www.aiotlab.org)|18.238.176.108|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3879189 (3.7M) [binary/octet-stream]\n",
      "Saving to: â€˜TetrisTCPserver_v0.6.jarâ€™\n",
      "\n",
      "TetrisTCPserver_v0. 100%[===================>]   3.70M  --.-KB/s    in 0.08s   \n",
      "\n",
      "2025-04-16 14:13:42 (49.2 MB/s) - â€˜TetrisTCPserver_v0.6.jarâ€™ saved [3879189/3879189]\n",
      "\n",
      "âœ… æª”æ¡ˆè¤‡è£½æˆåŠŸ\n"
     ]
    }
   ],
   "source": [
    "!pip install \"stable-baselines3[extra]\"\n",
    "!pip install wandb\n",
    "!wget http://www.aiotlab.org/teaching/oop/tetris/TetrisTCPserver_v0.6.jar\n",
    "import os\n",
    "\n",
    "if os.path.exists(\"TetrisTCPserver_v0.6.jar\"):\n",
    "    print(\"âœ… æª”æ¡ˆè¤‡è£½æˆåŠŸ\")\n",
    "else:\n",
    "    print(\"âŒ æª”æ¡ˆè¤‡è£½å¤±æ•—\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T14:49:45.456095Z",
     "iopub.status.busy": "2025-04-16T14:49:45.455422Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Java started\n",
      "âœ… Java server started\n",
      "â³ ç­‰å¾… Tetris TCP server å•Ÿå‹•ä¸­...\n",
      "âœ… Java TCP server æº–å‚™å®Œæˆï¼Œé€£ç·šæˆåŠŸ\n",
      "âœ… PyTorch is using GPU:Client has joined the game Tesla T4\n",
      "Client has exited the game\n",
      "\n",
      "âœ… å»ºç«‹ç’°å¢ƒé–‹å§‹\n",
      "Client has exited the game\n",
      "Client has joined the game\n",
      "Address already in use (Bind failed)\n",
      "Tetris TCP server is listening at 10612\n",
      "Client has joined the game\n",
      "Using cuda device\n",
      "Model device: cuda\n",
      "Logging to ./sb3_log/DQN_11\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.856    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 23       |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 152      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.683    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 23       |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 334      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.528    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 23       |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 497      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.256    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 23       |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 783      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0937   |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 23       |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 954      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 23       |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 1646     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.383    |\n",
      "|    n_updates        | 161      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 23       |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 2102     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.457    |\n",
      "|    n_updates        | 275      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total_timesteps  | 2529     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.605    |\n",
      "|    n_updates        | 382      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 124      |\n",
      "|    total_timesteps  | 2863     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.284    |\n",
      "|    n_updates        | 465      |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import socket\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import imageio\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import VecNormalize, VecFrameStack\n",
    "from IPython.display import FileLink, display, Image\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import torch\n",
    "# ä½¿ç”¨ wandb è¨˜éŒ„è¨“ç·´æ—¥èªŒ\n",
    "import os\n",
    "import wandb\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "# å¾ Kaggle Secrets è®€å– API Token\n",
    "user_secrets = UserSecretsClient()\n",
    "WANDB_API_KEY = user_secrets.get_secret(\"WANDB_API_KEY\")\n",
    "\n",
    "# è¨­å®šç’°å¢ƒè®Šæ•¸ï¼Œæ¨¡æ“¬ login\n",
    "os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY\n",
    "\n",
    "# login & init\n",
    "wandb.login()\n",
    "wandb.init(project=\"tetris-training\", entity=\"t113598065-ntut-edu-tw\")\n",
    "\n",
    "log_path = \"/kaggle/working/tetris_train_log.txt\"\n",
    "\n",
    "def write_log(message):\n",
    "    with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(message + \"\\n\")\n",
    "    print(message)\n",
    "\n",
    "import time\n",
    "\n",
    "def wait_for_tetris_server(ip=\"127.0.0.1\", port=10612, timeout=30):\n",
    "    write_log(\"â³ ç­‰å¾… Tetris TCP server å•Ÿå‹•ä¸­...\")\n",
    "    start_time = time.time()\n",
    "    while True:\n",
    "        try:\n",
    "            test_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "            test_sock.settimeout(1.0)\n",
    "            test_sock.connect((ip, port))\n",
    "            test_sock.close()\n",
    "            write_log(\"âœ… Java TCP server æº–å‚™å®Œæˆï¼Œé€£ç·šæˆåŠŸ\")\n",
    "            break\n",
    "        except socket.error:\n",
    "            if time.time() - start_time > timeout:\n",
    "                raise TimeoutError(\"âŒ ç­‰å¾… Java TCP server è¶…æ™‚\")\n",
    "            time.sleep(0.5)\n",
    "\n",
    "# å•Ÿå‹• Java Tetris server\n",
    "print(\"Java started\")\n",
    "subprocess.Popen([\"java\", \"-jar\", \"TetrisTCPserver_v0.6.jar\"])\n",
    "write_log(\"âœ… Java server started\")\n",
    "wait_for_tetris_server()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"âœ… PyTorch is using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"âŒ PyTorch is using CPU\")\n",
    "# ----------------------------\n",
    "# å®šç¾© Tetris ç’°å¢ƒ (æ¡ç”¨è€å¸«çš„æ ¼å¼)\n",
    "class RewardLoggerCallback(BaseCallback):\n",
    "    def __init__(self, log_path=\"./reward_log.txt\", verbose=0):\n",
    "        super().__init__(verbose)\n",
    "        self.log_path = log_path\n",
    "        self.episode_rewards = []\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # æ¯æ¬¡ env step å‘¼å«ä¸€æ¬¡ï¼Œä½†åªæœ‰åœ¨ episode çµæŸæ™‚æ‰è¨˜éŒ„\n",
    "        infos = self.locals.get(\"infos\", [])\n",
    "        for info in infos:\n",
    "            if \"episode\" in info:  # VecEnv æœƒå›å‚³ episode reward\n",
    "                ep_reward = info[\"episode\"][\"r\"]\n",
    "                self.episode_rewards.append(ep_reward)\n",
    "                with open(self.log_path, \"a\") as f:\n",
    "                    f.write(f\"{len(self.episode_rewards)},{ep_reward}\\n\")\n",
    "                print(f\"ğŸ“ˆ Episode {len(self.episode_rewards)} Reward: {ep_reward}\")\n",
    "        return True\n",
    "\n",
    "class TetrisEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\"], \"render_fps\": 20}\n",
    "    N_DISCRETE_ACTIONS = 5\n",
    "    IMG_HEIGHT = 200\n",
    "    IMG_WIDTH = 100\n",
    "    IMG_CHANNELS = 3\n",
    "\n",
    "    def __init__(self, host_ip=\"127.0.0.1\", host_port=10612):\n",
    "        super().__init__()\n",
    "        self.action_space = spaces.Discrete(self.N_DISCRETE_ACTIONS)\n",
    "        # self.observation_space = spaces.Box(low=0, high=255, shape=(84, 84), dtype=np.uint8)\n",
    "        self.observation_space = spaces.Box(low=0, high=255, shape=(1, 84, 84), dtype=np.uint8)\n",
    "        self.server_ip = host_ip\n",
    "        self.server_port = host_port\n",
    "\n",
    "        self.client_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "        self.client_sock.connect((self.server_ip, self.server_port))\n",
    "\n",
    "        # åˆå§‹åŒ– reward shaping èˆ‡çµ±è¨ˆç”¨è®Šæ•¸\n",
    "        self.lines_removed = 0\n",
    "        self.height = 0\n",
    "        self.holes = 0\n",
    "        self.lifetime = 0\n",
    "\n",
    "    def step(self, action):\n",
    "        if action == 0:\n",
    "            self.client_sock.sendall(b\"move -1\\n\")\n",
    "        elif action == 1:\n",
    "            self.client_sock.sendall(b\"move 1\\n\")\n",
    "        elif action == 2:\n",
    "            self.client_sock.sendall(b\"rotate 0\\n\")\n",
    "        elif action == 3:\n",
    "            self.client_sock.sendall(b\"rotate 1\\n\")\n",
    "        elif action == 4:\n",
    "            self.client_sock.sendall(b\"drop\\n\")\n",
    "    \n",
    "        terminated, lines, height, holes, observation = self.get_tetris_server_response(self.client_sock)\n",
    "    \n",
    "        reward = 0\n",
    "        if action == 4:\n",
    "            reward += 5\n",
    "    \n",
    "        if height > self.height:\n",
    "            reward -= (height - self.height) * 5\n",
    "    \n",
    "        if holes < self.holes:\n",
    "            reward += (self.holes - holes) * 10\n",
    "    \n",
    "        if lines > self.lines_removed:\n",
    "            reward += (lines - self.lines_removed) * 1000\n",
    "            self.lines_removed = lines\n",
    "    \n",
    "        self.height = height\n",
    "        self.holes = holes\n",
    "        self.lifetime += 1\n",
    "    \n",
    "        info = {'removed_lines': self.lines_removed, 'lifetime': self.lifetime}\n",
    "    \n",
    "        truncated = False\n",
    "    \n",
    "        # é—œéµï¼è™•ç†çµ‚æ­¢è§€å¯Ÿå€¼\n",
    "        if terminated:\n",
    "            info['terminal_observation']  = observation.copy()  \n",
    "    \n",
    "        return observation, reward, terminated, truncated, info\n",
    "\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        self.client_sock.sendall(b\"start\\n\")\n",
    "        terminated, lines, height, holes, observation = self.get_tetris_server_response(self.client_sock)\n",
    "        # é‡ç½®çµ±è¨ˆè®Šæ•¸\n",
    "        self.lines_removed = 0\n",
    "        self.height = 0\n",
    "        self.holes = 0\n",
    "        self.lifetime = 0\n",
    "        return observation, {}\n",
    "\n",
    "    def render(self):\n",
    "        cv2.imshow(\"Tetris\", self.last_observation)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "    def close(self):\n",
    "        self.client_sock.close()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def get_tetris_server_response(self, sock):\n",
    "        is_game_over = (sock.recv(1) == b'\\x01')\n",
    "        removed_lines = int.from_bytes(sock.recv(4), 'big')\n",
    "        height = int.from_bytes(sock.recv(4), 'big')\n",
    "        holes = int.from_bytes(sock.recv(4), 'big')\n",
    "        img_size = int.from_bytes(sock.recv(4), 'big')\n",
    "        img_png = sock.recv(img_size)\n",
    "        nparr = np.frombuffer(img_png, np.uint8)\n",
    "        np_image = cv2.imdecode(nparr, -1)\n",
    "        resized = cv2.resize(np_image, (84, 84))\n",
    "        gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
    "        gray = np.expand_dims(gray, axis=0)  # <- é—œéµï¼channel-first\n",
    "        self.last_observation = gray.copy()\n",
    "        return is_game_over, removed_lines, height, holes, gray\n",
    "    \n",
    "\n",
    "        \n",
    "# æª¢æŸ¥ç’°å¢ƒ\n",
    "print(\"âœ… å»ºç«‹ç’°å¢ƒé–‹å§‹\")\n",
    "env = TetrisEnv()\n",
    "check_env(env)\n",
    "\n",
    "# ----------------------------\n",
    "# å»ºç«‹è¨“ç·´ç’°å¢ƒï¼ˆä½¿ç”¨å‘é‡åŒ–ã€å¤šå€‹ envï¼‰ä¸¦åŠ å…¥æ­£è¦åŒ–èˆ‡ frame stacking\n",
    "# é€™éƒ¨åˆ†ä¸»è¦ç”¨æ–¼åŠ é€Ÿä¸¦ç©©å®šè¨“ç·´\n",
    "# train_env = make_vec_env(TetrisEnv, n_envs=3)\n",
    "# train_env = VecNormalize(train_env, norm_obs=False, norm_reward=True)\n",
    "# train_env = VecFrameStack(train_env, n_stack=4, channels_order='first')\n",
    "train_env = DummyVecEnv([lambda: TetrisEnv()])\n",
    "train_env = VecFrameStack(train_env, n_stack=4, channels_order=\"first\")\n",
    "\n",
    "# ----------------------------\n",
    "# ä½¿ç”¨ DQN é€²è¡Œè¨“ç·´ï¼Œèª¿æ•´è¶…åƒæ•¸ä»¥æå‡æ•ˆèƒ½ï¼š\n",
    "# é€™è£¡è¨­å®š buffer_sizeã€learning_startsã€target_update_interval ç­‰åƒæ•¸\n",
    "model = DQN(\"CnnPolicy\", train_env, verbose=1, tensorboard_log=\"./sb3_log/\",\n",
    "            gamma=0.95,\n",
    "            learning_rate=1e-4,         # è¼ƒä½çš„å­¸ç¿’ç‡æœ‰åŠ©æ–¼ç©©å®šæ”¶æ–‚\n",
    "            buffer_size=20000,         # ç¶“é©—å›æ”¾ç·©è¡å€å¤§å°\n",
    "            learning_starts=1000,       # å¤šå°‘æ­¥å¾Œé–‹å§‹å­¸ç¿’\n",
    "            policy_kwargs=dict(normalize_images=False),\n",
    "            target_update_interval=1000 # ç›®æ¨™ç¶²è·¯æ›´æ–°é »ç‡\n",
    "           )\n",
    "write_log(\"Model device: \" + str(model.device))\n",
    "# model.learn(total_timesteps=100000)  # å¯æ ¹æ“šéœ€è¦å»¶é•· timesteps1000000\n",
    "reward_logger = RewardLoggerCallback(log_path=\"./reward_log.txt\")\n",
    "model.learn(total_timesteps=5000000, callback=reward_logger)\n",
    "\n",
    "# å„²å­˜è¨“ç·´å¾Œçš„æ¨¡å‹ï¼ˆè¨“ç·´å®Œç•¢å¾Œå¯å…ˆæš«åœ train_env çš„æ­¸ä¸€åŒ–æ›´æ–°ï¼‰\n",
    "train_env.training = False\n",
    "\n",
    "# ----------------------------\n",
    "# åŒ…è£æ¸¬è©¦ç’°å¢ƒï¼Œä½†åƒ…ç”¨ä¾†ç¬¦åˆ predict æ ¼å¼ï¼Œå–å½±åƒé‚„æ˜¯å¾åŸç”Ÿç’°å¢ƒæ‹¿\n",
    "# wrapped_test_env = make_vec_env(TetrisEnv, n_envs=1)\n",
    "# wrapped_test_env = VecNormalize(wrapped_test_env, norm_obs=False, norm_reward=False, training=False)\n",
    "# wrapped_test_env = VecFrameStack(wrapped_test_env, n_stack=4, channels_order='first')\n",
    "wrapped_test_env = DummyVecEnv([lambda: TetrisEnv()])\n",
    "wrapped_test_env = VecFrameStack(wrapped_test_env, n_stack=4, channels_order=\"first\")\n",
    "\n",
    "# åŸå§‹ç’°å¢ƒä¿ç•™ç”¨ä¾†å–å½±åƒ\n",
    "raw_test_env = TetrisEnv()\n",
    "\n",
    "# åˆå§‹åŒ–ç‹€æ…‹\n",
    "wrapped_obs = wrapped_test_env.reset()\n",
    "raw_obs, _ = raw_test_env.reset()\n",
    "\n",
    "frames = []\n",
    "total_test_reward = 0\n",
    "test_steps = 1000\n",
    "\n",
    "for step in range(test_steps):\n",
    "    action, _ = model.predict(wrapped_obs, deterministic=True)\n",
    "\n",
    "    # åŸ·è¡Œå‹•ä½œ\n",
    "    next_raw_obs, reward, done, truncated, info = raw_test_env.step(action)\n",
    "    wrapped_obs, _, _, _ = wrapped_test_env.step(action)\n",
    "\n",
    "    total_test_reward += reward\n",
    "    frames.append(np.expand_dims(raw_obs.copy(), axis=0))\n",
    "    # frames.append(raw_obs.copy())  # å„²å­˜åŸå§‹å½±åƒ\n",
    "    raw_obs = next_raw_obs\n",
    "\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "write_log(\"Test completed: Total reward = \" + str(total_test_reward))\n",
    "\n",
    "# å°‡å›æ”¾å½±åƒå­˜å…¥è³‡æ–™å¤¾ï¼ˆä¾è€å¸«æ ¼å¼ï¼‰\n",
    "replay_folder = './replay'\n",
    "if os.path.exists(replay_folder):\n",
    "    shutil.rmtree(replay_folder)\n",
    "os.makedirs(replay_folder, exist_ok=True)\n",
    "episode_folder = os.path.join(replay_folder, \"0\", \"0\")\n",
    "os.makedirs(episode_folder, exist_ok=True)\n",
    "for i, frame in enumerate(frames):\n",
    "    fname = os.path.join(episode_folder, '{:06d}.png'.format(i))\n",
    "    cv2.imwrite(fname,frame[0].squeeze())\n",
    "\n",
    "# ç”¢ç”Ÿ replay GIFï¼ˆæœ€ä½³å›æ”¾ï¼‰\n",
    "filenames = sorted(glob.glob(episode_folder + '/*.png'))\n",
    "gif_images = []\n",
    "for filename in filenames:\n",
    "    gif_images.append(imageio.imread(filename))\n",
    "imageio.mimsave('replay.gif', gif_images, loop=0)\n",
    "print(\"Replay GIF saved: replay.gif\")\n",
    "display(FileLink('replay.gif'))\n",
    "\n",
    "# å°‡æ¸¬è©¦çµæœå¯«å…¥ CSVï¼ˆæ ¼å¼èˆ‡è€å¸«ç‰ˆæœ¬ä¸€è‡´ï¼‰\n",
    "with open('tetris_best_score_test2.csv', 'w') as fs:\n",
    "    fs.write('id,removed_lines,played_steps\\n')\n",
    "    fs.write(f'0,{info[\"removed_lines\"]},{info[\"lifetime\"]}\\n')\n",
    "    fs.write(f'1,{info[\"removed_lines\"]},{info[\"lifetime\"]}\\n')\n",
    "print(\"CSV file saved: tetris_best_score_test2.csv\")\n",
    "display(FileLink('tetris_best_score_test2.csv'))\n",
    "wandb.save('tetris_best_score_test2.csv')\n",
    "\n",
    "# ----------------------------\n",
    "# å„²å­˜æœ€çµ‚æ¨¡å‹ï¼ˆè«‹ç¢ºèªå°‡ '113598065' æ›¿æ›æˆä½ çš„å­¸è™Ÿï¼‰\n",
    "model.save('113598065_dqn_30env_1M.zip')\n",
    "print(\"Model saved: 113598065_dqn_30env_1M.zip\")\n",
    "display(FileLink('113598065_dqn_30env_1M.zip'))\n",
    "wandb.save('113598065_dqn_30env_1M.zip')\n",
    "\n",
    "# é—œé–‰ç’°å¢ƒ\n",
    "wrapped_test_env.close()\n",
    "raw_test_env.close()\n",
    "train_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import socket\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import imageio\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import VecNormalize, VecFrameStack, DummyVecEnv\n",
    "from IPython.display import FileLink, display, Image\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# --- Wandb Setup ---\n",
    "import os\n",
    "import wandb\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "# Import WandbCallback for SB3 integration\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "# å¾ Kaggle Secrets è®€å– API Token\n",
    "user_secrets = UserSecretsClient()\n",
    "WANDB_API_KEY = user_secrets.get_secret(\"WANDB_API_KEY\")\n",
    "\n",
    "# è¨­å®šç’°å¢ƒè®Šæ•¸ï¼Œæ¨¡æ“¬ login\n",
    "os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY\n",
    "\n",
    "# login & init\n",
    "wandb.login()\n",
    "# Start a wandb run\n",
    "run = wandb.init(\n",
    "    project=\"tetris-training-improved\", # Changed project name slightly\n",
    "    entity=\"t113598065-ntut-edu-tw\",\n",
    "    sync_tensorboard=True,  # auto-upload sb3 logs\n",
    "    monitor_gym=True,       # auto-upload videos and plots\n",
    "    save_code=True,         # save script to wandb\n",
    "    config={ # Log hyperparameters\n",
    "        \"policy_type\": \"CnnPolicy\",\n",
    "        \"total_timesteps\": 2000000, # Example: increased timesteps\n",
    "        \"env_id\": \"TetrisEnv-v1\",\n",
    "        \"gamma\": 0.99, # Increased gamma\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"buffer_size\": 300000, # Increased buffer size\n",
    "        \"learning_starts\": 10000, # Increased learning starts\n",
    "        \"target_update_interval\": 10000, # Increased target update interval\n",
    "        \"exploration_fraction\": 0.6, # Explore for 60% of training\n",
    "        \"exploration_final_eps\": 0.05, # Lower final epsilon\n",
    "        \"batch_size\": 32, # Default for DQN, can be tuned\n",
    "        \"n_stack\": 4, # Frame stacking\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "log_path = \"/kaggle/working/tetris_train_log.txt\"\n",
    "\n",
    "def write_log(message):\n",
    "    \"\"\"Appends a message to the log file and prints it.\"\"\"\n",
    "    with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"{time.strftime('%Y-%m-%d %H:%M:%S')} - {message}\\n\")\n",
    "    print(message)\n",
    "\n",
    "def wait_for_tetris_server(ip=\"127.0.0.1\", port=10612, timeout=60):\n",
    "    \"\"\"Waits for the Tetris TCP server to become available.\"\"\"\n",
    "    write_log(f\"â³ ç­‰å¾… Tetris TCP server å•Ÿå‹•ä¸­ ({ip}:{port})...\")\n",
    "    start_time = time.time()\n",
    "    while True:\n",
    "        try:\n",
    "            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as test_sock:\n",
    "                test_sock.settimeout(1.0)\n",
    "                test_sock.connect((ip, port))\n",
    "            write_log(\"âœ… Java TCP server æº–å‚™å®Œæˆï¼Œé€£ç·šæˆåŠŸ\")\n",
    "            break\n",
    "        except socket.error as e:\n",
    "            if time.time() - start_time > timeout:\n",
    "                raise TimeoutError(f\"âŒ ç­‰å¾… Java TCP server è¶…æ™‚ ({timeout}s)\")\n",
    "            # write_log(f\"   é€£æ¥å¤±æ•— ({e}), é‡è©¦ä¸­...\") # Optional: more verbose logging\n",
    "            time.sleep(1.0) # Wait a bit longer before retrying\n",
    "\n",
    "# --- Start Java Server ---\n",
    "try:\n",
    "    write_log(\"ğŸš€ å˜—è©¦å•Ÿå‹• Java Tetris server...\")\n",
    "    # Ensure the JAR file exists\n",
    "    jar_file = \"TetrisTCPserver_v0.6.jar\"\n",
    "    if not os.path.exists(jar_file):\n",
    "         write_log(f\"âŒ éŒ¯èª¤: æ‰¾ä¸åˆ° JAR æª”æ¡ˆ '{jar_file}'ã€‚è«‹ç¢ºä¿å®ƒåœ¨å·¥ä½œç›®éŒ„ä¸­ã€‚\")\n",
    "         # Handle error appropriately, maybe exit\n",
    "         raise FileNotFoundError(f\"JAR file '{jar_file}' not found.\")\n",
    "\n",
    "    process = subprocess.Popen([\"java\", \"-jar\", jar_file], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    write_log(f\"âœ… Java server process å•Ÿå‹• (PID: {process.pid})\")\n",
    "    wait_for_tetris_server()\n",
    "except Exception as e:\n",
    "    write_log(f\"âŒ å•Ÿå‹•æˆ–ç­‰å¾… Java server æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
    "    # Optionally log process output if it failed\n",
    "    if 'process' in locals() and process.poll() is not None:\n",
    "        stdout, stderr = process.communicate()\n",
    "        write_log(f\"   Java Server STDOUT: {stdout.decode('utf-8', errors='ignore')}\")\n",
    "        write_log(f\"   Java Server STDERR: {stderr.decode('utf-8', errors='ignore')}\")\n",
    "    raise # Re-raise the exception to stop the script\n",
    "\n",
    "# --- Check GPU ---\n",
    "if torch.cuda.is_available():\n",
    "    write_log(f\"âœ… PyTorch is using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    write_log(\"âš ï¸ PyTorch is using CPU. Training will be significantly slower.\")\n",
    "\n",
    "# ----------------------------\n",
    "# å®šç¾© Tetris ç’°å¢ƒ (æ¡ç”¨è€å¸«çš„æ ¼å¼, çµåˆçå‹µæ©Ÿåˆ¶æ¦‚å¿µ)\n",
    "# ----------------------------\n",
    "class TetrisEnv(gym.Env):\n",
    "    \"\"\"Custom Environment for Tetris that interacts with a Java TCP server.\"\"\"\n",
    "    metadata = {\"render_modes\": [\"human\", \"rgb_array\"], \"render_fps\": 30} # Added rgb_array for potential recording\n",
    "    N_DISCRETE_ACTIONS = 5  # 0: left, 1: right, 2: rot_left, 3: rot_right, 4: drop\n",
    "    IMG_HEIGHT = 200 # Original image height from server (used for decoding)\n",
    "    IMG_WIDTH = 100  # Original image width from server (used for decoding)\n",
    "    IMG_CHANNELS = 3 # Original image channels\n",
    "    RESIZED_DIM = 84 # Dimension for resized observation\n",
    "\n",
    "    def __init__(self, host_ip=\"127.0.0.1\", host_port=10612, render_mode=None):\n",
    "        super().__init__()\n",
    "        self.render_mode = render_mode\n",
    "        self.action_space = spaces.Discrete(self.N_DISCRETE_ACTIONS)\n",
    "        # Observation space: Grayscale image, channel-first (needed for CnnPolicy)\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0, high=255,\n",
    "            shape=(1, self.RESIZED_DIM, self.RESIZED_DIM), # (Channels, Height, Width)\n",
    "            dtype=np.uint8\n",
    "        )\n",
    "        self.server_ip = host_ip\n",
    "        self.server_port = host_port\n",
    "        self.client_sock = None # Initialize socket to None\n",
    "        self._connect_socket() # Connect in init\n",
    "\n",
    "        # Reward shaping & statistics variables\n",
    "        self.current_score = 0 # Keep track of raw game score if needed\n",
    "        self.lines_removed = 0\n",
    "        self.current_height = 0\n",
    "        self.current_holes = 0\n",
    "        self.lifetime = 0\n",
    "        self.last_observation = np.zeros(self.observation_space.shape, dtype=np.uint8) # Store last obs\n",
    "\n",
    "        # --- Reward Shaping Coefficients (Tuning is crucial!) ---\n",
    "        self.reward_line_clear_coeff = 100.0 # Base reward per line squared\n",
    "        self.penalty_height_increase_coeff = 15.0 # Penalty for increasing max height\n",
    "        self.penalty_hole_increase_coeff = 25.0 # Penalty for creating new holes\n",
    "        self.penalty_step_coeff = 0.1 # Small penalty per step to encourage speed\n",
    "        self.penalty_game_over_coeff = 500.0 # Large penalty for losing\n",
    "\n",
    "        # For rendering\n",
    "        self.window = None\n",
    "        self.clock = None\n",
    "\n",
    "\n",
    "    def _connect_socket(self):\n",
    "        \"\"\"Establishes connection to the game server.\"\"\"\n",
    "        try:\n",
    "            # Close existing socket if any before reconnecting\n",
    "            if self.client_sock:\n",
    "                self.client_sock.close()\n",
    "            self.client_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "            # Set a timeout for socket operations to prevent indefinite blocking\n",
    "            self.client_sock.settimeout(10.0) # 10 seconds timeout\n",
    "            self.client_sock.connect((self.server_ip, self.server_port))\n",
    "            write_log(f\"ğŸ”Œ Socket connected to {self.server_ip}:{self.server_port}\")\n",
    "        except socket.error as e:\n",
    "            write_log(f\"âŒ Socket connection error during connect: {e}\")\n",
    "            raise # Re-raise to indicate failure\n",
    "\n",
    "    def _send_command(self, command: bytes):\n",
    "        \"\"\"Sends a command to the server, handles potential errors.\"\"\"\n",
    "        try:\n",
    "            self.client_sock.sendall(command)\n",
    "        except socket.timeout:\n",
    "            write_log(\"âŒ Socket timeout during send.\")\n",
    "            raise ConnectionAbortedError(\"Socket timeout during send\")\n",
    "        except socket.error as e:\n",
    "            write_log(f\"âŒ Socket error during send: {e}\")\n",
    "            # Attempt to reconnect on send error? Could be risky. Better to fail.\n",
    "            raise ConnectionAbortedError(f\"Socket error during send: {e}\")\n",
    "\n",
    "    def _receive_data(self, size):\n",
    "        \"\"\"Receives exactly size bytes from the server.\"\"\"\n",
    "        data = b\"\"\n",
    "        while len(data) < size:\n",
    "            try:\n",
    "                chunk = self.client_sock.recv(size - len(data))\n",
    "                if not chunk:\n",
    "                    write_log(\"âŒ Socket connection broken during receive (received empty chunk).\")\n",
    "                    raise ConnectionAbortedError(\"Socket connection broken\")\n",
    "                data += chunk\n",
    "            except socket.timeout:\n",
    "                 write_log(f\"âŒ Socket timeout during receive (expected {size}, got {len(data)}).\")\n",
    "                 raise ConnectionAbortedError(\"Socket timeout during receive\")\n",
    "            except socket.error as e:\n",
    "                write_log(f\"âŒ Socket error during receive: {e}\")\n",
    "                raise ConnectionAbortedError(f\"Socket error during receive: {e}\")\n",
    "        return data\n",
    "\n",
    "    def get_tetris_server_response(self):\n",
    "        \"\"\"Gets state update from the Tetris server via socket.\"\"\"\n",
    "        try:\n",
    "            is_game_over_byte = self._receive_data(1)\n",
    "            is_game_over = (is_game_over_byte == b'\\x01')\n",
    "\n",
    "            removed_lines_bytes = self._receive_data(4)\n",
    "            removed_lines = int.from_bytes(removed_lines_bytes, 'big')\n",
    "\n",
    "            height_bytes = self._receive_data(4)\n",
    "            height = int.from_bytes(height_bytes, 'big')\n",
    "\n",
    "            holes_bytes = self._receive_data(4)\n",
    "            holes = int.from_bytes(holes_bytes, 'big')\n",
    "\n",
    "            img_size_bytes = self._receive_data(4)\n",
    "            img_size = int.from_bytes(img_size_bytes, 'big')\n",
    "\n",
    "            # Ensure image size is reasonable to prevent memory issues\n",
    "            if img_size <= 0 or img_size > 500000: # Set a reasonable max size (e.g., 500KB)\n",
    "                 write_log(f\"âŒ Received invalid image size: {img_size}. Aborting receive.\")\n",
    "                 raise ValueError(f\"Invalid image size received: {img_size}\")\n",
    "\n",
    "            img_png = self._receive_data(img_size)\n",
    "\n",
    "            # Decode and preprocess image\n",
    "            nparr = np.frombuffer(img_png, np.uint8)\n",
    "            # Use IMREAD_COLOR to ensure 3 channels even if image is grayscale upstream\n",
    "            np_image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "            if np_image is None:\n",
    "                 write_log(\"âŒ Failed to decode image from server response.\")\n",
    "                 # Return a default observation or raise error\n",
    "                 # Using last observation as fallback might be problematic\n",
    "                 # raise ValueError(\"Failed to decode image\")\n",
    "                 # Let's return the last known good observation and signal game over potentially\n",
    "                 return True, self.lines_removed, self.current_height, self.current_holes, self.last_observation.copy()\n",
    "\n",
    "\n",
    "            resized = cv2.resize(np_image, (self.RESIZED_DIM, self.RESIZED_DIM), interpolation=cv2.INTER_AREA)\n",
    "            gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
    "            # Add channel dimension: (H, W) -> (1, H, W) for PyTorch Conv2D (channel-first)\n",
    "            observation = np.expand_dims(gray, axis=0)\n",
    "            # Ensure dtype is uint8 for the observation space\n",
    "            observation = observation.astype(np.uint8)\n",
    "\n",
    "            # Store the raw BGR resized image for rendering if needed\n",
    "            self.last_raw_render_frame = resized.copy()\n",
    "            # Store the processed observation\n",
    "            self.last_observation = observation.copy()\n",
    "\n",
    "            return is_game_over, removed_lines, height, holes, observation\n",
    "\n",
    "        except ConnectionAbortedError as e:\n",
    "             write_log(f\"âŒ Connection aborted while getting server response: {e}\")\n",
    "             # Attempt to reconnect? Or just end the episode. Let's end it.\n",
    "             # Return a state indicating termination and use the last valid observation\n",
    "             return True, self.lines_removed, self.current_height, self.current_holes, self.last_observation.copy()\n",
    "        except Exception as e:\n",
    "            write_log(f\"âŒ Unexpected error getting server response: {e}\")\n",
    "             # End the episode on unexpected errors\n",
    "            return True, self.lines_removed, self.current_height, self.current_holes, self.last_observation.copy()\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        # --- Send Action ---\n",
    "        if action == 0:\n",
    "            command = b\"move -1\\n\"\n",
    "        elif action == 1:\n",
    "            command = b\"move 1\\n\"\n",
    "        elif action == 2:\n",
    "            command = b\"rotate 0\\n\" # Assuming 0 is one direction (e.g., left/ccw)\n",
    "        elif action == 3:\n",
    "            command = b\"rotate 1\\n\" # Assuming 1 is other direction (e.g., right/cw)\n",
    "        elif action == 4:\n",
    "            command = b\"drop\\n\"\n",
    "        else:\n",
    "            write_log(f\"âš ï¸ Invalid action received: {action}. Sending 'drop'.\")\n",
    "            command = b\"drop\\n\" # Default safe action? Or raise error?\n",
    "\n",
    "        try:\n",
    "            self._send_command(command)\n",
    "        except ConnectionAbortedError:\n",
    "            # If sending fails, the episode must end.\n",
    "            write_log(\"âŒ Ending episode due to send failure in step.\")\n",
    "            terminated = True\n",
    "            # Use last known state for observation, provide zero reward.\n",
    "            observation = self.last_observation.copy()\n",
    "            reward = self.penalty_game_over_coeff * -1 # Penalize heavily\n",
    "            info = {'removed_lines': self.lines_removed, 'lifetime': self.lifetime, 'final_status': 'send_error'}\n",
    "            # SB3 expects terminal_observation in info if terminated\n",
    "            info['terminal_observation'] = observation\n",
    "            return observation, reward, terminated, False, info # terminated=True, truncated=False\n",
    "\n",
    "        # --- Get State Update ---\n",
    "        terminated, new_lines_removed, new_height, new_holes, observation = self.get_tetris_server_response()\n",
    "\n",
    "        # --- Calculate Reward ---\n",
    "        reward = 0.0\n",
    "\n",
    "        # 1. Line Clear Reward (Quadratic)\n",
    "        lines_cleared_this_step = new_lines_removed - self.lines_removed\n",
    "        if lines_cleared_this_step > 0:\n",
    "            # Quadratic reward emphasizes clearing multiple lines\n",
    "            reward += (lines_cleared_this_step ** 2) * self.reward_line_clear_coeff\n",
    "            # Bonus for Tetris (4 lines)? Optional.\n",
    "            # if lines_cleared_this_step == 4:\n",
    "            #    reward += 1000 # Large bonus\n",
    "\n",
    "        # 2. Height Increase Penalty\n",
    "        height_increase = new_height - self.current_height\n",
    "        if height_increase > 0:\n",
    "            reward -= height_increase * self.penalty_height_increase_coeff\n",
    "\n",
    "        # 3. Hole Increase Penalty\n",
    "        hole_increase = new_holes - self.current_holes\n",
    "        if hole_increase > 0:\n",
    "            reward -= hole_increase * self.penalty_hole_increase_coeff\n",
    "        # Optional: Small reward for *filling* holes?\n",
    "        # elif hole_increase < 0:\n",
    "        #    reward += abs(hole_increase) * (self.penalty_hole_increase_coeff / 2)\n",
    "\n",
    "\n",
    "        # 4. Step Penalty (encourages efficiency)\n",
    "        reward -= self.penalty_step_coeff\n",
    "\n",
    "        # 5. Game Over Penalty\n",
    "        if terminated:\n",
    "            reward -= self.penalty_game_over_coeff\n",
    "            write_log(f\"ğŸ’” Game Over! Final Lines: {new_lines_removed}, Lifetime: {self.lifetime + 1}\")\n",
    "\n",
    "\n",
    "        # --- Update Internal State ---\n",
    "        self.lines_removed = new_lines_removed\n",
    "        self.current_height = new_height\n",
    "        self.current_holes = new_holes\n",
    "        self.lifetime += 1\n",
    "\n",
    "        # --- Prepare Return Values ---\n",
    "        info = {'removed_lines': self.lines_removed, 'lifetime': self.lifetime}\n",
    "        truncated = False # We use terminated based on the game's state\n",
    "\n",
    "        # IMPORTANT: Provide terminal observation in info when terminated\n",
    "        # This is required by SB3 for correct value estimation at episode end\n",
    "        if terminated:\n",
    "            info['terminal_observation'] = observation.copy()\n",
    "            # Log final stats to wandb if needed (can also be done in callback)\n",
    "            # wandb.log({\"final/lines_removed\": self.lines_removed, \"final/lifetime\": self.lifetime})\n",
    "\n",
    "        return observation, reward, terminated, truncated, info\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed) # Important for Gym compatibility\n",
    "\n",
    "        # Ensure connection is alive, reconnect if needed\n",
    "        try:\n",
    "            # Simple check: send 'start' and see if we get a response without error\n",
    "             self._send_command(b\"start\\n\")\n",
    "             # Initial state read\n",
    "             terminated, lines, height, holes, observation = self.get_tetris_server_response()\n",
    "             if terminated: # Should not be terminated on reset, indicates server issue\n",
    "                 write_log(\"âš ï¸ Server reported game over immediately after reset. Attempting reconnect and reset again.\")\n",
    "                 self._connect_socket() # Reconnect\n",
    "                 self._send_command(b\"start\\n\") # Try starting again\n",
    "                 terminated, lines, height, holes, observation = self.get_tetris_server_response()\n",
    "                 if terminated:\n",
    "                      write_log(\"âŒ Server still terminated after reset/reconnect. Cannot proceed.\")\n",
    "                      raise RuntimeError(\"Tetris server failed to reset properly.\")\n",
    "\n",
    "        except (ConnectionAbortedError, socket.error, TimeoutError) as e:\n",
    "             write_log(f\"ğŸ”Œ Connection issue during reset ({e}). Attempting reconnect...\")\n",
    "             self._connect_socket() # Re-establish connection\n",
    "             self._send_command(b\"start\\n\") # Send start command again\n",
    "             terminated, lines, height, holes, observation = self.get_tetris_server_response() # Get initial state\n",
    "             # Check again if terminated immediately\n",
    "             if terminated:\n",
    "                 write_log(\"âŒ Server terminated immediately after reset/reconnect. Cannot proceed.\")\n",
    "                 raise RuntimeError(\"Tetris server failed to reset properly after reconnect.\")\n",
    "\n",
    "\n",
    "        # Reset internal statistics\n",
    "        self.lines_removed = 0\n",
    "        self.current_height = height # Initial height from server\n",
    "        self.current_holes = holes   # Initial holes from server\n",
    "        self.lifetime = 0\n",
    "        self.last_observation = observation.copy() # Store initial observation\n",
    "\n",
    "        write_log(f\"ğŸ”„ Environment Reset. Initial state: H={height}, O={holes}\")\n",
    "\n",
    "        info = {} # No extra info needed on reset by default\n",
    "        return observation, info\n",
    "\n",
    "    def render(self):\n",
    "         # Render using the stored raw frame suitable for display\n",
    "         if self.render_mode == \"human\":\n",
    "             if self.window is None:\n",
    "                 pygame.init()\n",
    "                 pygame.display.init()\n",
    "                 self.window = pygame.display.set_mode((self.RESIZED_DIM * 3, self.RESIZED_DIM * 3)) # Upscale a bit\n",
    "                 pygame.display.set_caption(\"Tetris Env\")\n",
    "             if self.clock is None:\n",
    "                 self.clock = pygame.time.Clock()\n",
    "\n",
    "             # Need a surface to display the BGR image correctly\n",
    "             # self.last_raw_render_frame should be (H, W, C) BGR\n",
    "             if hasattr(self, 'last_raw_render_frame'):\n",
    "                 # Pygame uses RGB, OpenCV uses BGR. Need conversion.\n",
    "                 render_frame_rgb = cv2.cvtColor(self.last_raw_render_frame, cv2.COLOR_BGR2RGB)\n",
    "                 # Pygame surface requires (width, height)\n",
    "                 surf = pygame.Surface((self.RESIZED_DIM, self.RESIZED_DIM))\n",
    "                 # Transpose is needed if axes are wrong, check render_frame_rgb shape\n",
    "                 pygame.surfarray.blit_array(surf, np.transpose(render_frame_rgb, (1, 0, 2)))\n",
    "                 surf = pygame.transform.scale(surf, (self.RESIZED_DIM * 3, self.RESIZED_DIM * 3)) # Scale up\n",
    "                 self.window.blit(surf, (0, 0))\n",
    "                 pygame.event.pump()\n",
    "                 self.clock.tick(self.metadata[\"render_fps\"])\n",
    "                 pygame.display.flip()\n",
    "             else:\n",
    "                 # Draw a blank screen if no frame available yet\n",
    "                  self.window.fill((0,0,0))\n",
    "                  pygame.display.flip()\n",
    "\n",
    "\n",
    "         elif self.render_mode == \"rgb_array\":\n",
    "              # Return the last processed observation (channel first) or raw render frame\n",
    "              # Returning the processed observation might be more useful if logging video\n",
    "              # return self.last_observation # Shape (1, H, W)\n",
    "              # Or return the displayable frame\n",
    "              if hasattr(self, 'last_raw_render_frame'):\n",
    "                  return cv2.cvtColor(self.last_raw_render_frame, cv2.COLOR_BGR2RGB) # Return RGB (H, W, C)\n",
    "              else:\n",
    "                  return np.zeros((self.RESIZED_DIM, self.RESIZED_DIM, 3), dtype=np.uint8) # Return black frame\n",
    "\n",
    "\n",
    "    def close(self):\n",
    "        write_log(\"ğŸ”Œ Closing environment connection.\")\n",
    "        if self.client_sock:\n",
    "            try:\n",
    "                # Send a final command? Like 'quit' if the server supports it?\n",
    "                # self.client_sock.sendall(b\"quit\\n\")\n",
    "                self.client_sock.close()\n",
    "                write_log(\"   Socket closed.\")\n",
    "            except socket.error as e:\n",
    "                 write_log(f\"   Error closing socket: {e}\")\n",
    "            self.client_sock = None\n",
    "        # Close pygame window\n",
    "        if self.window is not None:\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n",
    "            self.window = None\n",
    "            write_log(\"   Pygame window closed.\")\n",
    "\n",
    "\n",
    "# --- Environment Setup ---\n",
    "write_log(\"âœ… å»ºç«‹ç’°å¢ƒé–‹å§‹\")\n",
    "\n",
    "# Create a function to instantiate the environment\n",
    "def make_env():\n",
    "    env = TetrisEnv()\n",
    "    return env\n",
    "\n",
    "# Use DummyVecEnv for single environment interaction with the Java server\n",
    "# If you could run multiple servers on different ports, you could use SubprocVecEnv\n",
    "train_env = DummyVecEnv([make_env])\n",
    "\n",
    "# Wrap with VecFrameStack (channel-first order is important for CnnPolicy)\n",
    "train_env = VecFrameStack(train_env, n_stack=run.config[\"n_stack\"], channels_order=\"first\")\n",
    "\n",
    "# Wrap with VecNormalize, NORMALIZING REWARDS ONLY. Observation normalization\n",
    "# should ideally be handled by the policy or done carefully if needed.\n",
    "# Since policy_kwargs has normalize_images=False, we definitely don't normalize obs here.\n",
    "train_env = VecNormalize(train_env, norm_obs=False, norm_reward=True, gamma=run.config[\"gamma\"]) # Pass gamma\n",
    "\n",
    "write_log(\"   ç’°å¢ƒå»ºç«‹å®Œæˆä¸¦å·²åŒ…è£ (DummyVecEnv -> VecFrameStack -> VecNormalize)\")\n",
    "\n",
    "# Check environment (optional but recommended)\n",
    "# Note: check_env doesn't work directly on VecEnv, check the base env if needed\n",
    "# check_env(make_env())\n",
    "# write_log(\"   åŸºç¤ç’°å¢ƒæª¢æŸ¥é€šé\")\n",
    "\n",
    "# ----------------------------\n",
    "# DQN Model Setup and Training\n",
    "# ----------------------------\n",
    "write_log(\"ğŸ§  è¨­å®š DQN æ¨¡å‹...\")\n",
    "\n",
    "# Define DQN model with tuned hyperparameters and Wandb logging\n",
    "model = DQN(\n",
    "    run.config[\"policy_type\"], # \"CnnPolicy\"\n",
    "    train_env,\n",
    "    verbose=1,\n",
    "    tensorboard_log=f\"/kaggle/working/runs/{run.id}\", # Log TensorBoard data for Wandb\n",
    "    gamma=run.config[\"gamma\"],\n",
    "    learning_rate=run.config[\"learning_rate\"],\n",
    "    buffer_size=run.config[\"buffer_size\"],\n",
    "    learning_starts=run.config[\"learning_starts\"],\n",
    "    batch_size=run.config[\"batch_size\"],\n",
    "    train_freq=(1, \"step\"), # Train every step\n",
    "    gradient_steps=1,       # Perform 1 gradient update per training step\n",
    "    target_update_interval=run.config[\"target_update_interval\"],\n",
    "    exploration_fraction=run.config[\"exploration_fraction\"],\n",
    "    exploration_final_eps=run.config[\"exploration_final_eps\"],\n",
    "    policy_kwargs=dict(normalize_images=False), # As per original code\n",
    "    seed=42 # Set seed for reproducibility\n",
    "    # device=\"cuda\" if torch.cuda.is_available() else \"cpu\" # Explicitly set device if needed\n",
    ")\n",
    "write_log(f\"   æ¨¡å‹å»ºç«‹å®Œæˆ. Device: {model.device}\")\n",
    "write_log(f\"   è¶…åƒæ•¸: {run.config}\")\n",
    "\n",
    "\n",
    "# Setup Wandb callback for logging SB3 metrics, gradients, etc.\n",
    "wandb_callback = WandbCallback(\n",
    "    gradient_save_freq=10000, # Save gradients every N steps\n",
    "    model_save_path=f\"/kaggle/working/models/{run.id}\", # Save model checkpoints locally\n",
    "    model_save_freq=50000, # Save model every N steps\n",
    "    log=\"all\", # Log histograms, gradients, etc.\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "\n",
    "# --- Training ---\n",
    "write_log(\"ğŸš€ é–‹å§‹è¨“ç·´...\")\n",
    "try:\n",
    "    model.learn(\n",
    "        total_timesteps=run.config[\"total_timesteps\"],\n",
    "        callback=wandb_callback, # Use Wandb callback\n",
    "        log_interval=10 # Log basic stats (like reward) every 10 episodes to console/wandb\n",
    "    )\n",
    "    write_log(\"âœ… è¨“ç·´å®Œæˆ!\")\n",
    "except Exception as e:\n",
    "     write_log(f\"âŒ è¨“ç·´éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
    "     # Save model before exiting if error occurs mid-training\n",
    "     error_save_path = '/kaggle/working/113598065_dqn_error_save.zip'\n",
    "     model.save(error_save_path)\n",
    "     write_log(f\"   æ¨¡å‹å·²å„²å­˜è‡³ {error_save_path}\")\n",
    "     wandb.save(error_save_path) # Upload to Wandb\n",
    "     run.finish(exit_code=1, quiet=True) # Finish wandb run with error code\n",
    "     raise # Re-raise exception\n",
    "\n",
    "\n",
    "# --- Save Final Model ---\n",
    "# Important: Save VecNormalize statistics before saving the agent\n",
    "# These stats are needed to properly evaluate the trained agent later\n",
    "stats_path = \"/kaggle/working/vecnormalize_stats.pkl\"\n",
    "train_env.save(stats_path)\n",
    "write_log(f\"   VecNormalize çµ±è¨ˆæ•¸æ“šå·²å„²å­˜è‡³ {stats_path}\")\n",
    "wandb.save(stats_path) # Save stats to wandb\n",
    "\n",
    "# Save the final trained model\n",
    "final_model_name = '113598065_dqn_final.zip' # Use a clear name\n",
    "final_model_path = os.path.join(\"/kaggle/working\", final_model_name)\n",
    "model.save(final_model_path)\n",
    "write_log(f\"âœ… æœ€çµ‚æ¨¡å‹å·²å„²å­˜: {final_model_path}\")\n",
    "display(FileLink(final_model_path))\n",
    "wandb.save(final_model_path) # Upload final model to Wandb\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Evaluation (Optional but recommended)\n",
    "# ----------------------------\n",
    "write_log(\"\\nğŸ§ª é–‹å§‹è©•ä¼°è¨“ç·´å¾Œçš„æ¨¡å‹...\")\n",
    "\n",
    "# Create a separate evaluation environment\n",
    "eval_env = DummyVecEnv([make_env])\n",
    "# IMPORTANT: Load the SAME VecNormalize statistics saved during training\n",
    "# Use training=False to disable updates to the running stats\n",
    "eval_env = VecNormalize.load(stats_path, eval_env)\n",
    "eval_env.training = False # Do not update stats\n",
    "eval_env.norm_reward = False # Do not normalize rewards during evaluation for true score\n",
    "\n",
    "# Wrap with FrameStack, same as training\n",
    "eval_env = VecFrameStack(eval_env, n_stack=run.config[\"n_stack\"], channels_order=\"first\")\n",
    "\n",
    "# Load the trained model (optional, could just use 'model')\n",
    "# loaded_model = DQN.load(final_model_path, env=eval_env) # Load model with eval env if needed\n",
    "\n",
    "# --- Run Evaluation Episodes ---\n",
    "num_eval_episodes = 5\n",
    "total_rewards = []\n",
    "total_lines = []\n",
    "total_lifetimes = []\n",
    "all_frames = [] # Store frames for one episode's GIF\n",
    "\n",
    "for i in range(num_eval_episodes):\n",
    "    obs = eval_env.reset()\n",
    "    done = False\n",
    "    episode_reward = 0\n",
    "    episode_lines = 0\n",
    "    episode_lifetime = 0\n",
    "    frames = []\n",
    "    last_info = {}\n",
    "\n",
    "    while not done:\n",
    "        # Get the raw observation for rendering/saving GIF if needed\n",
    "        # Access the underlying environment's last raw frame\n",
    "        # This assumes DummyVecEnv and accesses the first (and only) env\n",
    "        # Be careful if using SubprocVecEnv\n",
    "        raw_frame = eval_env.envs[0].render(mode=\"rgb_array\")\n",
    "        if i == 0: # Only save frames for the first evaluation episode\n",
    "             frames.append(raw_frame)\n",
    "\n",
    "        # Use deterministic=True for consistent evaluation actions\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, infos = eval_env.step(action)\n",
    "\n",
    "        # Note: reward here is the unnormalized reward because eval_env.norm_reward = False\n",
    "        episode_reward += reward[0] # VecEnv returns lists\n",
    "        last_info = infos[0] # Get info from the single env\n",
    "        episode_lines = last_info.get('removed_lines', 0) # Get final lines from info\n",
    "        episode_lifetime = last_info.get('lifetime', 0)   # Get final lifetime from info\n",
    "\n",
    "        # Handle VecEnv done signal (it's an array)\n",
    "        done = done[0]\n",
    "\n",
    "\n",
    "    write_log(f\"   è©•ä¼° Episode {i+1}: Reward={episode_reward:.2f}, Lines={episode_lines}, Steps={episode_lifetime}\")\n",
    "    total_rewards.append(episode_reward)\n",
    "    total_lines.append(episode_lines)\n",
    "    total_lifetimes.append(episode_lifetime)\n",
    "    if i == 0:\n",
    "        all_frames = frames # Keep frames from first episode\n",
    "\n",
    "write_log(f\"--- è©•ä¼°çµæœ ({num_eval_episodes} episodes) ---\")\n",
    "write_log(f\"   å¹³å‡ Reward: {np.mean(total_rewards):.2f} +/- {np.std(total_rewards):.2f}\")\n",
    "write_log(f\"   å¹³å‡ Lines: {np.mean(total_lines):.2f} +/- {np.std(total_lines):.2f}\")\n",
    "write_log(f\"   å¹³å‡ Steps: {np.mean(total_lifetimes):.2f} +/- {np.std(total_lifetimes):.2f}\")\n",
    "\n",
    "# Log evaluation metrics to Wandb\n",
    "wandb.log({\n",
    "    \"eval/mean_reward\": np.mean(total_rewards),\n",
    "    \"eval/std_reward\": np.std(total_rewards),\n",
    "    \"eval/mean_lines\": np.mean(total_lines),\n",
    "    \"eval/std_lines\": np.std(total_lines),\n",
    "    \"eval/mean_lifetime\": np.mean(total_lifetimes),\n",
    "    \"eval/std_lifetime\": np.std(total_lifetimes),\n",
    "})\n",
    "\n",
    "\n",
    "# --- Generate Replay GIF (from first evaluation episode) ---\n",
    "if all_frames:\n",
    "    gif_path = '/kaggle/working/replay_eval.gif'\n",
    "    write_log(f\"ğŸ’¾ æ­£åœ¨å„²å­˜è©•ä¼°å›æ”¾ GIF è‡³ {gif_path}...\")\n",
    "    try:\n",
    "        # Ensure frames are uint8\n",
    "        imageio.mimsave(gif_path, [np.array(frame).astype(np.uint8) for frame in all_frames], fps=15, loop=0)\n",
    "        write_log(\"   GIF å„²å­˜æˆåŠŸ.\")\n",
    "        display(FileLink(gif_path))\n",
    "        # Log the GIF to Wandb\n",
    "        wandb.log({\"eval/replay\": wandb.Video(gif_path, fps=15, format=\"gif\")})\n",
    "    except Exception as e:\n",
    "        write_log(f\"   âŒ å„²å­˜ GIF æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
    "else:\n",
    "     write_log(\"   âš ï¸ æœªèƒ½å„²å­˜ GIF (æ²’æœ‰æ”¶é›†åˆ°å¹€).\")\n",
    "\n",
    "\n",
    "# --- Save Evaluation Results CSV ---\n",
    "csv_filename = 'tetris_evaluation_scores.csv'\n",
    "csv_path = os.path.join(\"/kaggle/working\", csv_filename)\n",
    "try:\n",
    "    with open(csv_path, 'w') as fs:\n",
    "        fs.write('episode_id,removed_lines,played_steps,reward\\n')\n",
    "        # Use stats from the first episode for the format you requested\n",
    "        # Ideally, log all episodes or averages\n",
    "        fs.write(f'eval_0,{total_lines[0]},{total_lifetimes[0]},{total_rewards[0]:.2f}\\n')\n",
    "        # Add more lines if needed, e.g., for averages or best episode\n",
    "        fs.write(f'eval_avg,{np.mean(total_lines):.2f},{np.mean(total_lifetimes):.2f},{np.mean(total_rewards):.2f}\\n')\n",
    "    write_log(f\"âœ… è©•ä¼°åˆ†æ•¸ CSV å·²å„²å­˜: {csv_path}\")\n",
    "    display(FileLink(csv_path))\n",
    "    wandb.save(csv_path) # Upload CSV to Wandb\n",
    "except Exception as e:\n",
    "    write_log(f\"   âŒ å„²å­˜ CSV æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
    "\n",
    "\n",
    "# --- Cleanup ---\n",
    "write_log(\"ğŸ§¹ æ¸…ç†ç’°å¢ƒ...\")\n",
    "eval_env.close()\n",
    "train_env.close() # Close training env as well\n",
    "# Close the Java server process if needed (might require PID management or specific server command)\n",
    "if 'process' in locals() and process.poll() is None:\n",
    "     write_log(\"   æ­£åœ¨çµ‚æ­¢ Java server process...\")\n",
    "     process.terminate() # Ask nicely first\n",
    "     try:\n",
    "         process.wait(timeout=5) # Wait for termination\n",
    "         write_log(\"   Java server process å·²çµ‚æ­¢.\")\n",
    "     except subprocess.TimeoutExpired:\n",
    "         write_log(\"   Java server æœªèƒ½åœ¨ 5 ç§’å…§çµ‚æ­¢, å¼·åˆ¶çµæŸ...\")\n",
    "         process.kill() # Force kill\n",
    "         write_log(\"   Java server process å·²å¼·åˆ¶çµæŸ.\")\n",
    "\n",
    "\n",
    "# Finish the Wandb run\n",
    "run.finish()\n",
    "write_log(\"âœ¨ Wandb run finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import socket\n",
    "import cv2\n",
    "# import matplotlib.pyplot as plt # Matplotlib not strictly needed for core logic\n",
    "import subprocess\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import imageio\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "# from stable_baselines3.common.env_checker import check_env # Not used on VecEnv\n",
    "from stable_baselines3 import DQN\n",
    "# from stable_baselines3.common.env_util import make_vec_env # Not used\n",
    "from stable_baselines3.common.vec_env import VecNormalize, VecFrameStack, DummyVecEnv\n",
    "from IPython.display import FileLink, display # Image not used directly\n",
    "# from stable_baselines3.common.callbacks import BaseCallback # Replaced by WandbCallback\n",
    "import torch\n",
    "import time\n",
    "import pygame # Added for rendering in TetrisEnv\n",
    "\n",
    "# --- Wandb Setup ---\n",
    "import os\n",
    "import wandb\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "# Import WandbCallback for SB3 integration\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "# --- Configuration ---\n",
    "# Set your student ID here for filenames\n",
    "STUDENT_ID = \"113598065\"\n",
    "# Set total training steps\n",
    "#TOTAL_TIMESTEPS = 2000000 # Adjust as needed (e.g., 1M, 2M, 5M)\n",
    "TOTAL_TIMESTEPS = 2000000 # Reduced for a potentially quicker test run, increase for full training\n",
    "\n",
    "\n",
    "# --- Wandb Login and Initialization ---\n",
    "try:\n",
    "    user_secrets = UserSecretsClient()\n",
    "    WANDB_API_KEY = user_secrets.get_secret(\"WANDB_API_KEY\")\n",
    "    os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY\n",
    "    wandb.login()\n",
    "    wandb_enabled = True\n",
    "except Exception as e:\n",
    "    print(f\"Wandb login failed (running without secrets?): {e}. Running without Wandb logging.\")\n",
    "    wandb_enabled = False\n",
    "    WANDB_API_KEY = None # Ensure it's None if not available\n",
    "\n",
    "# Start a wandb run if enabled\n",
    "if wandb_enabled:\n",
    "    run = wandb.init(\n",
    "        project=\"tetris-training-improved\",\n",
    "        entity=\"t113598065-ntut-edu-tw\", # Replace with your Wandb entity if different\n",
    "        sync_tensorboard=True,\n",
    "        monitor_gym=True,\n",
    "        save_code=True,\n",
    "        config={ # Log hyperparameters\n",
    "            \"policy_type\": \"CnnPolicy\",\n",
    "            \"total_timesteps\": TOTAL_TIMESTEPS,\n",
    "            \"env_id\": \"TetrisEnv-v1\",\n",
    "            \"gamma\": 0.99,\n",
    "            \"learning_rate\": 1e-4,\n",
    "            \"buffer_size\": 300000, # Increased buffer size\n",
    "            \"learning_starts\": 10000, # Keep reasonable starts\n",
    "            \"target_update_interval\": 10000, # Keep reasonable update interval\n",
    "            \"exploration_fraction\": 0.3, # Explore for 60% of training\n",
    "            \"exploration_final_eps\": 0.05, # Lower final epsilon\n",
    "            \"batch_size\": 32, # Default for DQN, can be tuned\n",
    "            \"n_stack\": 4, # Frame stacking\n",
    "            \"student_id\": STUDENT_ID,\n",
    "        }\n",
    "    )\n",
    "    run_id = run.id # Get run ID for saving paths\n",
    "else:\n",
    "    run = None # Set run to None if wandb is disabled\n",
    "    run_id = f\"local_{int(time.time())}\" # Create a local ID for paths\n",
    "\n",
    "\n",
    "log_path = f\"/kaggle/working/tetris_train_log_{run_id}.txt\"\n",
    "\n",
    "def write_log(message):\n",
    "    \"\"\"Appends a message to the log file and prints it.\"\"\"\n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    log_message = f\"{timestamp} - {message}\"\n",
    "    try:\n",
    "        with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(log_message + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing to log file {log_path}: {e}\")\n",
    "    print(log_message)\n",
    "\n",
    "def wait_for_tetris_server(ip=\"127.0.0.1\", port=10612, timeout=60):\n",
    "    \"\"\"Waits for the Tetris TCP server to become available.\"\"\"\n",
    "    write_log(f\"â³ ç­‰å¾… Tetris TCP server å•Ÿå‹•ä¸­ ({ip}:{port})...\")\n",
    "    start_time = time.time()\n",
    "    while True:\n",
    "        try:\n",
    "            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as test_sock:\n",
    "                test_sock.settimeout(1.0)\n",
    "                test_sock.connect((ip, port))\n",
    "            write_log(\"âœ… Java TCP server æº–å‚™å®Œæˆï¼Œé€£ç·šæˆåŠŸ\")\n",
    "            return True # Indicate success\n",
    "        except socket.error as e:\n",
    "            if time.time() - start_time > timeout:\n",
    "                write_log(f\"âŒ ç­‰å¾… Java TCP server è¶…æ™‚ ({timeout}s)\")\n",
    "                return False # Indicate failure\n",
    "            time.sleep(1.0) # Wait a bit longer before retrying\n",
    "\n",
    "# --- Start Java Server ---\n",
    "java_process = None # Initialize to None\n",
    "try:\n",
    "    write_log(\"ğŸš€ å˜—è©¦å•Ÿå‹• Java Tetris server...\")\n",
    "    jar_file = \"TetrisTCPserver_v0.6.jar\"\n",
    "    if not os.path.exists(jar_file):\n",
    "         write_log(f\"âŒ éŒ¯èª¤: æ‰¾ä¸åˆ° JAR æª”æ¡ˆ '{jar_file}'ã€‚è«‹ç¢ºä¿å®ƒåœ¨å·¥ä½œç›®éŒ„ä¸­ã€‚\")\n",
    "         raise FileNotFoundError(f\"JAR file '{jar_file}' not found.\")\n",
    "\n",
    "    # Start process, redirect stdout/stderr to DEVNULL if desired to keep console clean\n",
    "    java_process = subprocess.Popen(\n",
    "        [\"java\", \"-jar\", jar_file],\n",
    "        stdout=subprocess.DEVNULL, # Optional: hide server stdout\n",
    "        stderr=subprocess.DEVNULL  # Optional: hide server stderr\n",
    "    )\n",
    "    write_log(f\"âœ… Java server process å•Ÿå‹• (PID: {java_process.pid})\")\n",
    "    if not wait_for_tetris_server():\n",
    "        raise TimeoutError(\"Java server did not become available.\") # Raise specific error\n",
    "\n",
    "except Exception as e:\n",
    "    write_log(f\"âŒ å•Ÿå‹•æˆ–ç­‰å¾… Java server æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
    "    # Attempt to terminate if process started but failed connection\n",
    "    if java_process and java_process.poll() is None:\n",
    "         write_log(\"   å˜—è©¦çµ‚æ­¢æœªæˆåŠŸé€£æ¥çš„ Java server process...\")\n",
    "         java_process.terminate()\n",
    "         try:\n",
    "             java_process.wait(timeout=2)\n",
    "         except subprocess.TimeoutExpired:\n",
    "             java_process.kill()\n",
    "    raise # Re-raise the exception to stop the script\n",
    "\n",
    "# --- Check GPU ---\n",
    "if torch.cuda.is_available():\n",
    "    device_name = torch.cuda.get_device_name(0)\n",
    "    write_log(f\"âœ… PyTorch is using GPU: {device_name}\")\n",
    "    # Optional: Check compute capability if needed\n",
    "    # cc = torch.cuda.get_device_capability(0)\n",
    "    # write_log(f\"   Compute Capability: {cc[0]}.{cc[1]}\")\n",
    "else:\n",
    "    write_log(\"âš ï¸ PyTorch is using CPU. Training will be significantly slower.\")\n",
    "\n",
    "# ----------------------------\n",
    "# å®šç¾© Tetris ç’°å¢ƒ (æ¡ç”¨è€å¸«çš„æ ¼å¼, çµåˆçå‹µæ©Ÿåˆ¶æ¦‚å¿µ)\n",
    "# ----------------------------\n",
    "class TetrisEnv(gym.Env):\n",
    "    \"\"\"Custom Environment for Tetris that interacts with a Java TCP server.\"\"\"\n",
    "    metadata = {\"render_modes\": [\"human\", \"rgb_array\"], \"render_fps\": 30}\n",
    "    N_DISCRETE_ACTIONS = 5\n",
    "    IMG_HEIGHT = 200\n",
    "    IMG_WIDTH = 100\n",
    "    IMG_CHANNELS = 3\n",
    "    RESIZED_DIM = 84\n",
    "\n",
    "    def __init__(self, host_ip=\"127.0.0.1\", host_port=10612, render_mode=None):\n",
    "        super().__init__()\n",
    "        self.render_mode = render_mode\n",
    "        self.action_space = spaces.Discrete(self.N_DISCRETE_ACTIONS)\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0, high=255,\n",
    "            shape=(1, self.RESIZED_DIM, self.RESIZED_DIM), # (Channels, Height, Width)\n",
    "            dtype=np.uint8\n",
    "        )\n",
    "        self.server_ip = host_ip\n",
    "        self.server_port = host_port\n",
    "        self.client_sock = None\n",
    "        self._connect_socket() # Connect in init\n",
    "\n",
    "        # Reward shaping & statistics variables\n",
    "        self.lines_removed = 0\n",
    "        self.current_height = 0\n",
    "        self.current_holes = 0\n",
    "        self.lifetime = 0\n",
    "        self.last_observation = np.zeros(self.observation_space.shape, dtype=np.uint8)\n",
    "\n",
    "        # --- Reward Shaping Coefficients (TUNING REQUIRED) ---\n",
    "        self.reward_line_clear_coeff = 100.0\n",
    "        self.penalty_height_increase_coeff = 15.0\n",
    "        self.penalty_hole_increase_coeff = 25.0\n",
    "        self.penalty_step_coeff = 0.1\n",
    "        self.penalty_game_over_coeff = 500.0\n",
    "\n",
    "        # For rendering\n",
    "        self.window_surface = None\n",
    "        self.clock = None\n",
    "        self.is_pygame_initialized = False # Track Pygame init state\n",
    "\n",
    "    def _initialize_pygame(self):\n",
    "        \"\"\"Initializes Pygame if not already done.\"\"\"\n",
    "        if not self.is_pygame_initialized and self.render_mode == \"human\":\n",
    "            try:\n",
    "                import pygame\n",
    "                pygame.init()\n",
    "                pygame.display.init()\n",
    "                # Scale window for better visibility\n",
    "                window_width = self.RESIZED_DIM * 4\n",
    "                window_height = self.RESIZED_DIM * 4\n",
    "                self.window_surface = pygame.display.set_mode((window_width, window_height))\n",
    "                pygame.display.set_caption(f\"Tetris Env ({self.server_ip}:{self.server_port})\")\n",
    "                self.clock = pygame.time.Clock()\n",
    "                self.is_pygame_initialized = True\n",
    "                write_log(\"   Pygame initialized for rendering.\")\n",
    "            except ImportError:\n",
    "                write_log(\"âš ï¸ Pygame not installed, cannot use 'human' render mode.\")\n",
    "                self.render_mode = None # Disable human rendering\n",
    "            except Exception as e:\n",
    "                write_log(f\"âš ï¸ Error initializing Pygame: {e}\")\n",
    "                self.render_mode = None\n",
    "\n",
    "\n",
    "    def _connect_socket(self):\n",
    "        \"\"\"Establishes connection to the game server.\"\"\"\n",
    "        try:\n",
    "            if self.client_sock:\n",
    "                self.client_sock.close()\n",
    "            self.client_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "            self.client_sock.settimeout(10.0)\n",
    "            self.client_sock.connect((self.server_ip, self.server_port))\n",
    "            # write_log(f\"ğŸ”Œ Socket connected to {self.server_ip}:{self.server_port}\") # Less verbose\n",
    "        except socket.error as e:\n",
    "            write_log(f\"âŒ Socket connection error during connect: {e}\")\n",
    "            raise ConnectionError(f\"Failed to connect to Tetris server at {self.server_ip}:{self.server_port}\")\n",
    "\n",
    "    def _send_command(self, command: bytes):\n",
    "        \"\"\"Sends a command to the server, handles potential errors.\"\"\"\n",
    "        if not self.client_sock:\n",
    "             raise ConnectionError(\"Socket is not connected. Cannot send command.\")\n",
    "        try:\n",
    "            self.client_sock.sendall(command)\n",
    "        except socket.timeout:\n",
    "            write_log(\"âŒ Socket timeout during send.\")\n",
    "            raise ConnectionAbortedError(\"Socket timeout during send\")\n",
    "        except socket.error as e:\n",
    "            write_log(f\"âŒ Socket error during send: {e}\")\n",
    "            raise ConnectionAbortedError(f\"Socket error during send: {e}\")\n",
    "\n",
    "    def _receive_data(self, size):\n",
    "        \"\"\"Receives exactly size bytes from the server.\"\"\"\n",
    "        if not self.client_sock:\n",
    "             raise ConnectionError(\"Socket is not connected. Cannot receive data.\")\n",
    "        data = b\"\"\n",
    "        try:\n",
    "            self.client_sock.settimeout(10.0) # Set timeout for recv\n",
    "            while len(data) < size:\n",
    "                chunk = self.client_sock.recv(size - len(data))\n",
    "                if not chunk:\n",
    "                    write_log(\"âŒ Socket connection broken during receive (received empty chunk).\")\n",
    "                    raise ConnectionAbortedError(\"Socket connection broken\")\n",
    "                data += chunk\n",
    "        except socket.timeout:\n",
    "             write_log(f\"âŒ Socket timeout during receive (expected {size}, got {len(data)}).\")\n",
    "             raise ConnectionAbortedError(\"Socket timeout during receive\")\n",
    "        except socket.error as e:\n",
    "            write_log(f\"âŒ Socket error during receive: {e}\")\n",
    "            raise ConnectionAbortedError(f\"Socket error during receive: {e}\")\n",
    "        return data\n",
    "\n",
    "    def get_tetris_server_response(self):\n",
    "        \"\"\"Gets state update from the Tetris server via socket.\"\"\"\n",
    "        try:\n",
    "            is_game_over_byte = self._receive_data(1)\n",
    "            is_game_over = (is_game_over_byte == b'\\x01')\n",
    "\n",
    "            removed_lines_bytes = self._receive_data(4)\n",
    "            removed_lines = int.from_bytes(removed_lines_bytes, 'big')\n",
    "\n",
    "            height_bytes = self._receive_data(4)\n",
    "            height = int.from_bytes(height_bytes, 'big')\n",
    "\n",
    "            holes_bytes = self._receive_data(4)\n",
    "            holes = int.from_bytes(holes_bytes, 'big')\n",
    "\n",
    "            img_size_bytes = self._receive_data(4)\n",
    "            img_size = int.from_bytes(img_size_bytes, 'big')\n",
    "\n",
    "            if img_size <= 0 or img_size > 1000000: # Increased max size slightly\n",
    "                 write_log(f\"âŒ Received invalid image size: {img_size}. Aborting receive.\")\n",
    "                 raise ValueError(f\"Invalid image size received: {img_size}\")\n",
    "\n",
    "            img_png = self._receive_data(img_size)\n",
    "\n",
    "            # Decode and preprocess image\n",
    "            nparr = np.frombuffer(img_png, np.uint8)\n",
    "            np_image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "            if np_image is None:\n",
    "                 write_log(\"âŒ Failed to decode image from server response.\")\n",
    "                 # Return last known state and signal termination\n",
    "                 return True, self.lines_removed, self.current_height, self.current_holes, self.last_observation.copy()\n",
    "\n",
    "            resized = cv2.resize(np_image, (self.RESIZED_DIM, self.RESIZED_DIM), interpolation=cv2.INTER_AREA)\n",
    "            gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
    "            observation = np.expand_dims(gray, axis=0).astype(np.uint8) # Combine steps\n",
    "\n",
    "            # Store frames for rendering/observation\n",
    "            self.last_raw_render_frame = resized.copy() # Store BGR for render\n",
    "            self.last_observation = observation.copy() # Store processed obs\n",
    "\n",
    "            return is_game_over, removed_lines, height, holes, observation\n",
    "\n",
    "        except (ConnectionAbortedError, ConnectionRefusedError, ValueError) as e:\n",
    "             write_log(f\"âŒ Connection/Value error getting server response: {e}. Ending episode.\")\n",
    "             # Return last known state and signal termination\n",
    "             return True, self.lines_removed, self.current_height, self.current_holes, self.last_observation.copy()\n",
    "        except Exception as e:\n",
    "            write_log(f\"âŒ Unexpected error getting server response: {e}. Ending episode.\")\n",
    "            # Return last known state and signal termination\n",
    "            return True, self.lines_removed, self.current_height, self.current_holes, self.last_observation.copy()\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        # --- Send Action ---\n",
    "        command_map = {\n",
    "            0: b\"move -1\\n\", 1: b\"move 1\\n\",\n",
    "            2: b\"rotate 0\\n\", 3: b\"rotate 1\\n\",\n",
    "            4: b\"drop\\n\"\n",
    "        }\n",
    "        command = command_map.get(action)\n",
    "        if command is None:\n",
    "            write_log(f\"âš ï¸ Invalid action received: {action}. Sending 'drop'.\")\n",
    "            command = b\"drop\\n\"\n",
    "\n",
    "        try:\n",
    "            self._send_command(command)\n",
    "        except (ConnectionAbortedError, ConnectionError) as e:\n",
    "            write_log(f\"âŒ Ending episode due to send failure in step: {e}\")\n",
    "            terminated = True\n",
    "            observation = self.last_observation.copy()\n",
    "            reward = self.penalty_game_over_coeff * -1\n",
    "            info = {'removed_lines': self.lines_removed, 'lifetime': self.lifetime, 'final_status': 'send_error'}\n",
    "            info['terminal_observation'] = observation\n",
    "            return observation, reward, terminated, False, info\n",
    "\n",
    "        # --- Get State Update ---\n",
    "        terminated, new_lines_removed, new_height, new_holes, observation = self.get_tetris_server_response()\n",
    "\n",
    "        # --- Calculate Reward ---\n",
    "        reward = 0.0\n",
    "        lines_cleared_this_step = new_lines_removed - self.lines_removed\n",
    "        if lines_cleared_this_step > 0:\n",
    "            reward += (lines_cleared_this_step ** 2) * self.reward_line_clear_coeff\n",
    "\n",
    "        height_increase = new_height - self.current_height\n",
    "        if height_increase > 0:\n",
    "            reward -= height_increase * self.penalty_height_increase_coeff\n",
    "\n",
    "        hole_increase = new_holes - self.current_holes\n",
    "        if hole_increase > 0:\n",
    "            reward -= hole_increase * self.penalty_hole_increase_coeff\n",
    "\n",
    "        reward -= self.penalty_step_coeff # Step penalty\n",
    "\n",
    "        if terminated:\n",
    "            reward -= self.penalty_game_over_coeff\n",
    "            # Log only once per game over for clarity\n",
    "            write_log(f\"ğŸ’” Game Over! Final Lines: {new_lines_removed}, Lifetime: {self.lifetime + 1}, reward: {reward}\")\n",
    "\n",
    "        # --- Update Internal State ---\n",
    "        self.lines_removed = new_lines_removed\n",
    "        self.current_height = new_height\n",
    "        self.current_holes = new_holes\n",
    "        self.lifetime += 1\n",
    "\n",
    "        # --- Prepare Return Values ---\n",
    "        info = {'removed_lines': self.lines_removed, 'lifetime': self.lifetime}\n",
    "        truncated = False\n",
    "\n",
    "        if terminated:\n",
    "            info['terminal_observation'] = observation.copy()\n",
    "            # Log final stats here if needed, or use SB3 logger/callback\n",
    "            # Example: print(f\"Episode End: Lines={self.lines_removed}, Lifetime={self.lifetime}, Reward={reward}\")\n",
    "\n",
    "\n",
    "        # Optional: Render on step if requested\n",
    "        if self.render_mode == \"human\":\n",
    "             self.render()\n",
    "\n",
    "        return observation, reward, terminated, truncated, info\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        for attempt in range(3): # Allow a few attempts to reset/reconnect\n",
    "            try:\n",
    "                self._send_command(b\"start\\n\")\n",
    "                terminated, lines, height, holes, observation = self.get_tetris_server_response()\n",
    "                if terminated:\n",
    "                    write_log(f\"âš ï¸ Server reported game over on reset attempt {attempt+1}. Retrying...\")\n",
    "                    if attempt < 2: # Reconnect if not last attempt\n",
    "                         self._connect_socket()\n",
    "                         time.sleep(0.5) # Small delay before retry\n",
    "                         continue # Retry the loop\n",
    "                    else:\n",
    "                         write_log(\"âŒ Server still terminated after multiple reset attempts. Cannot proceed.\")\n",
    "                         raise RuntimeError(\"Tetris server failed to reset properly.\")\n",
    "                # Reset successful\n",
    "                self.lines_removed = 0\n",
    "                self.current_height = height\n",
    "                self.current_holes = holes\n",
    "                self.lifetime = 0\n",
    "                self.last_observation = observation.copy()\n",
    "                # write_log(f\"ğŸ”„ Environment Reset. Initial state: H={height}, O={holes}\") # Less verbose logging\n",
    "                info = {}\n",
    "                return observation, info\n",
    "\n",
    "            except (ConnectionAbortedError, ConnectionError, socket.error, TimeoutError) as e:\n",
    "                 write_log(f\"ğŸ”Œ Connection issue during reset attempt {attempt+1} ({e}). Retrying...\")\n",
    "                 if attempt < 2:\n",
    "                      try:\n",
    "                          self._connect_socket() # Attempt reconnect\n",
    "                          time.sleep(0.5)\n",
    "                      except ConnectionError:\n",
    "                           write_log(\"   Reconnect failed.\")\n",
    "                           if attempt == 1: # If second attempt also fails, raise\n",
    "                               raise RuntimeError(f\"Failed to reconnect and reset Tetris server after multiple attempts: {e}\")\n",
    "                 else: # Final attempt failed\n",
    "                     raise RuntimeError(f\"Failed to reset Tetris server after multiple attempts: {e}\")\n",
    "\n",
    "        # Should not be reached if logic is correct, but as fallback:\n",
    "        raise RuntimeError(\"Failed to reset Tetris server.\")\n",
    "\n",
    "\n",
    "    def render(self):\n",
    "        self._initialize_pygame() # Ensure pygame is ready if in human mode\n",
    "\n",
    "        if self.render_mode == \"human\" and self.is_pygame_initialized:\n",
    "            import pygame\n",
    "            if self.window_surface is None:\n",
    "                 # This should not happen if _initialize_pygame worked, but handle defensively\n",
    "                 write_log(\"âš ï¸ Render called but Pygame window is not initialized.\")\n",
    "                 return\n",
    "\n",
    "            if hasattr(self, 'last_raw_render_frame'):\n",
    "                try:\n",
    "                    # last_raw_render_frame is (H, W, C) BGR from OpenCV\n",
    "                    render_frame_rgb = cv2.cvtColor(self.last_raw_render_frame, cv2.COLOR_BGR2RGB)\n",
    "                    # Pygame surface requires (width, height)\n",
    "                    surf = pygame.Surface((self.RESIZED_DIM, self.RESIZED_DIM))\n",
    "                    # Transpose needed: (H, W, C) -> (W, H, C) for Pygame surfarray\n",
    "                    pygame.surfarray.blit_array(surf, np.transpose(render_frame_rgb, (1, 0, 2)))\n",
    "                    # Scale up to window size\n",
    "                    surf = pygame.transform.scale(surf, self.window_surface.get_size())\n",
    "                    self.window_surface.blit(surf, (0, 0))\n",
    "                    pygame.event.pump() # Process internal Pygame events\n",
    "                    pygame.display.flip() # Update the full screen surface\n",
    "                    self.clock.tick(self.metadata[\"render_fps\"]) # Control frame rate\n",
    "                except Exception as e:\n",
    "                    write_log(f\"âš ï¸ Error during Pygame rendering: {e}\")\n",
    "                    # Attempt to close pygame gracefully on error?\n",
    "                    # self.close()\n",
    "\n",
    "            else:\n",
    "                # Draw a black screen if no frame available yet\n",
    "                 self.window_surface.fill((0, 0, 0))\n",
    "                 pygame.display.flip()\n",
    "\n",
    "        elif self.render_mode == \"rgb_array\":\n",
    "             if hasattr(self, 'last_raw_render_frame'):\n",
    "                 # Return RGB (H, W, C)\n",
    "                 return cv2.cvtColor(self.last_raw_render_frame, cv2.COLOR_BGR2RGB)\n",
    "             else:\n",
    "                 # Return black frame if no observation yet\n",
    "                 return np.zeros((self.RESIZED_DIM, self.RESIZED_DIM, 3), dtype=np.uint8)\n",
    "\n",
    "    def close(self):\n",
    "        # write_log(\"ğŸ”Œ Closing environment connection.\") # Less verbose\n",
    "        if self.client_sock:\n",
    "            try:\n",
    "                self.client_sock.close()\n",
    "            except socket.error as e:\n",
    "                 write_log(f\"   Error closing socket: {e}\")\n",
    "            self.client_sock = None\n",
    "\n",
    "        if self.is_pygame_initialized:\n",
    "            try:\n",
    "                import pygame\n",
    "                pygame.display.quit()\n",
    "                pygame.quit()\n",
    "                self.is_pygame_initialized = False\n",
    "                # write_log(\"   Pygame window closed.\") # Less verbose\n",
    "            except Exception as e:\n",
    "                 write_log(f\"   Error closing Pygame: {e}\")\n",
    "\n",
    "# --- Environment Setup ---\n",
    "write_log(\"âœ… å»ºç«‹åŸºç¤ç’°å¢ƒå‡½æ•¸ make_env...\")\n",
    "def make_env():\n",
    "    \"\"\"Helper function to create an instance of the Tetris environment.\"\"\"\n",
    "    env = TetrisEnv()\n",
    "    return env\n",
    "\n",
    "write_log(\"âœ… å»ºç«‹å‘é‡åŒ–ç’°å¢ƒ (DummyVecEnv)...\")\n",
    "# Use DummyVecEnv for single environment interaction\n",
    "train_env_base = DummyVecEnv([make_env])\n",
    "\n",
    "write_log(\"âœ… åŒ…è£ç’°å¢ƒ (VecFrameStack)...\")\n",
    "# Wrap with VecFrameStack (channel-first is important)\n",
    "# Use wandb config if available, otherwise use default\n",
    "n_stack = run.config[\"n_stack\"] if run else 4\n",
    "train_env_stacked = VecFrameStack(train_env_base, n_stack=n_stack, channels_order=\"first\")\n",
    "\n",
    "write_log(\"âœ… åŒ…è£ç’°å¢ƒ (VecNormalize - Rewards Only)...\")\n",
    "# Wrap with VecNormalize, NORMALIZING REWARDS ONLY.\n",
    "# Use wandb config if available, otherwise use default\n",
    "gamma = run.config[\"gamma\"] if run else 0.99\n",
    "train_env = VecNormalize(train_env_stacked, norm_obs=False, norm_reward=True, gamma=gamma)\n",
    "\n",
    "write_log(\"   ç’°å¢ƒå»ºç«‹å®Œæˆä¸¦å·²åŒ…è£ (DummyVecEnv -> VecFrameStack -> VecNormalize)\")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# DQN Model Setup and Training\n",
    "# ----------------------------\n",
    "write_log(\"ğŸ§  è¨­å®š DQN æ¨¡å‹...\")\n",
    "# Use wandb config for hyperparameters if available, otherwise use defaults\n",
    "policy_type = run.config[\"policy_type\"] if run else \"CnnPolicy\"\n",
    "learning_rate = run.config[\"learning_rate\"] if run else 1e-4\n",
    "buffer_size = run.config[\"buffer_size\"] if run else 100000\n",
    "learning_starts = run.config[\"learning_starts\"] if run else 10000\n",
    "batch_size = run.config[\"batch_size\"] if run else 32\n",
    "tau = 1.0 # Default for DQN\n",
    "target_update_interval = run.config[\"target_update_interval\"] if run else 10000\n",
    "gradient_steps = 1 # Default for DQN\n",
    "exploration_fraction = run.config[\"exploration_fraction\"] if run else 0.1 # Default DQN explore fraction is smaller\n",
    "exploration_final_eps = run.config[\"exploration_final_eps\"] if run else 0.05\n",
    "\n",
    "# Define DQN model\n",
    "model = DQN(\n",
    "    policy=policy_type,\n",
    "    env=train_env,\n",
    "    verbose=1,\n",
    "    gamma=gamma,\n",
    "    learning_rate=learning_rate,\n",
    "    buffer_size=buffer_size,\n",
    "    learning_starts=learning_starts,\n",
    "    batch_size=batch_size,\n",
    "    tau=tau,\n",
    "    train_freq=(1, \"step\"), # Train every step\n",
    "    gradient_steps=gradient_steps,\n",
    "    target_update_interval=target_update_interval,\n",
    "    exploration_fraction=exploration_fraction,\n",
    "    exploration_final_eps=exploration_final_eps,\n",
    "    policy_kwargs=dict(normalize_images=False), # As per original code\n",
    "    seed=42, # Set seed for reproducibility\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    tensorboard_log=f\"/kaggle/working/runs/{run_id}\" if wandb_enabled else None # Log TB only if wandb enabled\n",
    ")\n",
    "write_log(f\"   æ¨¡å‹å»ºç«‹å®Œæˆ. Device: {model.device}\")\n",
    "if run: write_log(f\"   ä½¿ç”¨ Wandb è¶…åƒæ•¸: {run.config}\")\n",
    "else: write_log(\"   ä½¿ç”¨é»˜èªè¶…åƒæ•¸ (Wandb æœªå•Ÿç”¨).\")\n",
    "\n",
    "\n",
    "# Setup Wandb callback if enabled\n",
    "if wandb_enabled:\n",
    "    wandb_callback = WandbCallback(\n",
    "        gradient_save_freq=10000,\n",
    "        model_save_path=f\"/kaggle/working/models/{run_id}\",\n",
    "        model_save_freq=50000,\n",
    "        log=\"all\",\n",
    "        verbose=2\n",
    "    )\n",
    "    callback_list = [wandb_callback]\n",
    "else:\n",
    "    callback_list = None # No callback if wandb is disabled\n",
    "\n",
    "# --- Training ---\n",
    "write_log(f\"ğŸš€ é–‹å§‹è¨“ç·´ {TOTAL_TIMESTEPS} æ­¥...\")\n",
    "training_successful = False\n",
    "try:\n",
    "    model.learn(\n",
    "        total_timesteps=TOTAL_TIMESTEPS,\n",
    "        callback=callback_list,\n",
    "        log_interval=10 # Log basic stats every 10 episodes\n",
    "    )\n",
    "    write_log(\"âœ… è¨“ç·´å®Œæˆ!\")\n",
    "    training_successful = True\n",
    "except Exception as e:\n",
    "     write_log(f\"âŒ è¨“ç·´éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}\", exc_info=True) # Log exception info\n",
    "     # Save model before exiting if error occurs mid-training\n",
    "     error_save_path = f'/kaggle/working/{STUDENT_ID}_dqn_error_save.zip'\n",
    "     try:\n",
    "        model.save(error_save_path)\n",
    "        write_log(f\"   æ¨¡å‹å·²å˜—è©¦å„²å­˜è‡³ {error_save_path}\")\n",
    "        if wandb_enabled: wandb.save(error_save_path)\n",
    "     except Exception as save_e:\n",
    "         write_log(f\"   âŒ å„²å­˜éŒ¯èª¤æ¨¡å‹æ™‚ä¹Ÿç™¼ç”ŸéŒ¯èª¤: {save_e}\")\n",
    "     if run: run.finish(exit_code=1, quiet=True) # Finish wandb run with error code\n",
    "\n",
    "# --- Save Final Model (only if training completed successfully) ---\n",
    "if training_successful:\n",
    "    stats_path = f\"/kaggle/working/vecnormalize_stats_{run_id}.pkl\"\n",
    "    final_model_name = f'{STUDENT_ID}_dqn_final_{run_id}.zip'\n",
    "    final_model_path = os.path.join(\"/kaggle/working\", final_model_name)\n",
    "\n",
    "    try:\n",
    "        train_env.save(stats_path)\n",
    "        write_log(f\"   VecNormalize çµ±è¨ˆæ•¸æ“šå·²å„²å­˜è‡³ {stats_path}\")\n",
    "        if wandb_enabled: wandb.save(stats_path)\n",
    "\n",
    "        model.save(final_model_path)\n",
    "        write_log(f\"âœ… æœ€çµ‚æ¨¡å‹å·²å„²å­˜: {final_model_path}\")\n",
    "        display(FileLink(final_model_path))\n",
    "        if wandb_enabled: wandb.save(final_model_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        write_log(f\"âŒ å„²å­˜æœ€çµ‚æ¨¡å‹æˆ–çµ±è¨ˆæ•¸æ“šæ™‚å‡ºéŒ¯: {e}\")\n",
    "        training_successful = False # Mark as unsuccessful if saving fails\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Evaluation (only if training and saving were successful)\n",
    "# ----------------------------\n",
    "if training_successful:\n",
    "    write_log(\"\\nğŸ§ª é–‹å§‹è©•ä¼°è¨“ç·´å¾Œçš„æ¨¡å‹...\")\n",
    "\n",
    "    # Create a separate evaluation environment\n",
    "    try:\n",
    "        eval_env_base = DummyVecEnv([make_env])\n",
    "\n",
    "        # Wrap with FrameStack FIRST, same as training\n",
    "        n_stack_eval = run.config[\"n_stack\"] if run else 4\n",
    "        eval_env_stacked = VecFrameStack(eval_env_base, n_stack=n_stack_eval, channels_order=\"first\")\n",
    "\n",
    "        # Load the SAME VecNormalize statistics\n",
    "        eval_env = VecNormalize.load(stats_path, eval_env_stacked)\n",
    "        eval_env.training = False\n",
    "        eval_env.norm_reward = False # IMPORTANT: à¦¦à§‡à¦–à¦¤à§‡ à¦†à¦¸à¦² reward\n",
    "\n",
    "        write_log(\"   è©•ä¼°ç’°å¢ƒå»ºç«‹æˆåŠŸ.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        write_log(f\"âŒ éŒ¯èª¤: VecNormalize çµ±è¨ˆæ–‡ä»¶æœªæ‰¾åˆ°æ–¼ {stats_path}ã€‚è·³éè©•ä¼°ã€‚\")\n",
    "        eval_env = None\n",
    "    except Exception as e:\n",
    "        write_log(f\"âŒ å»ºç«‹è©•ä¼°ç’°å¢ƒæ™‚å‡ºéŒ¯: {e}\")\n",
    "        eval_env = None\n",
    "\n",
    "    if eval_env is not None:\n",
    "        # --- Run Evaluation Episodes ---\n",
    "        num_eval_episodes = 5\n",
    "        total_rewards = []\n",
    "        total_lines = []\n",
    "        total_lifetimes = []\n",
    "        all_frames = []\n",
    "\n",
    "        try:\n",
    "            for i in range(num_eval_episodes):\n",
    "                obs = eval_env.reset()\n",
    "                done = False\n",
    "                episode_reward = 0\n",
    "                episode_lines = 0\n",
    "                episode_lifetime = 0\n",
    "                frames = []\n",
    "                last_info = {}\n",
    "\n",
    "                while not done:\n",
    "                    # Render base env for GIF\n",
    "                    try:\n",
    "                         base_env = eval_env.get_attr(\"envs\")[0].env\n",
    "                         raw_frame = base_env.render(mode=\"rgb_array\")\n",
    "                         if i == 0: frames.append(raw_frame) # Only for first ep\n",
    "                    except Exception as render_err:\n",
    "                         write_log(f\"âš ï¸ è©•ä¼°æ™‚ç²å–æ¸²æŸ“å¹€å‡ºéŒ¯: {render_err}\")\n",
    "\n",
    "                    # Predict and step\n",
    "                    action, _ = model.predict(obs, deterministic=True)\n",
    "                    obs, reward, done, infos = eval_env.step(action)\n",
    "\n",
    "                    episode_reward += reward[0]\n",
    "                    last_info = infos[0]\n",
    "                    # Use .get() for safety, default to previous value if key missing\n",
    "                    episode_lines = last_info.get('removed_lines', episode_lines)\n",
    "                    episode_lifetime = last_info.get('lifetime', episode_lifetime)\n",
    "                    done = done[0]\n",
    "\n",
    "                write_log(f\"   è©•ä¼° Episode {i+1}: Reward={episode_reward:.2f}, Lines={episode_lines}, Steps={episode_lifetime}\")\n",
    "                total_rewards.append(episode_reward)\n",
    "                total_lines.append(episode_lines)\n",
    "                total_lifetimes.append(episode_lifetime)\n",
    "                if i == 0: all_frames = frames\n",
    "\n",
    "            write_log(f\"--- è©•ä¼°çµæœ ({num_eval_episodes} episodes) ---\")\n",
    "            mean_reward = np.mean(total_rewards)\n",
    "            std_reward = np.std(total_rewards)\n",
    "            mean_lines = np.mean(total_lines)\n",
    "            std_lines = np.std(total_lines)\n",
    "            mean_lifetime = np.mean(total_lifetimes)\n",
    "            std_lifetime = np.std(total_lifetimes)\n",
    "\n",
    "            write_log(f\"   å¹³å‡ Reward: {mean_reward:.2f} +/- {std_reward:.2f}\")\n",
    "            write_log(f\"   å¹³å‡ Lines: {mean_lines:.2f} +/- {std_lines:.2f}\")\n",
    "            write_log(f\"   å¹³å‡ Steps: {mean_lifetime:.2f} +/- {std_lifetime:.2f}\")\n",
    "\n",
    "            # Log evaluation metrics to Wandb\n",
    "            if wandb_enabled:\n",
    "                wandb.log({\n",
    "                    \"eval/mean_reward\": mean_reward, \"eval/std_reward\": std_reward,\n",
    "                    \"eval/mean_lines\": mean_lines, \"eval/std_lines\": std_lines,\n",
    "                    \"eval/mean_lifetime\": mean_lifetime, \"eval/std_lifetime\": std_lifetime,\n",
    "                })\n",
    "\n",
    "            # --- Generate Replay GIF ---\n",
    "            if all_frames:\n",
    "                gif_path = f'/kaggle/working/replay_eval_{run_id}.gif'\n",
    "                write_log(f\"ğŸ’¾ æ­£åœ¨å„²å­˜è©•ä¼°å›æ”¾ GIF è‡³ {gif_path}...\")\n",
    "                try:\n",
    "                    imageio.mimsave(gif_path, [np.array(frame).astype(np.uint8) for frame in all_frames], fps=15, loop=0)\n",
    "                    write_log(\"   GIF å„²å­˜æˆåŠŸ.\")\n",
    "                    display(FileLink(gif_path))\n",
    "                    if wandb_enabled: wandb.log({\"eval/replay\": wandb.Video(gif_path, fps=15, format=\"gif\")})\n",
    "                except Exception as e: write_log(f\"   âŒ å„²å­˜ GIF æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
    "            else: write_log(\"   âš ï¸ æœªèƒ½å„²å­˜ GIF (æ²’æœ‰æ”¶é›†åˆ°å¹€).\")\n",
    "\n",
    "            # --- Save Evaluation Results CSV ---\n",
    "            csv_filename = f'tetris_evaluation_scores_{run_id}.csv'\n",
    "            csv_path = os.path.join(\"/kaggle/working\", csv_filename)\n",
    "            try:\n",
    "                with open(csv_path, 'w') as fs:\n",
    "                    fs.write('episode_id,removed_lines,played_steps,reward\\n')\n",
    "                    if total_lines: # Ensure lists are not empty\n",
    "                        fs.write(f'eval_0,{total_lines[0]},{total_lifetimes[0]},{total_rewards[0]:.2f}\\n')\n",
    "                    fs.write(f'eval_avg,{mean_lines:.2f},{mean_lifetime:.2f},{mean_reward:.2f}\\n')\n",
    "                write_log(f\"âœ… è©•ä¼°åˆ†æ•¸ CSV å·²å„²å­˜: {csv_path}\")\n",
    "                display(FileLink(csv_path))\n",
    "                if wandb_enabled: wandb.save(csv_path)\n",
    "            except Exception as e: write_log(f\"   âŒ å„²å­˜ CSV æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
    "\n",
    "        except Exception as eval_e:\n",
    "            write_log(f\"âŒ è©•ä¼°è¿´åœˆä¸­ç™¼ç”ŸéŒ¯èª¤: {eval_e}\", exc_info=True)\n",
    "\n",
    "        finally:\n",
    "             # Ensure evaluation env is closed even if errors occur\n",
    "             if eval_env:\n",
    "                 eval_env.close()\n",
    "                 write_log(\"   è©•ä¼°ç’°å¢ƒå·²é—œé–‰.\")\n",
    "\n",
    "# --- Cleanup ---\n",
    "write_log(\"ğŸ§¹ æ¸…ç†ç’°å¢ƒ...\")\n",
    "if 'train_env' in locals() and train_env: # Check if train_env exists\n",
    "    train_env.close()\n",
    "    write_log(\"   è¨“ç·´ç’°å¢ƒå·²é—œé–‰.\")\n",
    "# Close the Java server process\n",
    "if java_process and java_process.poll() is None:\n",
    "     write_log(\"   æ­£åœ¨çµ‚æ­¢ Java server process...\")\n",
    "     java_process.terminate()\n",
    "     try:\n",
    "         java_process.wait(timeout=5)\n",
    "         write_log(\"   Java server process å·²çµ‚æ­¢.\")\n",
    "     except subprocess.TimeoutExpired:\n",
    "         write_log(\"   Java server æœªèƒ½åœ¨ 5 ç§’å…§çµ‚æ­¢, å¼·åˆ¶çµæŸ...\")\n",
    "         java_process.kill()\n",
    "         write_log(\"   Java server process å·²å¼·åˆ¶çµæŸ.\")\n",
    "elif java_process and java_process.poll() is not None:\n",
    "     write_log(\"   Java server process å·²è‡ªè¡ŒçµæŸ.\")\n",
    "else:\n",
    "     write_log(\"   Java server process æœªå•Ÿå‹•æˆ–å·²é—œé–‰.\")\n",
    "\n",
    "\n",
    "# Finish the Wandb run if it was initialized and training didn't crash early\n",
    "if run:\n",
    "    if training_successful:\n",
    "         run.finish()\n",
    "         write_log(\"âœ¨ Wandb run finished.\")\n",
    "    else:\n",
    "         # Run might have already been finished in the exception handler\n",
    "         if run.is_running:\n",
    "              run.finish(exit_code=1) # Ensure it's marked as failed\n",
    "         write_log(\"âœ¨ Wandb run finished (marked as failed due to error).\")\n",
    "\n",
    "write_log(\"ğŸ è…³æœ¬åŸ·è¡Œå®Œç•¢.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11461423,
     "sourceId": 96443,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
