{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T14:11:21.839803Z",
     "iopub.status.busy": "2025-04-16T14:11:21.839521Z",
     "iopub.status.idle": "2025-04-16T14:13:42.815519Z",
     "shell.execute_reply": "2025-04-16T14:13:42.814614Z",
     "shell.execute_reply.started": "2025-04-16T14:11:21.839777Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3[extra] in /usr/local/lib/python3.11/dist-packages (2.1.0)\n",
      "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (0.29.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.5.1+cu124)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.1.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.2.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.7.5)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.11.0.86)\n",
      "Requirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.6.1)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.18.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (7.0.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.67.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (14.0.0)\n",
      "Collecting shimmy~=1.1.0 (from shimmy[atari]~=1.1.0; extra == \"extra\"->stable-baselines3[extra])\n",
      "  Downloading Shimmy-1.1.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (11.1.0)\n",
      "Collecting autorom~=0.6.1 (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra])\n",
      "  Downloading AutoROM-0.6.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (8.1.8)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (2.32.3)\n",
      "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra])\n",
      "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (4.13.1)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (0.0.4)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->stable-baselines3[extra]) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->stable-baselines3[extra]) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->stable-baselines3[extra]) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->stable-baselines3[extra]) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->stable-baselines3[extra]) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->stable-baselines3[extra]) (2.4.1)\n",
      "Collecting ale-py~=0.8.1 (from shimmy[atari]~=1.1.0; extra == \"extra\"->stable-baselines3[extra])\n",
      "  Downloading ale_py-0.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.70.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.7)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (75.1.0)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.17.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.18.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3[extra]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3[extra]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3[extra]) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13->stable-baselines3[extra])\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13->stable-baselines3[extra])\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13->stable-baselines3[extra])\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13->stable-baselines3[extra])\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13->stable-baselines3[extra])\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13->stable-baselines3[extra])\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3[extra]) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13->stable-baselines3[extra])\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3[extra]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13->stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (2.19.1)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from ale-py~=0.8.1->shimmy[atari]~=1.1.0; extra == \"extra\"->stable-baselines3[extra]) (6.5.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->stable-baselines3[extra]) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->stable-baselines3[extra]) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.20->stable-baselines3[extra]) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.20->stable-baselines3[extra]) (2024.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (2025.1.31)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.20->stable-baselines3[extra]) (2024.2.0)\n",
      "Downloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
      "Downloading Shimmy-1.1.0-py3-none-any.whl (37 kB)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ale_py-0.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: AutoROM.accept-rom-license\n",
      "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for AutoROM.accept-rom-license: filename=autorom_accept_rom_license-0.6.1-py3-none-any.whl size=446711 sha256=7e8674bb3652723d968220c220e31bb74ebed5d3f8dda55abe3cec83bee78a76\n",
      "  Stored in directory: /root/.cache/pip/wheels/bc/fc/c6/8aa657c0d2089982f2dabd110efc68c61eb49831fdb7397351\n",
      "Successfully built AutoROM.accept-rom-license\n",
      "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, AutoROM.accept-rom-license, autorom, nvidia-cusolver-cu12, shimmy, ale-py\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
      "  Attempting uninstall: shimmy\n",
      "    Found existing installation: Shimmy 1.3.0\n",
      "    Uninstalling Shimmy-1.3.0:\n",
      "      Successfully uninstalled Shimmy-1.3.0\n",
      "  Attempting uninstall: ale-py\n",
      "    Found existing installation: ale-py 0.10.1\n",
      "    Uninstalling ale-py-0.10.1:\n",
      "      Successfully uninstalled ale-py-0.10.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "kaggle-environments 1.16.11 requires shimmy>=1.2.1, but you have shimmy 1.1.0 which is incompatible.\n",
      "dopamine-rl 4.1.2 requires ale-py>=0.10.1, but you have ale-py 0.8.1 which is incompatible.\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed AutoROM.accept-rom-license-0.6.1 ale-py-0.8.1 autorom-0.6.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 shimmy-1.1.0\n",
      "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.6)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (7.0.0)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.3)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.21.0)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.1)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "--2025-04-16 14:13:42--  http://www.aiotlab.org/teaching/oop/tetris/TetrisTCPserver_v0.6.jar\n",
      "Resolving www.aiotlab.org (www.aiotlab.org)... 18.238.176.108, 18.238.176.59, 18.238.176.89, ...\n",
      "Connecting to www.aiotlab.org (www.aiotlab.org)|18.238.176.108|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://www.aiotlab.org/teaching/oop/tetris/TetrisTCPserver_v0.6.jar [following]\n",
      "--2025-04-16 14:13:42--  https://www.aiotlab.org/teaching/oop/tetris/TetrisTCPserver_v0.6.jar\n",
      "Connecting to www.aiotlab.org (www.aiotlab.org)|18.238.176.108|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3879189 (3.7M) [binary/octet-stream]\n",
      "Saving to: ‚ÄòTetrisTCPserver_v0.6.jar‚Äô\n",
      "\n",
      "TetrisTCPserver_v0. 100%[===================>]   3.70M  --.-KB/s    in 0.08s   \n",
      "\n",
      "2025-04-16 14:13:42 (49.2 MB/s) - ‚ÄòTetrisTCPserver_v0.6.jar‚Äô saved [3879189/3879189]\n",
      "\n",
      "‚úÖ Ê™îÊ°àË§áË£ΩÊàêÂäü\n"
     ]
    }
   ],
   "source": [
    "!pip install \"stable-baselines3[extra]\"\n",
    "!pip install wandb\n",
    "!wget http://www.aiotlab.org/teaching/oop/tetris/TetrisTCPserver_v0.6.jar\n",
    "import os\n",
    "\n",
    "if os.path.exists(\"TetrisTCPserver_v0.6.jar\"):\n",
    "    print(\"‚úÖ Ê™îÊ°àË§áË£ΩÊàêÂäü\")\n",
    "else:\n",
    "    print(\"‚ùå Ê™îÊ°àË§áË£ΩÂ§±Êïó\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T14:49:45.456095Z",
     "iopub.status.busy": "2025-04-16T14:49:45.455422Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Java started\n",
      "‚úÖ Java server started\n",
      "‚è≥ Á≠âÂæÖ Tetris TCP server ÂïüÂãï‰∏≠...\n",
      "‚úÖ Java TCP server Ê∫ñÂÇôÂÆåÊàêÔºåÈÄ£Á∑öÊàêÂäü\n",
      "‚úÖ PyTorch is using GPU:Client has joined the game Tesla T4\n",
      "Client has exited the game\n",
      "\n",
      "‚úÖ Âª∫Á´ãÁí∞Â¢ÉÈñãÂßã\n",
      "Client has exited the game\n",
      "Client has joined the game\n",
      "Address already in use (Bind failed)\n",
      "Tetris TCP server is listening at 10612\n",
      "Client has joined the game\n",
      "Using cuda device\n",
      "Model device: cuda\n",
      "Logging to ./sb3_log/DQN_11\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.856    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 23       |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 152      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.683    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 23       |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 334      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.528    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 23       |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 497      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.256    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 23       |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 783      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0937   |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 23       |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 954      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 23       |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 1646     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.383    |\n",
      "|    n_updates        | 161      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 23       |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 2102     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.457    |\n",
      "|    n_updates        | 275      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total_timesteps  | 2529     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.605    |\n",
      "|    n_updates        | 382      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 124      |\n",
      "|    total_timesteps  | 2863     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.284    |\n",
      "|    n_updates        | 465      |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import socket\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import imageio\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import VecNormalize, VecFrameStack\n",
    "from IPython.display import FileLink, display, Image\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import torch\n",
    "# ‰ΩøÁî® wandb Ë®òÈåÑË®ìÁ∑¥Êó•Ë™å\n",
    "import os\n",
    "import wandb\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "# Âæû Kaggle Secrets ËÆÄÂèñ API Token\n",
    "user_secrets = UserSecretsClient()\n",
    "WANDB_API_KEY = user_secrets.get_secret(\"WANDB_API_KEY\")\n",
    "\n",
    "# Ë®≠ÂÆöÁí∞Â¢ÉËÆäÊï∏ÔºåÊ®°Êì¨ login\n",
    "os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY\n",
    "\n",
    "# login & init\n",
    "wandb.login()\n",
    "wandb.init(project=\"tetris-training\", entity=\"t113598065-ntut-edu-tw\")\n",
    "\n",
    "log_path = \"/kaggle/working/tetris_train_log.txt\"\n",
    "\n",
    "def write_log(message):\n",
    "    with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(message + \"\\n\")\n",
    "    print(message)\n",
    "\n",
    "import time\n",
    "\n",
    "def wait_for_tetris_server(ip=\"127.0.0.1\", port=10612, timeout=30):\n",
    "    write_log(\"‚è≥ Á≠âÂæÖ Tetris TCP server ÂïüÂãï‰∏≠...\")\n",
    "    start_time = time.time()\n",
    "    while True:\n",
    "        try:\n",
    "            test_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "            test_sock.settimeout(1.0)\n",
    "            test_sock.connect((ip, port))\n",
    "            test_sock.close()\n",
    "            write_log(\"‚úÖ Java TCP server Ê∫ñÂÇôÂÆåÊàêÔºåÈÄ£Á∑öÊàêÂäü\")\n",
    "            break\n",
    "        except socket.error:\n",
    "            if time.time() - start_time > timeout:\n",
    "                raise TimeoutError(\"‚ùå Á≠âÂæÖ Java TCP server Ë∂ÖÊôÇ\")\n",
    "            time.sleep(0.5)\n",
    "\n",
    "# ÂïüÂãï Java Tetris server\n",
    "print(\"Java started\")\n",
    "subprocess.Popen([\"java\", \"-jar\", \"TetrisTCPserver_v0.6.jar\"])\n",
    "write_log(\"‚úÖ Java server started\")\n",
    "wait_for_tetris_server()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"‚úÖ PyTorch is using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"‚ùå PyTorch is using CPU\")\n",
    "# ----------------------------\n",
    "# ÂÆöÁæ© Tetris Áí∞Â¢É (Êé°Áî®ËÄÅÂ∏´ÁöÑÊ†ºÂºè)\n",
    "class RewardLoggerCallback(BaseCallback):\n",
    "    def __init__(self, log_path=\"./reward_log.txt\", verbose=0):\n",
    "        super().__init__(verbose)\n",
    "        self.log_path = log_path\n",
    "        self.episode_rewards = []\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # ÊØèÊ¨° env step ÂëºÂè´‰∏ÄÊ¨°Ôºå‰ΩÜÂè™ÊúâÂú® episode ÁµêÊùüÊôÇÊâçË®òÈåÑ\n",
    "        infos = self.locals.get(\"infos\", [])\n",
    "        for info in infos:\n",
    "            if \"episode\" in info:  # VecEnv ÊúÉÂõûÂÇ≥ episode reward\n",
    "                ep_reward = info[\"episode\"][\"r\"]\n",
    "                self.episode_rewards.append(ep_reward)\n",
    "                with open(self.log_path, \"a\") as f:\n",
    "                    f.write(f\"{len(self.episode_rewards)},{ep_reward}\\n\")\n",
    "                print(f\"üìà Episode {len(self.episode_rewards)} Reward: {ep_reward}\")\n",
    "        return True\n",
    "\n",
    "class TetrisEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\"], \"render_fps\": 20}\n",
    "    N_DISCRETE_ACTIONS = 5\n",
    "    IMG_HEIGHT = 200\n",
    "    IMG_WIDTH = 100\n",
    "    IMG_CHANNELS = 3\n",
    "\n",
    "    def __init__(self, host_ip=\"127.0.0.1\", host_port=10612):\n",
    "        super().__init__()\n",
    "        self.action_space = spaces.Discrete(self.N_DISCRETE_ACTIONS)\n",
    "        # self.observation_space = spaces.Box(low=0, high=255, shape=(84, 84), dtype=np.uint8)\n",
    "        self.observation_space = spaces.Box(low=0, high=255, shape=(1, 84, 84), dtype=np.uint8)\n",
    "        self.server_ip = host_ip\n",
    "        self.server_port = host_port\n",
    "\n",
    "        self.client_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "        self.client_sock.connect((self.server_ip, self.server_port))\n",
    "\n",
    "        # ÂàùÂßãÂåñ reward shaping ËàáÁµ±Ë®àÁî®ËÆäÊï∏\n",
    "        self.lines_removed = 0\n",
    "        self.height = 0\n",
    "        self.holes = 0\n",
    "        self.lifetime = 0\n",
    "\n",
    "    def step(self, action):\n",
    "        if action == 0:\n",
    "            self.client_sock.sendall(b\"move -1\\n\")\n",
    "        elif action == 1:\n",
    "            self.client_sock.sendall(b\"move 1\\n\")\n",
    "        elif action == 2:\n",
    "            self.client_sock.sendall(b\"rotate 0\\n\")\n",
    "        elif action == 3:\n",
    "            self.client_sock.sendall(b\"rotate 1\\n\")\n",
    "        elif action == 4:\n",
    "            self.client_sock.sendall(b\"drop\\n\")\n",
    "    \n",
    "        terminated, lines, height, holes, observation = self.get_tetris_server_response(self.client_sock)\n",
    "    \n",
    "        reward = 0\n",
    "        if action == 4:\n",
    "            reward += 5\n",
    "    \n",
    "        if height > self.height:\n",
    "            reward -= (height - self.height) * 5\n",
    "    \n",
    "        if holes < self.holes:\n",
    "            reward += (self.holes - holes) * 10\n",
    "    \n",
    "        if lines > self.lines_removed:\n",
    "            reward += (lines - self.lines_removed) * 1000\n",
    "            self.lines_removed = lines\n",
    "    \n",
    "        self.height = height\n",
    "        self.holes = holes\n",
    "        self.lifetime += 1\n",
    "    \n",
    "        info = {'removed_lines': self.lines_removed, 'lifetime': self.lifetime}\n",
    "    \n",
    "        truncated = False\n",
    "    \n",
    "        # ÈóúÈçµÔºÅËôïÁêÜÁµÇÊ≠¢ËßÄÂØüÂÄº\n",
    "        if terminated:\n",
    "            info['terminal_observation']  = observation.copy()  \n",
    "    \n",
    "        return observation, reward, terminated, truncated, info\n",
    "\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        self.client_sock.sendall(b\"start\\n\")\n",
    "        terminated, lines, height, holes, observation = self.get_tetris_server_response(self.client_sock)\n",
    "        # ÈáçÁΩÆÁµ±Ë®àËÆäÊï∏\n",
    "        self.lines_removed = 0\n",
    "        self.height = 0\n",
    "        self.holes = 0\n",
    "        self.lifetime = 0\n",
    "        return observation, {}\n",
    "\n",
    "    def render(self):\n",
    "        cv2.imshow(\"Tetris\", self.last_observation)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "    def close(self):\n",
    "        self.client_sock.close()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def get_tetris_server_response(self, sock):\n",
    "        is_game_over = (sock.recv(1) == b'\\x01')\n",
    "        removed_lines = int.from_bytes(sock.recv(4), 'big')\n",
    "        height = int.from_bytes(sock.recv(4), 'big')\n",
    "        holes = int.from_bytes(sock.recv(4), 'big')\n",
    "        img_size = int.from_bytes(sock.recv(4), 'big')\n",
    "        img_png = sock.recv(img_size)\n",
    "        nparr = np.frombuffer(img_png, np.uint8)\n",
    "        np_image = cv2.imdecode(nparr, -1)\n",
    "        resized = cv2.resize(np_image, (84, 84))\n",
    "        gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
    "        gray = np.expand_dims(gray, axis=0)  # <- ÈóúÈçµÔºÅchannel-first\n",
    "        self.last_observation = gray.copy()\n",
    "        return is_game_over, removed_lines, height, holes, gray\n",
    "    \n",
    "\n",
    "        \n",
    "# Ê™¢Êü•Áí∞Â¢É\n",
    "print(\"‚úÖ Âª∫Á´ãÁí∞Â¢ÉÈñãÂßã\")\n",
    "env = TetrisEnv()\n",
    "check_env(env)\n",
    "\n",
    "# ----------------------------\n",
    "# Âª∫Á´ãË®ìÁ∑¥Áí∞Â¢ÉÔºà‰ΩøÁî®ÂêëÈáèÂåñ„ÄÅÂ§öÂÄã envÔºâ‰∏¶Âä†ÂÖ•Ê≠£Ë¶èÂåñËàá frame stacking\n",
    "# ÈÄôÈÉ®ÂàÜ‰∏ªË¶ÅÁî®ÊñºÂä†ÈÄü‰∏¶Á©©ÂÆöË®ìÁ∑¥\n",
    "# train_env = make_vec_env(TetrisEnv, n_envs=3)\n",
    "# train_env = VecNormalize(train_env, norm_obs=False, norm_reward=True)\n",
    "# train_env = VecFrameStack(train_env, n_stack=4, channels_order='first')\n",
    "train_env = DummyVecEnv([lambda: TetrisEnv()])\n",
    "train_env = VecFrameStack(train_env, n_stack=4, channels_order=\"first\")\n",
    "\n",
    "# ----------------------------\n",
    "# ‰ΩøÁî® DQN ÈÄ≤Ë°åË®ìÁ∑¥ÔºåË™øÊï¥Ë∂ÖÂèÉÊï∏‰ª•ÊèêÂçáÊïàËÉΩÔºö\n",
    "# ÈÄôË£°Ë®≠ÂÆö buffer_size„ÄÅlearning_starts„ÄÅtarget_update_interval Á≠âÂèÉÊï∏\n",
    "model = DQN(\"CnnPolicy\", train_env, verbose=1, tensorboard_log=\"./sb3_log/\",\n",
    "            gamma=0.95,\n",
    "            learning_rate=1e-4,         # ËºÉ‰ΩéÁöÑÂ≠∏ÁøíÁéáÊúâÂä©ÊñºÁ©©ÂÆöÊî∂ÊñÇ\n",
    "            buffer_size=20000,         # Á∂ìÈ©óÂõûÊîæÁ∑©Ë°ùÂçÄÂ§ßÂ∞è\n",
    "            learning_starts=1000,       # Â§öÂ∞ëÊ≠•ÂæåÈñãÂßãÂ≠∏Áøí\n",
    "            policy_kwargs=dict(normalize_images=False),\n",
    "            target_update_interval=1000 # ÁõÆÊ®ôÁ∂≤Ë∑ØÊõ¥Êñ∞È†ªÁéá\n",
    "           )\n",
    "write_log(\"Model device: \" + str(model.device))\n",
    "# model.learn(total_timesteps=100000)  # ÂèØÊ†πÊìöÈúÄË¶ÅÂª∂Èï∑ timesteps1000000\n",
    "reward_logger = RewardLoggerCallback(log_path=\"./reward_log.txt\")\n",
    "model.learn(total_timesteps=5000000, callback=reward_logger)\n",
    "\n",
    "# ÂÑ≤Â≠òË®ìÁ∑¥ÂæåÁöÑÊ®°ÂûãÔºàË®ìÁ∑¥ÂÆåÁï¢ÂæåÂèØÂÖàÊö´ÂÅú train_env ÁöÑÊ≠∏‰∏ÄÂåñÊõ¥Êñ∞Ôºâ\n",
    "train_env.training = False\n",
    "\n",
    "# ----------------------------\n",
    "# ÂåÖË£ùÊ∏¨Ë©¶Áí∞Â¢ÉÔºå‰ΩÜÂÉÖÁî®‰æÜÁ¨¶Âêà predict Ê†ºÂºèÔºåÂèñÂΩ±ÂÉèÈÇÑÊòØÂæûÂéüÁîüÁí∞Â¢ÉÊãø\n",
    "# wrapped_test_env = make_vec_env(TetrisEnv, n_envs=1)\n",
    "# wrapped_test_env = VecNormalize(wrapped_test_env, norm_obs=False, norm_reward=False, training=False)\n",
    "# wrapped_test_env = VecFrameStack(wrapped_test_env, n_stack=4, channels_order='first')\n",
    "wrapped_test_env = DummyVecEnv([lambda: TetrisEnv()])\n",
    "wrapped_test_env = VecFrameStack(wrapped_test_env, n_stack=4, channels_order=\"first\")\n",
    "\n",
    "# ÂéüÂßãÁí∞Â¢É‰øùÁïôÁî®‰æÜÂèñÂΩ±ÂÉè\n",
    "raw_test_env = TetrisEnv()\n",
    "\n",
    "# ÂàùÂßãÂåñÁãÄÊÖã\n",
    "wrapped_obs = wrapped_test_env.reset()\n",
    "raw_obs, _ = raw_test_env.reset()\n",
    "\n",
    "frames = []\n",
    "total_test_reward = 0\n",
    "test_steps = 1000\n",
    "\n",
    "for step in range(test_steps):\n",
    "    action, _ = model.predict(wrapped_obs, deterministic=True)\n",
    "\n",
    "    # Âü∑Ë°åÂãï‰Ωú\n",
    "    next_raw_obs, reward, done, truncated, info = raw_test_env.step(action)\n",
    "    wrapped_obs, _, _, _ = wrapped_test_env.step(action)\n",
    "\n",
    "    total_test_reward += reward\n",
    "    frames.append(np.expand_dims(raw_obs.copy(), axis=0))\n",
    "    # frames.append(raw_obs.copy())  # ÂÑ≤Â≠òÂéüÂßãÂΩ±ÂÉè\n",
    "    raw_obs = next_raw_obs\n",
    "\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "write_log(\"Test completed: Total reward = \" + str(total_test_reward))\n",
    "\n",
    "# Â∞áÂõûÊîæÂΩ±ÂÉèÂ≠òÂÖ•Ë≥áÊñôÂ§æÔºà‰æùËÄÅÂ∏´Ê†ºÂºèÔºâ\n",
    "replay_folder = './replay'\n",
    "if os.path.exists(replay_folder):\n",
    "    shutil.rmtree(replay_folder)\n",
    "os.makedirs(replay_folder, exist_ok=True)\n",
    "episode_folder = os.path.join(replay_folder, \"0\", \"0\")\n",
    "os.makedirs(episode_folder, exist_ok=True)\n",
    "for i, frame in enumerate(frames):\n",
    "    fname = os.path.join(episode_folder, '{:06d}.png'.format(i))\n",
    "    cv2.imwrite(fname,frame[0].squeeze())\n",
    "\n",
    "# Áî¢Áîü replay GIFÔºàÊúÄ‰Ω≥ÂõûÊîæÔºâ\n",
    "filenames = sorted(glob.glob(episode_folder + '/*.png'))\n",
    "gif_images = []\n",
    "for filename in filenames:\n",
    "    gif_images.append(imageio.imread(filename))\n",
    "imageio.mimsave('replay.gif', gif_images, loop=0)\n",
    "print(\"Replay GIF saved: replay.gif\")\n",
    "display(FileLink('replay.gif'))\n",
    "\n",
    "# Â∞áÊ∏¨Ë©¶ÁµêÊûúÂØ´ÂÖ• CSVÔºàÊ†ºÂºèËàáËÄÅÂ∏´ÁâàÊú¨‰∏ÄËá¥Ôºâ\n",
    "with open('tetris_best_score_test2.csv', 'w') as fs:\n",
    "    fs.write('id,removed_lines,played_steps\\n')\n",
    "    fs.write(f'0,{info[\"removed_lines\"]},{info[\"lifetime\"]}\\n')\n",
    "    fs.write(f'1,{info[\"removed_lines\"]},{info[\"lifetime\"]}\\n')\n",
    "print(\"CSV file saved: tetris_best_score_test2.csv\")\n",
    "display(FileLink('tetris_best_score_test2.csv'))\n",
    "wandb.save('tetris_best_score_test2.csv')\n",
    "\n",
    "# ----------------------------\n",
    "# ÂÑ≤Â≠òÊúÄÁµÇÊ®°ÂûãÔºàË´ãÁ¢∫Ë™çÂ∞á '113598065' ÊõøÊèõÊàê‰Ω†ÁöÑÂ≠∏ËôüÔºâ\n",
    "model.save('113598065_dqn_30env_1M.zip')\n",
    "print(\"Model saved: 113598065_dqn_30env_1M.zip\")\n",
    "display(FileLink('113598065_dqn_30env_1M.zip'))\n",
    "wandb.save('113598065_dqn_30env_1M.zip')\n",
    "\n",
    "# ÈóúÈñâÁí∞Â¢É\n",
    "wrapped_test_env.close()\n",
    "raw_test_env.close()\n",
    "train_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import socket\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import imageio\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import VecNormalize, VecFrameStack, DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import torch\n",
    "import time\n",
    "import wandb\n",
    "import io\n",
    "import struct # For unpacking bytes\n",
    "from PIL import Image # For image processing\n",
    "\n",
    "# --- Kaggle/Jupyter ÁâπÊúâÂ∞éÂÖ• ---\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    # Â¶ÇÊûúÂú® Kaggle Áí∞Â¢ÉÔºåÂòóË©¶ËÆÄÂèñ WandB API Key\n",
    "    try:\n",
    "        user_secrets = UserSecretsClient()\n",
    "        WANDB_API_KEY = user_secrets.get_secret(\"WANDB_API_KEY\")\n",
    "        os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY\n",
    "        print(\"Trying to login WandB using Kaggle secrets...\")\n",
    "        wandb.login()\n",
    "        wandb.init(project=\"tetris-training\", entity=\"t113598065-ntut-edu-tw\", sync_tensorboard=True)\n",
    "        print(\"‚úÖ WandB login successful via Kaggle secrets.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå WandB setup via Kaggle secrets failed: {e}. Trying anonymous login.\")\n",
    "        wandb.login(anonymous=\"allow\")\n",
    "        wandb.init(project=\"tetris-training\", anonymous=\"allow\", sync_tensorboard=True)\n",
    "        print(\"‚úÖ WandB login successful anonymously.\")\n",
    "except ImportError:\n",
    "    # Â¶ÇÊûú‰∏çÂú® KaggleÔºåÂòóË©¶Áõ¥Êé•ÁôªÂÖ•\n",
    "    print(\"Kaggle secrets not found. Trying standard WandB login...\")\n",
    "    try:\n",
    "        if \"WANDB_API_KEY\" in os.environ:\n",
    "             wandb.login()\n",
    "             wandb.init(project=\"tetris-training\", entity=\"t113598065-ntut-edu-tw\", sync_tensorboard=True)\n",
    "             print(\"‚úÖ WandB login successful via environment variable.\")\n",
    "        else:\n",
    "             wandb.login(anonymous=\"allow\")\n",
    "             wandb.init(project=\"tetris-training\", anonymous=\"allow\", sync_tensorboard=True)\n",
    "             print(\"‚úÖ WandB login successful anonymously (no API key found).\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Standard WandB login failed: {e}. WandB logging disabled.\")\n",
    "        wandb.init(mode=\"disabled\") # Disable WandB if login fails\n",
    "\n",
    "# --- IPython Display Fallback ---\n",
    "try:\n",
    "    from IPython.display import display, FileLink\n",
    "except ImportError:\n",
    "    def display(dummy): pass\n",
    "    def FileLink(path): return f\"File available at: {path}\"\n",
    "    print(\"‚ö†Ô∏è IPython.display not found. Download links may not work as expected.\")\n",
    "\n",
    "# --- Logging Setup ---\n",
    "log_path = \"/kaggle/working/tetris_train_log.txt\" # Kaggle Ë∑ØÂæë\n",
    "if not os.path.exists(\"/kaggle/working/\"):\n",
    "    log_path = \"./tetris_train_log.txt\" # Êú¨Âú∞Ë∑ØÂæë\n",
    "\n",
    "def write_log(message):\n",
    "    with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] {message}\\n\")\n",
    "    print(message)\n",
    "\n",
    "# --- Wait for Server ---\n",
    "def wait_for_tetris_server(ip=\"127.0.0.1\", port=10612, timeout=30):\n",
    "    write_log(\"‚è≥ Á≠âÂæÖ Tetris TCP server ÂïüÂãï‰∏≠...\")\n",
    "    start_time = time.time()\n",
    "    while True:\n",
    "        try:\n",
    "            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as test_sock:\n",
    "                test_sock.settimeout(1.0)\n",
    "                test_sock.connect((ip, port))\n",
    "            write_log(f\"‚úÖ Java TCP server ({ip}:{port}) Ê∫ñÂÇôÂÆåÊàêÔºåÈÄ£Á∑öÊàêÂäü\")\n",
    "            break\n",
    "        except socket.error as e:\n",
    "            if time.time() - start_time > timeout:\n",
    "                write_log(f\"‚ùå Á≠âÂæÖ Java TCP server Ë∂ÖÊôÇ ({timeout}s)\")\n",
    "                raise TimeoutError(\"‚ùå Á≠âÂæÖ Java TCP server Ë∂ÖÊôÇ\")\n",
    "            time.sleep(0.5)\n",
    "\n",
    "# --- Reward Logger Callback (TXT format) ---\n",
    "class RewardLoggerCallback(BaseCallback):\n",
    "    def __init__(self, log_path: str, verbose: int = 0):\n",
    "        super().__init__(verbose)\n",
    "        self.log_path = log_path\n",
    "        self.episode_rewards = []\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Check if the environment is vectorized\n",
    "        is_vec_env = isinstance(self.training_env, (DummyVecEnv, VecFrameStack, VecNormalize))\n",
    "\n",
    "        if is_vec_env:\n",
    "            for i, done in enumerate(self.locals[\"dones\"]):\n",
    "                if done:\n",
    "                    info = self.locals[\"infos\"][i]\n",
    "                    if \"episode\" in info:\n",
    "                        ep_reward = info[\"episode\"][\"r\"]\n",
    "                        ep_len = info[\"episode\"][\"l\"]\n",
    "                        ep_num = len(self.episode_rewards) + 1\n",
    "                        self.episode_rewards.append(ep_reward)\n",
    "                        with open(self.log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "                            f.write(f\"{ep_num},{ep_reward}\\n\")\n",
    "                        if wandb.run and wandb.run.mode != \"disabled\":\n",
    "                             wandb.log({\"train/episode_reward\": ep_reward, \"train/episode_length\": ep_len}, step=self.num_timesteps)\n",
    "        # Handling for non-vectorized envs (less common with SB3 but good practice)\n",
    "        elif self.locals[\"dones\"]:\n",
    "             info = self.locals[\"infos\"] # Should be a single dict\n",
    "             if \"episode\" in info:\n",
    "                  ep_reward = info[\"episode\"][\"r\"]\n",
    "                  ep_len = info[\"episode\"][\"l\"]\n",
    "                  ep_num = len(self.episode_rewards) + 1\n",
    "                  self.episode_rewards.append(ep_reward)\n",
    "                  with open(self.log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "                       f.write(f\"{ep_num},{ep_reward}\\n\")\n",
    "                  if wandb.run and wandb.run.mode != \"disabled\":\n",
    "                       wandb.log({\"train/episode_reward\": ep_reward, \"train/episode_length\": ep_len}, step=self.num_timesteps)\n",
    "        return True\n",
    "\n",
    "\n",
    "# --- Tetris Áí∞Â¢É (‰øÆÊîπÁÇ∫Êé•Êî∂ÂúñÂÉè) ---\n",
    "class TetrisEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Tetris Áí∞Â¢ÉÔºåÈÄöÈÅé TCP ËàáÂ§ñÈÉ® Java ‰º∫ÊúçÂô®ÈÄö‰ø°„ÄÇ\n",
    "    **Ë≠¶Âëä:** ÂÖßÈÉ®ÂØ¶ÁèæÂü∫ÊñºÂ∞ç‰º∫ÊúçÂô®ÂçîË≠∞ÁöÑÂÅáË®≠ (ÁôºÈÄÅÂúñÂÉè + ÊñáÊú¨ÁãÄÊÖã)„ÄÇ\n",
    "    \"\"\"\n",
    "    metadata = {'render_modes': ['human', 'ansi'], 'render_fps': 4}\n",
    "\n",
    "    def __init__(self, ip=\"127.0.0.1\", port=10612, render_mode=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.server_ip = ip\n",
    "        self.server_port = port\n",
    "        self.sock = None\n",
    "        self.text_buffer = \"\" # Buffer for text messages\n",
    "        self.render_mode = render_mode\n",
    "        self.current_observation_image = None\n",
    "\n",
    "        # **ÂÅáË®≠:** ÁãÄÊÖãÊòØ 200x100 RGB ÂúñÂÉè\n",
    "        self.image_height = 200\n",
    "        self.image_width = 100\n",
    "        self.image_channels = 3\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0, high=255,\n",
    "            shape=(self.image_height, self.image_width, self.image_channels),\n",
    "            dtype=np.uint8\n",
    "        )\n",
    "\n",
    "        # **ÂÅáË®≠:** Âãï‰ΩúÊòØ 40 Á®Æ (4 ÊóãËΩâ * 10 XÂ∫ßÊ®ô)\n",
    "        self.num_actions = 40\n",
    "        self.action_space = spaces.Discrete(self.num_actions)\n",
    "\n",
    "        assert render_mode is None or render_mode in self.metadata[\"render_modes\"]\n",
    "        write_log(f\"TetrisEnv (Image Mode) initialized. Observation space: {self.observation_space}, Action space: {self.action_space}\")\n",
    "\n",
    "    def _connect_to_server(self):\n",
    "        if self.sock:\n",
    "            self.close()\n",
    "        try:\n",
    "            self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "            self.sock.settimeout(20.0) # Increased timeout for potentially larger data\n",
    "            self.sock.connect((self.server_ip, self.server_port))\n",
    "        except socket.error as e:\n",
    "            write_log(f\"‚ùå Failed to connect to Tetris server: {e}\")\n",
    "            self.sock = None\n",
    "            raise ConnectionError(f\"Failed to connect to Tetris server: {e}\")\n",
    "\n",
    "    def _send_command(self, command):\n",
    "        if not self.sock:\n",
    "            raise ConnectionError(\"Not connected to server.\")\n",
    "        try:\n",
    "            full_command = command + \"\\n\"\n",
    "            self.sock.sendall(full_command.encode('utf-8'))\n",
    "        except socket.error as e:\n",
    "            write_log(f\"‚ùå Error sending command '{command}': {e}\")\n",
    "            self.close()\n",
    "            raise ConnectionError(f\"Error sending command: {e}\")\n",
    "\n",
    "    def _receive_exact_bytes(self, n_bytes):\n",
    "        \"\"\"Receives exactly n_bytes from the socket.\"\"\"\n",
    "        if not self.sock:\n",
    "            raise ConnectionError(\"Not connected to server.\")\n",
    "        chunks = []\n",
    "        bytes_recd = 0\n",
    "        while bytes_recd < n_bytes:\n",
    "            try:\n",
    "                chunk = self.sock.recv(min(n_bytes - bytes_recd, 4096))\n",
    "                if not chunk:\n",
    "                    self.close()\n",
    "                    raise ConnectionAbortedError(f\"Connection closed by server while waiting for {n_bytes} bytes.\")\n",
    "                chunks.append(chunk)\n",
    "                bytes_recd += len(chunk)\n",
    "            except socket.timeout:\n",
    "                self.close()\n",
    "                raise TimeoutError(f\"Socket timeout while waiting for {n_bytes} bytes.\")\n",
    "            except socket.error as e:\n",
    "                self.close()\n",
    "                raise ConnectionError(f\"Socket error while receiving data: {e}\")\n",
    "        return b''.join(chunks)\n",
    "\n",
    "    def _receive_text_line(self):\n",
    "        \"\"\"Receives a newline-terminated text message.\"\"\"\n",
    "        if not self.sock:\n",
    "             raise ConnectionError(\"Not connected to server.\")\n",
    "        while \"\\n\" not in self.text_buffer:\n",
    "            try:\n",
    "                # Use recv with a smaller size for text likely after image\n",
    "                chunk = self.sock.recv(1024)\n",
    "                if not chunk:\n",
    "                    self.close()\n",
    "                    raise ConnectionAbortedError(\"Connection closed by server while waiting for text line.\")\n",
    "                # Attempt to decode immediately to catch errors early, but buffer original bytes if needed\n",
    "                try:\n",
    "                    self.text_buffer += chunk.decode('utf-8')\n",
    "                except UnicodeDecodeError as e:\n",
    "                     # Handle case where text might be mixed with unexpected binary data\n",
    "                     write_log(f\"‚ùå Error decoding text chunk: {e}. Received bytes: {chunk}\")\n",
    "                     # Decide recovery strategy: skip chunk, raise error, etc.\n",
    "                     # For now, we'll raise, assuming text should be clean UTF-8\n",
    "                     raise ValueError(f\"Invalid UTF-8 received in text message: {e}\")\n",
    "\n",
    "            except socket.timeout:\n",
    "                self.close()\n",
    "                raise TimeoutError(\"Socket timeout while waiting for text line.\")\n",
    "            except socket.error as e:\n",
    "                self.close()\n",
    "                raise ConnectionError(f\"Socket error while receiving text line: {e}\")\n",
    "\n",
    "        line_end = self.text_buffer.find(\"\\n\")\n",
    "        data_line = self.text_buffer[:line_end]\n",
    "        self.text_buffer = self.text_buffer[line_end + 1:]\n",
    "        return data_line\n",
    "\n",
    "    def _receive_message(self):\n",
    "        \"\"\"\n",
    "        Receives a message based on the **assumed** protocol:\n",
    "        1. 4-byte integer (big-endian) for image size.\n",
    "        2. image_size bytes of PNG data.\n",
    "        3. Newline-terminated text line for status (reward, terminated, info).\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # 1. Receive image size header (4 bytes, big-endian)\n",
    "            header_bytes = self._receive_exact_bytes(4)\n",
    "            image_size = struct.unpack('>I', header_bytes)[0] # '>I' for big-endian unsigned int\n",
    "\n",
    "            # 2. Receive image data\n",
    "            if image_size == 0:\n",
    "                 # Handle case where server might send 0 size for error or empty image\n",
    "                 image_bytes = b''\n",
    "                 write_log(\"‚ö†Ô∏è Received image size 0 from server.\")\n",
    "            elif image_size > 5_000_000: # Sanity check for abnormally large size\n",
    "                 raise ValueError(f\"Received excessively large image size: {image_size} bytes.\")\n",
    "            else:\n",
    "                 image_bytes = self._receive_exact_bytes(image_size)\n",
    "\n",
    "            # 3. Receive status text line\n",
    "            status_line = self._receive_text_line()\n",
    "\n",
    "            return image_bytes, status_line\n",
    "\n",
    "        except (struct.error, ValueError) as e:\n",
    "             write_log(f\"‚ùå Error processing message header or size: {e}\")\n",
    "             raise ValueError(f\"Invalid message structure received: {e}\")\n",
    "\n",
    "\n",
    "    def _parse_image_and_status(self, image_bytes, status_line):\n",
    "        \"\"\"\n",
    "        Parses the received image bytes and status line.\n",
    "        **Assumes** status_line format: \"reward,term_flag[,lines_step][,final_lines][,final_lifetime]\"\n",
    "        \"\"\"\n",
    "        # Parse Image\n",
    "        observation_image = None\n",
    "        try:\n",
    "            if image_bytes:\n",
    "                 img = Image.open(io.BytesIO(image_bytes))\n",
    "                 # Convert to RGB if it's not already (handles RGBA, Grayscale etc.)\n",
    "                 img = img.convert(\"RGB\")\n",
    "                 observation_image = np.array(img, dtype=np.uint8)\n",
    "\n",
    "                 # Verify shape (optional but recommended)\n",
    "                 expected_shape = (self.image_height, self.image_width, self.image_channels)\n",
    "                 if observation_image.shape != expected_shape:\n",
    "                      write_log(f\"‚ö†Ô∏è Warning: Received image shape {observation_image.shape} differs from expected {expected_shape}. Resizing or check Env definition.\")\n",
    "                      # Example: Resize (might distort aspect ratio)\n",
    "                      # from skimage.transform import resize\n",
    "                      # observation_image = (resize(observation_image, expected_shape, anti_aliasing=True) * 255).astype(np.uint8)\n",
    "                      # Fallback: Return error state if resize is not desired\n",
    "                      raise ValueError(\"Incorrect image dimensions received.\")\n",
    "\n",
    "            else: # Handle empty image bytes case\n",
    "                 observation_image = np.zeros(self.observation_space.shape, dtype=self.observation_space.dtype)\n",
    "\n",
    "        except Exception as e:\n",
    "            write_log(f\"‚ùå Error processing received image data: {e}\")\n",
    "            observation_image = np.zeros(self.observation_space.shape, dtype=self.observation_space.dtype)\n",
    "            # We still need to parse the status line if possible\n",
    "            # return observation_image, 0.0, True, False, {\"error\": f\"Image processing error: {e}\"}\n",
    "\n",
    "        # Parse Status Line\n",
    "        try:\n",
    "            parts = status_line.strip().split(',')\n",
    "            if len(parts) < 2:\n",
    "                raise ValueError(\"Status line has too few parts.\")\n",
    "\n",
    "            reward = float(parts[0])\n",
    "            terminated_flag = int(parts[1])\n",
    "            terminated = (terminated_flag == 1)\n",
    "            truncated = False # Assume no truncation via time limit\n",
    "\n",
    "            # Attempt to parse optional info fields\n",
    "            info = {}\n",
    "            if len(parts) > 2: info['lines_cleared_this_step'] = int(parts[2])\n",
    "            if terminated and len(parts) > 3: info['removed_lines'] = int(parts[3]) # Only relevant if terminated\n",
    "            if terminated and len(parts) > 4: info['lifetime'] = int(parts[4])      # Only relevant if terminated\n",
    "\n",
    "            # Fill defaults if keys are missing after termination (needed for evaluation)\n",
    "            if terminated:\n",
    "                 info.setdefault('removed_lines', 0)\n",
    "                 info.setdefault('lifetime', 0)\n",
    "\n",
    "\n",
    "            return observation_image, reward, terminated, truncated, info\n",
    "\n",
    "        except Exception as e:\n",
    "            write_log(f\"‚ùå Error parsing status line '{status_line}': {e}\")\n",
    "            # Return observation image if valid, but signal error/termination\n",
    "            if observation_image is None: # If image parsing also failed\n",
    "                 observation_image = np.zeros(self.observation_space.shape, dtype=self.observation_space.dtype)\n",
    "            # Terminate the episode on parsing error\n",
    "            return observation_image, 0.0, True, False, {\"error\": f\"Status parsing error: {e}\"}\n",
    "\n",
    "\n",
    "    def _map_action_to_command(self, action):\n",
    "        \"\"\"\n",
    "        Maps action index (0-39) to \"PLACE <rot> <x>\" command (Assumption).\n",
    "        \"\"\"\n",
    "        if not 0 <= action < self.num_actions:\n",
    "            write_log(f\"‚ùå Invalid action: {action}. Using action 0.\")\n",
    "            action = 0\n",
    "        num_x_positions = 10\n",
    "        rotation_index = action // num_x_positions\n",
    "        x_position = action % num_x_positions\n",
    "        command = f\"PLACE {rotation_index} {x_position}\"\n",
    "        return command\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        try:\n",
    "            self._connect_to_server()\n",
    "            self._send_command(\"RESET\")\n",
    "            image_bytes, status_line = self._receive_message()\n",
    "            observation, _, _, _, info = self._parse_image_and_status(image_bytes, status_line)\n",
    "            self.current_observation_image = observation\n",
    "            if self.render_mode == \"human\": self.render()\n",
    "            if info is None: info = {} # Ensure info is always a dict\n",
    "            return observation, info\n",
    "        except (ConnectionError, TimeoutError, ValueError, ConnectionAbortedError, struct.error) as e:\n",
    "             write_log(f\"‚ùå Error during reset: {e}. Returning zero observation.\")\n",
    "             obs = np.zeros(self.observation_space.shape, dtype=self.observation_space.dtype)\n",
    "             info = {\"error\": f\"Reset error: {e}\"}\n",
    "             self.current_observation_image = obs\n",
    "             return obs, info\n",
    "\n",
    "    def step(self, action):\n",
    "        if self.sock is None:\n",
    "            write_log(\"‚ùå Attempting to step with no connection.\")\n",
    "            obs = np.zeros(self.observation_space.shape, dtype=self.observation_space.dtype)\n",
    "            return obs, 0.0, True, False, {\"error\": \"Connection lost\"}\n",
    "        try:\n",
    "            command = self._map_action_to_command(action)\n",
    "            self._send_command(command)\n",
    "            image_bytes, status_line = self._receive_message()\n",
    "            observation, reward, terminated, truncated, info = self._parse_image_and_status(image_bytes, status_line)\n",
    "            self.current_observation_image = observation\n",
    "\n",
    "            if self.render_mode == \"human\": self.render()\n",
    "            if info is None: info = {} # Ensure info is always a dict\n",
    "\n",
    "            # Add final evaluation keys if terminated (based on parsing assumption)\n",
    "            if terminated:\n",
    "                info.setdefault('removed_lines', 0)\n",
    "                info.setdefault('lifetime', 0)\n",
    "\n",
    "            return observation, float(reward), bool(terminated), bool(truncated), info\n",
    "\n",
    "        except (ConnectionError, TimeoutError, ValueError, ConnectionAbortedError, struct.error) as e:\n",
    "             write_log(f\"‚ùå Error during step: {e}. Terminating episode.\")\n",
    "             obs = self.current_observation_image if self.current_observation_image is not None else np.zeros(self.observation_space.shape, dtype=self.observation_space.dtype)\n",
    "             return obs, 0.0, True, False, {\"error\": f\"Step error: {e}\"}\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode == \"ansi\":\n",
    "            # Cannot render image as text easily\n",
    "            print(\"State: (Image observation, use 'human' mode or check saved images)\")\n",
    "        elif self.render_mode == \"human\":\n",
    "             if self.current_observation_image is not None:\n",
    "                 try:\n",
    "                     # Convert RGB (PIL/numpy) to BGR (OpenCV)\n",
    "                     img_bgr = cv2.cvtColor(self.current_observation_image, cv2.COLOR_RGB2BGR)\n",
    "                     cv2.imshow(\"Tetris (Python Render)\", img_bgr)\n",
    "                     cv2.waitKey(1) # Needed for imshow to refresh\n",
    "                 except Exception as e:\n",
    "                     print(f\"Human rendering failed: {e}\")\n",
    "             else:\n",
    "                 print(\"State: (No observation image available)\")\n",
    "\n",
    "    def close(self):\n",
    "        if self.sock:\n",
    "            try:\n",
    "                self.sock.shutdown(socket.SHUT_RDWR)\n",
    "                self.sock.close()\n",
    "            except socket.error: pass\n",
    "            finally: self.sock = None\n",
    "        if self.render_mode == \"human\":\n",
    "             try: cv2.destroyAllWindows()\n",
    "             except: pass\n",
    "\n",
    "\n",
    "# --- ‰∏ªÁ®ãÂºè ---\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Constants ---\n",
    "    SERVER_IP = \"127.0.0.1\"\n",
    "    SERVER_PORT = 10612\n",
    "    STUDENT_ID = \"113598065\"\n",
    "    # Using EXACT filenames as requested\n",
    "    MODEL_SAVE_PATH_ZIP = \"/kaggle/working/113598065_dqn_30env_1M.zip\"\n",
    "    CSV_SAVE_PATH = \"/kaggle/working/tetris_best_score_test2.csv\"\n",
    "    # Other paths derived from WORK_DIR\n",
    "    WORK_DIR = \"/kaggle/working/\"\n",
    "    if not os.path.exists(WORK_DIR): WORK_DIR = \"./\"\n",
    "    REWARD_LOG_FILE_PATH = os.path.join(WORK_DIR, \"reward_log.txt\")\n",
    "    TENSORBOARD_LOG_PATH = os.path.join(WORK_DIR, \"tensorboard_logs/\")\n",
    "    JAVA_SERVER_JAR = \"TetrisTCPserver_v0.6.jar\"\n",
    "    TOTAL_TRAIN_TIMESTEPS = 1_000_000 # Adjust training steps if needed (doesn't affect filename now)\n",
    "    N_STACK_FRAMES = 4 # Number of frames to stack for CNN\n",
    "\n",
    "    # --- 1. ÂïüÂãï Java Server ---\n",
    "    write_log(\"--- Starting Java Server ---\")\n",
    "    java_process = None\n",
    "    # ...(Same Java startup code as before)...\n",
    "    try:\n",
    "        java_process = subprocess.Popen([\"java\", \"-jar\", JAVA_SERVER_JAR], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        write_log(f\"‚úÖ Java server process started (PID: {java_process.pid}). Waiting for connection...\")\n",
    "        # Add brief pause and check for immediate errors\n",
    "        time.sleep(2)\n",
    "        stderr_check = \"\"\n",
    "        try: stderr_check = java_process.stderr.read()\n",
    "        except: pass # Ignore read errors if process running\n",
    "        if stderr_check:\n",
    "             write_log(\"--- Java Server STDERR on Startup ---\"); write_log(stderr_check); write_log(\"---------------------------------\")\n",
    "        wait_for_tetris_server(SERVER_IP, SERVER_PORT)\n",
    "    except FileNotFoundError:\n",
    "        write_log(f\"‚ùå Error: {JAVA_SERVER_JAR} not found.\"); exit()\n",
    "    except Exception as e:\n",
    "        write_log(f\"‚ùå Error starting/waiting for Java server: {e}\")\n",
    "        if java_process: java_process.terminate()\n",
    "        exit()\n",
    "\n",
    "    # --- 2. Áí∞Â¢ÉÊ™¢Êü•ËàáÂâµÂª∫ ---\n",
    "    write_log(\"--- Setting up Environment ---\")\n",
    "    env_instance_for_check = None\n",
    "    train_env_vec = None\n",
    "    try:\n",
    "        # Check the base environment first\n",
    "        env_instance_for_check = TetrisEnv(ip=SERVER_IP, port=SERVER_PORT)\n",
    "        check_env(env_instance_for_check, warn=True)\n",
    "        write_log(\"‚úÖ Base environment check passed.\")\n",
    "    except Exception as e:\n",
    "        write_log(f\"‚ùå Environment check failed: {e}\")\n",
    "        if env_instance_for_check: env_instance_for_check.close()\n",
    "        if java_process: java_process.terminate()\n",
    "        exit()\n",
    "    finally:\n",
    "         if env_instance_for_check: env_instance_for_check.close()\n",
    "\n",
    "    # Create vectorized and stacked environment for training\n",
    "    train_env = DummyVecEnv([lambda: TetrisEnv(ip=SERVER_IP, port=SERVER_PORT)])\n",
    "    train_env_vec = VecFrameStack(train_env, n_stack=N_STACK_FRAMES)\n",
    "    write_log(f\"‚úÖ Training environment created and wrapped with VecFrameStack (n_stack={N_STACK_FRAMES}).\")\n",
    "    write_log(f\"   Observation space (stacked): {train_env_vec.observation_space}\")\n",
    "\n",
    "\n",
    "    # --- 3. ÂÆöÁæ©Ê®°Âûã ---\n",
    "    write_log(\"--- Defining DQN Model (CNN Policy) ---\")\n",
    "    policy_type = \"CnnPolicy\" # Use CNN for image input\n",
    "    os.makedirs(TENSORBOARD_LOG_PATH, exist_ok=True)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    write_log(f\"Using device: {device}\")\n",
    "\n",
    "    model = DQN(\n",
    "        policy_type,\n",
    "        train_env_vec, # Train on the stacked environment\n",
    "        verbose=1,\n",
    "        tensorboard_log=TENSORBOARD_LOG_PATH,\n",
    "        learning_rate=1e-4, # May need tuning for CNN\n",
    "        buffer_size=50000,  # May need larger buffer for images\n",
    "        learning_starts=10000,# Let buffer fill more before learning\n",
    "        batch_size=32,      # Often smaller batch size for CNNs due to memory\n",
    "        tau=1.0,\n",
    "        gamma=0.99,\n",
    "        train_freq=4,\n",
    "        gradient_steps=1,\n",
    "        target_update_interval=1000, # May need longer interval\n",
    "        exploration_fraction=0.1,\n",
    "        exploration_final_eps=0.05,\n",
    "        # SB3's DQN with CnnPolicy expects images in channel-first format (C, H, W)\n",
    "        # VecFrameStack usually handles the dimension permutation if the env returns H, W, C\n",
    "        policy_kwargs=dict(features_extractor_kwargs=dict(features_dim=512)), # Example CNN feature dim\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # --- 4. ÂÆöÁæ©ÂõûË™øÂáΩÊï∏ ---\n",
    "    reward_logger = RewardLoggerCallback(log_path=REWARD_LOG_FILE_PATH)\n",
    "    callbacks = [reward_logger]\n",
    "    if wandb.run and wandb.run.mode != \"disabled\":\n",
    "        from wandb.integration.sb3 import WandbCallback\n",
    "        wandb_callback = WandbCallback(log=\"all\", verbose=2)\n",
    "        callbacks.append(wandb_callback)\n",
    "\n",
    "    # --- 5. Ë®ìÁ∑¥Ê®°Âûã ---\n",
    "    write_log(f\"--- Starting Training for {TOTAL_TRAIN_TIMESTEPS} timesteps ---\")\n",
    "    training_successful = False\n",
    "    try:\n",
    "        model.learn(\n",
    "            total_timesteps=TOTAL_TRAIN_TIMESTEPS,\n",
    "            log_interval=10,\n",
    "            callback=callbacks\n",
    "        )\n",
    "        training_successful = True\n",
    "        write_log(\"‚úÖ Training completed successfully.\")\n",
    "    except KeyboardInterrupt:\n",
    "        write_log(\"üõë Training interrupted by user.\")\n",
    "    except Exception as train_e:\n",
    "        write_log(f\"‚ùå Training failed: {train_e}\")\n",
    "        # ...(Error saving logic remains the same)...\n",
    "        error_save_path = os.path.join(WORK_DIR, f\"{STUDENT_ID}_dqn_error.zip\") # Generic error name\n",
    "        try: model.save(error_save_path); write_log(f\"üíæ Intermediate model saved to {error_save_path}\")\n",
    "        except: write_log(\"‚ùå Failed to save intermediate model after error.\")\n",
    "    finally:\n",
    "        # --- ‰øùÂ≠òÊúÄÁµÇÊ®°Âûã (Using exact requested filename) ---\n",
    "        if training_successful:\n",
    "            try:\n",
    "                model.save(MODEL_SAVE_PATH_ZIP) # Use the exact path defined earlier\n",
    "                write_log(f\"üíæ Final model saved: {MODEL_SAVE_PATH_ZIP}\")\n",
    "                display(FileLink(MODEL_SAVE_PATH_ZIP))\n",
    "                if wandb.run and wandb.run.mode != \"disabled\":\n",
    "                    wandb.save(MODEL_SAVE_PATH_ZIP, base_path=WORK_DIR)\n",
    "                    write_log(\"‚¨ÜÔ∏è Final model uploaded to WandB.\")\n",
    "            except Exception as final_save_e:\n",
    "                write_log(f\"‚ùå Failed to save final model: {final_save_e}\")\n",
    "        # ÈóúÈñâË®ìÁ∑¥Áí∞Â¢É\n",
    "        if train_env_vec: train_env_vec.close() # Close the VecFrameStack wrapper\n",
    "        write_log(\"‚úÖ Training environment closed.\")\n",
    "\n",
    "    # --- 6. Ë©ï‰º∞Ê®°Âûã‰∏¶‰øùÂ≠ò CSV ---\n",
    "    if training_successful:\n",
    "        write_log(\"\\n--- Starting Model Evaluation ---\")\n",
    "        # Use a non-vectorized, non-stacked env for simplicity in eval loop control\n",
    "        eval_env = None\n",
    "        try:\n",
    "            write_log(f\"üîÑ Loading model from: {MODEL_SAVE_PATH_ZIP}\")\n",
    "            # Load model, no env needed if saved correctly\n",
    "            eval_model = DQN.load(MODEL_SAVE_PATH_ZIP, device=device)\n",
    "\n",
    "            # Create a fresh evaluation environment (not stacked)\n",
    "            eval_env = TetrisEnv(ip=SERVER_IP, port=SERVER_PORT)\n",
    "            obs, info = eval_env.reset() # obs is single image (H, W, C)\n",
    "\n",
    "            # For CNN policy, prediction needs channel-first and batch dim (N, C, H, W)\n",
    "            # And needs stacking if trained with stacking. Manual stacking for eval:\n",
    "            stacked_obs_deque = io.deque([np.zeros_like(obs)] * N_STACK_FRAMES, maxlen=N_STACK_FRAMES)\n",
    "            stacked_obs_deque.append(obs)\n",
    "\n",
    "            def get_stacked_observation(deque):\n",
    "                # Stack along the channel dimension (axis=2 for HWC -> HWSC, then transpose) or a new axis\n",
    "                stacked_frames = np.array(list(deque)) # Shape (N_STACK, H, W, C)\n",
    "                # SB3 CnnPolicy usually expects (Batch, C*N_STACK, H, W) or similar based on extractor\n",
    "                # Or VecFrameStack gives (Batch, H, W, C*N_STACK) -> let's assume this\n",
    "                # This part is tricky and depends on how VecFrameStack observation space is structured.\n",
    "                # Let's assume VecFrameStack concatenates channels: (H, W, C * N_STACK)\n",
    "                # We need to replicate this manually.\n",
    "                processed_obs = np.concatenate(list(deque), axis=-1) # Concatenate along channel axis -> (H, W, C*N_STACK)\n",
    "                # Add batch dimension\n",
    "                return np.expand_dims(processed_obs, axis=0)\n",
    "\n",
    "\n",
    "            terminated = False\n",
    "            truncated = False\n",
    "            played_steps = 0\n",
    "            removed_lines_total = 0\n",
    "            final_removed_lines = 0\n",
    "            final_lifetime = 0\n",
    "\n",
    "            while not terminated and not truncated:\n",
    "                current_stacked_obs_for_policy = get_stacked_observation(stacked_obs_deque)\n",
    "                action, _ = eval_model.predict(current_stacked_obs_for_policy, deterministic=True)\n",
    "                obs, reward, terminated, truncated, info = eval_env.step(action[0]) # action is usually wrapped in a list/array\n",
    "                stacked_obs_deque.append(obs) # Add new observation\n",
    "                played_steps += 1\n",
    "                # Accumulate lines based on info from step (ASSUMPTION)\n",
    "                removed_lines_total += info.get('lines_cleared_this_step', 0)\n",
    "                # If terminated, try to get final stats from info (ASSUMPTION)\n",
    "                if terminated:\n",
    "                    final_removed_lines = info.get('removed_lines', removed_lines_total)\n",
    "                    final_lifetime = info.get('lifetime', played_steps)\n",
    "\n",
    "            write_log(f\"üèÅ Evaluation Episode finished. Steps: {final_lifetime}, Removed Lines: {final_removed_lines}\")\n",
    "\n",
    "            # --- ÂØ´ÂÖ• CSV Êñá‰ª∂ (Using exact requested filename and format) ---\n",
    "            write_log(f\"üíæ Writing evaluation results to: {CSV_SAVE_PATH}\")\n",
    "            with open(CSV_SAVE_PATH, 'w') as fs:\n",
    "                fs.write('id,removed_lines,played_steps\\n')\n",
    "                fs.write(f'0,{final_removed_lines},{final_lifetime}\\n')\n",
    "                fs.write(f'1,{final_removed_lines},{final_lifetime}\\n')\n",
    "            write_log(\"‚úÖ CSV file saved.\")\n",
    "            display(FileLink(CSV_SAVE_PATH))\n",
    "            if wandb.run and wandb.run.mode != \"disabled\":\n",
    "                wandb.save(CSV_SAVE_PATH, base_path=WORK_DIR)\n",
    "                write_log(\"‚¨ÜÔ∏è CSV results uploaded to WandB.\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "             write_log(f\"‚ùå Evaluation failed: Model file not found at {MODEL_SAVE_PATH_ZIP}\")\n",
    "        except KeyError as e:\n",
    "             write_log(f\"‚ùå Evaluation failed: Missing key {e} in environment's info dictionary.\")\n",
    "             write_log(\"   Ensure TetrisEnv step() returns info with required keys on termination.\")\n",
    "        except Exception as eval_e:\n",
    "             write_log(f\"‚ùå An error occurred during evaluation or CSV saving: {eval_e}\")\n",
    "        finally:\n",
    "            if eval_env: eval_env.close()\n",
    "            write_log(\"‚úÖ Evaluation environment closed.\")\n",
    "\n",
    "\n",
    "    # --- 7. Ê∏ÖÁêÜÂ∑•‰Ωú ---\n",
    "    # ...(Same cleanup code as before)...\n",
    "    write_log(\"--- Cleaning up ---\")\n",
    "    if java_process:\n",
    "        try:\n",
    "            java_process.terminate()\n",
    "            java_process.wait(timeout=5)\n",
    "            write_log(\"‚òï Java server process terminated.\")\n",
    "        except subprocess.TimeoutExpired:\n",
    "            java_process.kill()\n",
    "            write_log(\"üî™ Java server process killed.\")\n",
    "        except Exception as e:\n",
    "            write_log(f\"‚ö†Ô∏è Error terminating Java process: {e}\")\n",
    "\n",
    "    if wandb.run and wandb.run.mode != \"disabled\":\n",
    "         wandb.finish()\n",
    "         write_log(\"üìä WandB run finished.\")\n",
    "\n",
    "    write_log(\"üèÅ Full script finished.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11461423,
     "sourceId": 96443,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
